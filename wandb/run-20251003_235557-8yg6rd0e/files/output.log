
Steps:   0%|                                                                       | 1/1000000 [00:04<1338:02:37,  4.82s/it][[34m2025-10-03 23:56:10[39m] Generating EMA samples done.
[[34m2025-10-03 23:56:10[39m] Step: 1, Training Logs: loss_final: 1.852024, loss_mean: 1.685077, proj_loss: -0.001562, loss_mean_cls: 0.118509, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 2/1000000 [00:05<738:31:24,  2.66s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.85, loss_mean=1.69, loss_m[[34m2025-10-03 23:56:11[39m] Step: 2, Training Logs: loss_final: 1.857074, loss_mean: 1.690185, proj_loss: -0.001133, loss_mean_cls: 0.118023, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 3/1000000 [00:07<548:21:25,  1.97s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_m[[34m2025-10-03 23:56:13[39m] Step: 3, Training Logs: loss_final: 1.893526, loss_mean: 1.725911, proj_loss: -0.000692, loss_mean_cls: 0.118307, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 4/1000000 [00:08<459:10:37,  1.65s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.89, loss_mean=1.73, loss_m[[34m2025-10-03 23:56:14[39m] Step: 4, Training Logs: loss_final: 1.863802, loss_mean: 1.696726, proj_loss: -0.000918, loss_mean_cls: 0.117994, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 5/1000000 [00:09<409:43:25,  1.48s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.7, loss_me[[34m2025-10-03 23:56:15[39m] Step: 5, Training Logs: loss_final: 1.876213, loss_mean: 1.708497, proj_loss: -0.001132, loss_mean_cls: 0.118849, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 6/1000000 [00:10<379:45:27,  1.37s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.88, loss_mean=1.71, loss_m[[34m2025-10-03 23:56:16[39m] Step: 6, Training Logs: loss_final: 1.861109, loss_mean: 1.693091, proj_loss: -0.000262, loss_mean_cls: 0.118281, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 7/1000000 [00:11<361:05:37,  1.30s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_m[[34m2025-10-03 23:56:17[39m] Step: 7, Training Logs: loss_final: 1.855225, loss_mean: 1.687699, proj_loss: -0.000456, loss_mean_cls: 0.117981, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 8/1000000 [00:12<348:41:34,  1.26s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_m[[34m2025-10-03 23:56:18[39m] Step: 8, Training Logs: loss_final: 1.865341, loss_mean: 1.697358, proj_loss: -0.000295, loss_mean_cls: 0.118278, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 9/1000000 [00:14<340:06:13,  1.22s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.87, loss_mean=1.7, loss_me[[34m2025-10-03 23:56:20[39m] Step: 9, Training Logs: loss_final: 1.856894, loss_mean: 1.689859, proj_loss: -0.001537, loss_mean_cls: 0.118572, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 10/1000000 [00:15<335:19:39,  1.21s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:56:21[39m] Step: 10, Training Logs: loss_final: 1.880090, loss_mean: 1.711735, proj_loss: 0.000060, loss_mean_cls: 0.118295, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 11/1000000 [00:16<331:21:57,  1.19s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.88, loss_mean=1.71, loss_[[34m2025-10-03 23:56:22[39m] Step: 11, Training Logs: loss_final: 1.858421, loss_mean: 1.690543, proj_loss: -0.000472, loss_mean_cls: 0.118350, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 12/1000000 [00:17<327:52:35,  1.18s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:56:23[39m] Step: 12, Training Logs: loss_final: 1.876679, loss_mean: 1.708093, proj_loss: 0.000305, loss_mean_cls: 0.118281, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 13/1000000 [00:18<325:36:27,  1.17s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.88, loss_mean=1.71, loss_[[34m2025-10-03 23:56:24[39m] Step: 13, Training Logs: loss_final: 1.844913, loss_mean: 1.677251, proj_loss: -0.000555, loss_mean_cls: 0.118217, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 14/1000000 [00:19<324:09:15,  1.17s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.84, loss_mean=1.68, loss_[[34m2025-10-03 23:56:25[39m] Step: 14, Training Logs: loss_final: 1.860075, loss_mean: 1.692572, proj_loss: -0.000743, loss_mean_cls: 0.118246, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 15/1000000 [00:21<323:24:35,  1.16s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:56:26[39m] Step: 15, Training Logs: loss_final: 1.858943, loss_mean: 1.690525, proj_loss: 0.000005, loss_mean_cls: 0.118413, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 16/1000000 [00:22<322:21:26,  1.16s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:56:28[39m] Step: 16, Training Logs: loss_final: 1.882615, loss_mean: 1.715268, proj_loss: -0.000550, loss_mean_cls: 0.117897, deep_loss: 0.050000, grad_norm: inf
Steps:   0%| | 17/1000000 [00:23<309:35:46,  1.11s/it, deep_loss=0.05, grad_norm=inf, loss_final=1.88, loss_mean=1.72, loss_[[34m2025-10-03 23:56:29[39m] Step: 17, Training Logs: loss_final: 1.849142, loss_mean: 1.680075, proj_loss: 0.000387, loss_mean_cls: 0.118681, deep_loss: 0.050000, grad_norm: inf
Steps:   0%| | 18/1000000 [00:24<287:46:29,  1.04s/it, deep_loss=0.05, grad_norm=inf, loss_final=1.85, loss_mean=1.68, loss_[[34m2025-10-03 23:56:29[39m] Step: 18, Training Logs: loss_final: 1.846045, loss_mean: 1.678042, proj_loss: -0.000140, loss_mean_cls: 0.118143, deep_loss: 0.050000, grad_norm: 3722890.000000
Steps:   0%| | 19/1000000 [00:24<267:12:33,  1.04it/s, deep_loss=0.05, grad_norm=3.72e+6, loss_final=1.85, loss_mean=1.68, l[[34m2025-10-03 23:56:30[39m] Step: 19, Training Logs: loss_final: 1.857450, loss_mean: 1.695266, proj_loss: -0.001839, loss_mean_cls: 0.118697, deep_loss: 0.045326, grad_norm: 1.190755
Steps:   0%| | 20/1000000 [00:25<260:05:37,  1.07it/s, deep_loss=0.0453, grad_norm=1.19, loss_final=1.86, loss_mean=1.7, los[[34m2025-10-03 23:56:31[39m] Step: 20, Training Logs: loss_final: 1.844619, loss_mean: 1.702542, proj_loss: -0.020595, loss_mean_cls: 0.118579, deep_loss: 0.044093, grad_norm: 1.050217
Steps:   0%| | 21/1000000 [00:26<279:57:37,  1.01s/it, deep_loss=0.0441, grad_norm=1.05, loss_final=1.84, loss_mean=1.7, los[[34m2025-10-03 23:56:32[39m] Step: 21, Training Logs: loss_final: 1.800544, loss_mean: 1.677884, proj_loss: -0.039088, loss_mean_cls: 0.118060, deep_loss: 0.043688, grad_norm: 0.775306
Steps:   0%| | 22/1000000 [00:28<292:35:58,  1.05s/it, deep_loss=0.0437, grad_norm=0.775, loss_final=1.8, loss_mean=1.68, lo[[34m2025-10-03 23:56:34[39m] Step: 22, Training Logs: loss_final: 1.779429, loss_mean: 1.675088, proj_loss: -0.057046, loss_mean_cls: 0.118154, deep_loss: 0.043234, grad_norm: 0.852297
Steps:   0%| | 23/1000000 [00:29<302:47:20,  1.09s/it, deep_loss=0.0432, grad_norm=0.852, loss_final=1.78, loss_mean=1.68, l[[34m2025-10-03 23:56:35[39m] Step: 23, Training Logs: loss_final: 1.779888, loss_mean: 1.684882, proj_loss: -0.066553, loss_mean_cls: 0.118888, deep_loss: 0.042671, grad_norm: 0.965044
Steps:   0%| | 24/1000000 [00:30<309:42:48,  1.11s/it, deep_loss=0.0427, grad_norm=0.965, loss_final=1.78, loss_mean=1.68, l[[34m2025-10-03 23:56:36[39m] Step: 24, Training Logs: loss_final: 1.732833, loss_mean: 1.650599, proj_loss: -0.077307, loss_mean_cls: 0.118220, deep_loss: 0.041320, grad_norm: 0.960297
Steps:   0%| | 25/1000000 [00:31<314:59:26,  1.13s/it, deep_loss=0.0413, grad_norm=0.96, loss_final=1.73, loss_mean=1.65, lo[[34m2025-10-03 23:56:37[39m] Step: 25, Training Logs: loss_final: 1.747091, loss_mean: 1.675151, proj_loss: -0.083633, loss_mean_cls: 0.117665, deep_loss: 0.037908, grad_norm: 1.071090
Steps:   0%| | 26/1000000 [00:32<318:43:14,  1.15s/it, deep_loss=0.0379, grad_norm=1.07, loss_final=1.75, loss_mean=1.68, lo[[34m2025-10-03 23:56:38[39m] Step: 26, Training Logs: loss_final: 1.732247, loss_mean: 1.664828, proj_loss: -0.086854, loss_mean_cls: 0.118246, deep_loss: 0.036028, grad_norm: 1.194224
Steps:   0%| | 27/1000000 [00:33<320:57:48,  1.16s/it, deep_loss=0.036, grad_norm=1.19, loss_final=1.73, loss_mean=1.66, los[[34m2025-10-03 23:56:39[39m] Step: 27, Training Logs: loss_final: 1.740822, loss_mean: 1.677012, proj_loss: -0.090685, loss_mean_cls: 0.117870, deep_loss: 0.036625, grad_norm: 1.458827
Steps:   0%| | 28/1000000 [00:35<323:28:00,  1.16s/it, deep_loss=0.0366, grad_norm=1.46, loss_final=1.74, loss_mean=1.68, lo[[34m2025-10-03 23:56:41[39m] Step: 28, Training Logs: loss_final: 1.726125, loss_mean: 1.666409, proj_loss: -0.095203, loss_mean_cls: 0.118141, deep_loss: 0.036778, grad_norm: 1.448264
Steps:   0%| | 29/1000000 [00:36<323:55:33,  1.17s/it, deep_loss=0.0368, grad_norm=1.45, loss_final=1.73, loss_mean=1.67, lo[[34m2025-10-03 23:56:42[39m] Step: 29, Training Logs: loss_final: 1.709279, loss_mean: 1.651641, proj_loss: -0.096746, loss_mean_cls: 0.118754, deep_loss: 0.035630, grad_norm: 1.323612
Steps:   0%| | 30/1000000 [00:37<325:11:10,  1.17s/it, deep_loss=0.0356, grad_norm=1.32, loss_final=1.71, loss_mean=1.65, lo[[34m2025-10-03 23:56:43[39m] Step: 30, Training Logs: loss_final: 1.716180, loss_mean: 1.663827, proj_loss: -0.099533, loss_mean_cls: 0.117709, deep_loss: 0.034177, grad_norm: 1.130866
Steps:   0%| | 31/1000000 [00:38<326:27:21,  1.18s/it, deep_loss=0.0342, grad_norm=1.13, loss_final=1.72, loss_mean=1.66, lo[[34m2025-10-03 23:56:44[39m] Step: 31, Training Logs: loss_final: 1.678653, loss_mean: 1.629526, proj_loss: -0.103068, loss_mean_cls: 0.117498, deep_loss: 0.034697, grad_norm: 0.945440
Steps:   0%| | 32/1000000 [00:39<326:16:14,  1.17s/it, deep_loss=0.0347, grad_norm=0.945, loss_final=1.68, loss_mean=1.63, l[[34m2025-10-03 23:56:45[39m] Step: 32, Training Logs: loss_final: 1.682934, loss_mean: 1.635470, proj_loss: -0.103926, loss_mean_cls: 0.117073, deep_loss: 0.034317, grad_norm: 1.013697
Steps:   0%| | 33/1000000 [00:40<325:46:42,  1.17s/it, deep_loss=0.0343, grad_norm=1.01, loss_final=1.68, loss_mean=1.64, lo[[34m2025-10-03 23:56:46[39m] Step: 33, Training Logs: loss_final: 1.691482, loss_mean: 1.647624, proj_loss: -0.107752, loss_mean_cls: 0.117478, deep_loss: 0.034132, grad_norm: 1.057782
Steps:   0%| | 34/1000000 [00:42<326:45:36,  1.18s/it, deep_loss=0.0341, grad_norm=1.06, loss_final=1.69, loss_mean=1.65, lo[[34m2025-10-03 23:56:48[39m] Step: 34, Training Logs: loss_final: 1.660714, loss_mean: 1.617018, proj_loss: -0.107499, loss_mean_cls: 0.117152, deep_loss: 0.034043, grad_norm: 0.951552
Steps:   0%| | 35/1000000 [00:43<327:07:05,  1.18s/it, deep_loss=0.034, grad_norm=0.952, loss_final=1.66, loss_mean=1.62, lo[[34m2025-10-03 23:56:49[39m] Step: 35, Training Logs: loss_final: 1.684107, loss_mean: 1.645801, proj_loss: -0.112035, loss_mean_cls: 0.117595, deep_loss: 0.032746, grad_norm: 0.923220
Steps:   0%| | 36/1000000 [00:44<327:04:46,  1.18s/it, deep_loss=0.0327, grad_norm=0.923, loss_final=1.68, loss_mean=1.65, l[[34m2025-10-03 23:56:50[39m] Step: 36, Training Logs: loss_final: 1.642755, loss_mean: 1.604292, proj_loss: -0.112821, loss_mean_cls: 0.117412, deep_loss: 0.033873, grad_norm: 0.981911
Steps:   0%| | 37/1000000 [00:45<326:55:38,  1.18s/it, deep_loss=0.0339, grad_norm=0.982, loss_final=1.64, loss_mean=1.6, lo[[34m2025-10-03 23:56:51[39m] Step: 37, Training Logs: loss_final: 1.644108, loss_mean: 1.610567, proj_loss: -0.116132, loss_mean_cls: 0.116967, deep_loss: 0.032705, grad_norm: 1.065663
Steps:   0%| | 38/1000000 [00:46<326:36:39,  1.18s/it, deep_loss=0.0327, grad_norm=1.07, loss_final=1.64, loss_mean=1.61, lo[[34m2025-10-03 23:56:52[39m] Step: 38, Training Logs: loss_final: 1.658254, loss_mean: 1.626786, proj_loss: -0.119235, loss_mean_cls: 0.117879, deep_loss: 0.032824, grad_norm: 0.967049
Steps:   0%| | 39/1000000 [00:48<327:17:10,  1.18s/it, deep_loss=0.0328, grad_norm=0.967, loss_final=1.66, loss_mean=1.63, l[[34m2025-10-03 23:56:54[39m] Step: 39, Training Logs: loss_final: 1.624334, loss_mean: 1.596041, proj_loss: -0.121517, loss_mean_cls: 0.116626, deep_loss: 0.033183, grad_norm: 0.936775
Steps:   0%| | 40/1000000 [00:49<326:33:48,  1.18s/it, deep_loss=0.0332, grad_norm=0.937, loss_final=1.62, loss_mean=1.6, lo[[34m2025-10-03 23:56:55[39m] Step: 40, Training Logs: loss_final: 1.621049, loss_mean: 1.597463, proj_loss: -0.126371, loss_mean_cls: 0.117717, deep_loss: 0.032240, grad_norm: 0.861901
Steps:   0%| | 41/1000000 [00:50<326:24:16,  1.18s/it, deep_loss=0.0322, grad_norm=0.862, loss_final=1.62, loss_mean=1.6, lo[[34m2025-10-03 23:56:56[39m] Step: 41, Training Logs: loss_final: 1.600093, loss_mean: 1.578682, proj_loss: -0.127728, loss_mean_cls: 0.117250, deep_loss: 0.031888, grad_norm: 0.834176
Steps:   0%| | 42/1000000 [00:51<325:45:53,  1.17s/it, deep_loss=0.0319, grad_norm=0.834, loss_final=1.6, loss_mean=1.58, lo[[34m2025-10-03 23:56:57[39m] Step: 42, Training Logs: loss_final: 1.595250, loss_mean: 1.575648, proj_loss: -0.128957, loss_mean_cls: 0.116559, deep_loss: 0.031999, grad_norm: 0.810932
Steps:   0%| | 43/1000000 [00:52<326:40:27,  1.18s/it, deep_loss=0.032, grad_norm=0.811, loss_final=1.6, loss_mean=1.58, los[[34m2025-10-03 23:56:58[39m] Step: 43, Training Logs: loss_final: 1.575175, loss_mean: 1.557783, proj_loss: -0.131346, loss_mean_cls: 0.116795, deep_loss: 0.031943, grad_norm: 0.758303
Steps:   0%| | 44/1000000 [00:53<327:12:59,  1.18s/it, deep_loss=0.0319, grad_norm=0.758, loss_final=1.58, loss_mean=1.56, l[[34m2025-10-03 23:56:59[39m] Step: 44, Training Logs: loss_final: 1.556452, loss_mean: 1.540380, proj_loss: -0.132271, loss_mean_cls: 0.116392, deep_loss: 0.031951, grad_norm: 0.704377
Steps:   0%| | 45/1000000 [00:55<326:55:39,  1.18s/it, deep_loss=0.032, grad_norm=0.704, loss_final=1.56, loss_mean=1.54, lo[[34m2025-10-03 23:57:01[39m] Step: 45, Training Logs: loss_final: 1.542624, loss_mean: 1.526685, proj_loss: -0.133199, loss_mean_cls: 0.116787, deep_loss: 0.032351, grad_norm: 0.936443
Steps:   0%| | 46/1000000 [00:56<325:56:18,  1.17s/it, deep_loss=0.0324, grad_norm=0.936, loss_final=1.54, loss_mean=1.53, l[[34m2025-10-03 23:57:02[39m] Step: 46, Training Logs: loss_final: 1.553499, loss_mean: 1.540522, proj_loss: -0.136116, loss_mean_cls: 0.116074, deep_loss: 0.033020, grad_norm: 1.172395
Steps:   0%| | 47/1000000 [00:57<327:06:06,  1.18s/it, deep_loss=0.033, grad_norm=1.17, loss_final=1.55, loss_mean=1.54, los[[34m2025-10-03 23:57:03[39m] Step: 47, Training Logs: loss_final: 1.524700, loss_mean: 1.512533, proj_loss: -0.136097, loss_mean_cls: 0.115781, deep_loss: 0.032483, grad_norm: 0.594672
Steps:   0%| | 48/1000000 [00:58<302:05:18,  1.09s/it, deep_loss=0.0325, grad_norm=0.595, loss_final=1.52, loss_mean=1.51, l[[34m2025-10-03 23:57:04[39m] Step: 48, Training Logs: loss_final: 1.534715, loss_mean: 1.525124, proj_loss: -0.138058, loss_mean_cls: 0.115779, deep_loss: 0.031869, grad_norm: 0.720464
Steps:   0%| | 49/1000000 [00:59<277:15:31,  1.00it/s, deep_loss=0.0319, grad_norm=0.72, loss_final=1.53, loss_mean=1.53, lo[[34m2025-10-03 23:57:05[39m] Step: 49, Training Logs: loss_final: 1.535623, loss_mean: 1.526733, proj_loss: -0.138876, loss_mean_cls: 0.116408, deep_loss: 0.031357, grad_norm: 1.048578
Steps:   0%| | 50/1000000 [00:59<260:30:24,  1.07it/s, deep_loss=0.0314, grad_norm=1.05, loss_final=1.54, loss_mean=1.53, lo[[34m2025-10-03 23:57:05[39m] Step: 50, Training Logs: loss_final: 1.541576, loss_mean: 1.532666, proj_loss: -0.139751, loss_mean_cls: 0.116019, deep_loss: 0.032641, grad_norm: 1.727470
Steps:   0%| | 51/1000000 [01:00<248:37:57,  1.12it/s, deep_loss=0.0326, grad_norm=1.73, loss_final=1.54, loss_mean=1.53, lo[[34m2025-10-03 23:57:06[39m] Step: 51, Training Logs: loss_final: 1.526954, loss_mean: 1.519844, proj_loss: -0.139691, loss_mean_cls: 0.115795, deep_loss: 0.031007, grad_norm: 0.736862
Steps:   0%| | 52/1000000 [01:01<240:43:10,  1.15it/s, deep_loss=0.031, grad_norm=0.737, loss_final=1.53, loss_mean=1.52, lo[[34m2025-10-03 23:57:07[39m] Step: 52, Training Logs: loss_final: 1.522411, loss_mean: 1.517837, proj_loss: -0.142827, loss_mean_cls: 0.115317, deep_loss: 0.032085, grad_norm: 2.321333
Steps:   0%| | 53/1000000 [01:02<234:44:46,  1.18it/s, deep_loss=0.0321, grad_norm=2.32, loss_final=1.52, loss_mean=1.52, lo[[34m2025-10-03 23:57:08[39m] Step: 53, Training Logs: loss_final: 1.528522, loss_mean: 1.523429, proj_loss: -0.141923, loss_mean_cls: 0.115068, deep_loss: 0.031949, grad_norm: 2.179204
Steps:   0%| | 54/1000000 [01:03<247:39:57,  1.12it/s, deep_loss=0.0319, grad_norm=2.18, loss_final=1.53, loss_mean=1.52, lo[[34m2025-10-03 23:57:09[39m] Step: 54, Training Logs: loss_final: 1.516810, loss_mean: 1.511703, proj_loss: -0.141782, loss_mean_cls: 0.115613, deep_loss: 0.031276, grad_norm: 0.745605
Steps:   0%| | 55/1000000 [01:04<272:26:43,  1.02it/s, deep_loss=0.0313, grad_norm=0.746, loss_final=1.52, loss_mean=1.51, l[[34m2025-10-03 23:57:10[39m] Step: 55, Training Logs: loss_final: 1.493713, loss_mean: 1.490762, proj_loss: -0.144253, loss_mean_cls: 0.115735, deep_loss: 0.031469, grad_norm: 1.587335
Steps:   0%| | 56/1000000 [01:05<288:56:55,  1.04s/it, deep_loss=0.0315, grad_norm=1.59, loss_final=1.49, loss_mean=1.49, lo[[34m2025-10-03 23:57:11[39m] Step: 56, Training Logs: loss_final: 1.480589, loss_mean: 1.477696, proj_loss: -0.144282, loss_mean_cls: 0.115040, deep_loss: 0.032135, grad_norm: 0.663576
Steps:   0%| | 57/1000000 [01:06<300:49:58,  1.08s/it, deep_loss=0.0321, grad_norm=0.664, loss_final=1.48, loss_mean=1.48, l[[34m2025-10-03 23:57:12[39m] Step: 57, Training Logs: loss_final: 1.509699, loss_mean: 1.508178, proj_loss: -0.145585, loss_mean_cls: 0.115396, deep_loss: 0.031710, grad_norm: 2.059987
Steps:   0%| | 58/1000000 [01:08<308:32:08,  1.11s/it, deep_loss=0.0317, grad_norm=2.06, loss_final=1.51, loss_mean=1.51, lo[[34m2025-10-03 23:57:14[39m] Step: 58, Training Logs: loss_final: 1.448789, loss_mean: 1.447078, proj_loss: -0.144859, loss_mean_cls: 0.115127, deep_loss: 0.031442, grad_norm: 0.828879
Steps:   0%| | 59/1000000 [01:09<314:21:39,  1.13s/it, deep_loss=0.0314, grad_norm=0.829, loss_final=1.45, loss_mean=1.45, l[[34m2025-10-03 23:57:15[39m] Step: 59, Training Logs: loss_final: 1.419547, loss_mean: 1.417690, proj_loss: -0.144037, loss_mean_cls: 0.115208, deep_loss: 0.030687, grad_norm: 0.828922
Steps:   0%| | 60/1000000 [01:10<318:41:08,  1.15s/it, deep_loss=0.0307, grad_norm=0.829, loss_final=1.42, loss_mean=1.42, l[[34m2025-10-03 23:57:16[39m] Step: 60, Training Logs: loss_final: 1.445580, loss_mean: 1.445961, proj_loss: -0.145697, loss_mean_cls: 0.114243, deep_loss: 0.031073, grad_norm: 1.472747
Steps:   0%| | 61/1000000 [01:11<321:12:41,  1.16s/it, deep_loss=0.0311, grad_norm=1.47, loss_final=1.45, loss_mean=1.45, lo[[34m2025-10-03 23:57:17[39m] Step: 61, Training Logs: loss_final: 1.473336, loss_mean: 1.474709, proj_loss: -0.147177, loss_mean_cls: 0.115304, deep_loss: 0.030500, grad_norm: 2.624000
Steps:   0%| | 62/1000000 [01:12<322:12:26,  1.16s/it, deep_loss=0.0305, grad_norm=2.62, loss_final=1.47, loss_mean=1.47, lo[[34m2025-10-03 23:57:18[39m] Step: 62, Training Logs: loss_final: 1.390192, loss_mean: 1.390908, proj_loss: -0.145978, loss_mean_cls: 0.114264, deep_loss: 0.030997, grad_norm: 0.592146
Steps:   0%| | 63/1000000 [01:13<324:34:35,  1.17s/it, deep_loss=0.031, grad_norm=0.592, loss_final=1.39, loss_mean=1.39, lo[[34m2025-10-03 23:57:19[39m] Step: 63, Training Logs: loss_final: 1.435668, loss_mean: 1.435140, proj_loss: -0.145679, loss_mean_cls: 0.115724, deep_loss: 0.030483, grad_norm: 2.247913
Steps:   0%| | 64/1000000 [01:15<324:36:39,  1.17s/it, deep_loss=0.0305, grad_norm=2.25, loss_final=1.44, loss_mean=1.44, lo[[34m2025-10-03 23:57:21[39m] Step: 64, Training Logs: loss_final: 1.377437, loss_mean: 1.377413, proj_loss: -0.145548, loss_mean_cls: 0.114757, deep_loss: 0.030814, grad_norm: 0.668074
Steps:   0%| | 65/1000000 [01:16<326:17:39,  1.17s/it, deep_loss=0.0308, grad_norm=0.668, loss_final=1.38, loss_mean=1.38, l[[34m2025-10-03 23:57:22[39m] Step: 65, Training Logs: loss_final: 1.461014, loss_mean: 1.462033, proj_loss: -0.147324, loss_mean_cls: 0.113329, deep_loss: 0.032976, grad_norm: 2.050485
Steps:   0%| | 66/1000000 [01:17<325:50:08,  1.17s/it, deep_loss=0.033, grad_norm=2.05, loss_final=1.46, loss_mean=1.46, los[[34m2025-10-03 23:57:23[39m] Step: 66, Training Logs: loss_final: 1.405724, loss_mean: 1.406946, proj_loss: -0.146336, loss_mean_cls: 0.114093, deep_loss: 0.031022, grad_norm: 1.424176
Steps:   0%| | 67/1000000 [01:18<326:34:48,  1.18s/it, deep_loss=0.031, grad_norm=1.42, loss_final=1.41, loss_mean=1.41, los[[34m2025-10-03 23:57:24[39m] Step: 67, Training Logs: loss_final: 1.374719, loss_mean: 1.377232, proj_loss: -0.147798, loss_mean_cls: 0.114253, deep_loss: 0.031032, grad_norm: 1.013231
Steps:   0%| | 68/1000000 [01:19<326:01:27,  1.17s/it, deep_loss=0.031, grad_norm=1.01, loss_final=1.37, loss_mean=1.38, los[[34m2025-10-03 23:57:25[39m] Step: 68, Training Logs: loss_final: 1.406424, loss_mean: 1.408510, proj_loss: -0.147273, loss_mean_cls: 0.113322, deep_loss: 0.031865, grad_norm: 1.811914
Steps:   0%| | 69/1000000 [01:20<326:13:05,  1.17s/it, deep_loss=0.0319, grad_norm=1.81, loss_final=1.41, loss_mean=1.41, lo[[34m2025-10-03 23:57:26[39m] Step: 69, Training Logs: loss_final: 1.383924, loss_mean: 1.384158, proj_loss: -0.145830, loss_mean_cls: 0.114079, deep_loss: 0.031517, grad_norm: 1.115738
Steps:   0%| | 70/1000000 [01:22<325:58:55,  1.17s/it, deep_loss=0.0315, grad_norm=1.12, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:57:28[39m] Step: 70, Training Logs: loss_final: 1.362709, loss_mean: 1.367818, proj_loss: -0.148725, loss_mean_cls: 0.113404, deep_loss: 0.030213, grad_norm: 1.190304
Steps:   0%| | 71/1000000 [01:23<326:42:29,  1.18s/it, deep_loss=0.0302, grad_norm=1.19, loss_final=1.36, loss_mean=1.37, lo[[34m2025-10-03 23:57:29[39m] Step: 71, Training Logs: loss_final: 1.427608, loss_mean: 1.430869, proj_loss: -0.148418, loss_mean_cls: 0.113308, deep_loss: 0.031848, grad_norm: 1.288794
Steps:   0%| | 72/1000000 [01:24<326:08:55,  1.17s/it, deep_loss=0.0318, grad_norm=1.29, loss_final=1.43, loss_mean=1.43, lo[[34m2025-10-03 23:57:30[39m] Step: 72, Training Logs: loss_final: 1.367123, loss_mean: 1.371226, proj_loss: -0.148376, loss_mean_cls: 0.113169, deep_loss: 0.031104, grad_norm: 1.171066
Steps:   0%| | 73/1000000 [01:25<326:15:18,  1.17s/it, deep_loss=0.0311, grad_norm=1.17, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:57:31[39m] Step: 73, Training Logs: loss_final: 1.371788, loss_mean: 1.374960, proj_loss: -0.147484, loss_mean_cls: 0.113780, deep_loss: 0.030532, grad_norm: 0.703961
Steps:   0%| | 74/1000000 [01:26<324:35:48,  1.17s/it, deep_loss=0.0305, grad_norm=0.704, loss_final=1.37, loss_mean=1.37, l[[34m2025-10-03 23:57:32[39m] Step: 74, Training Logs: loss_final: 1.384730, loss_mean: 1.388303, proj_loss: -0.148338, loss_mean_cls: 0.113315, deep_loss: 0.031450, grad_norm: 1.103655
Steps:   0%| | 75/1000000 [01:28<325:30:50,  1.17s/it, deep_loss=0.0314, grad_norm=1.1, loss_final=1.38, loss_mean=1.39, los[[34m2025-10-03 23:57:34[39m] Step: 75, Training Logs: loss_final: 1.367141, loss_mean: 1.369300, proj_loss: -0.147217, loss_mean_cls: 0.114179, deep_loss: 0.030878, grad_norm: 1.100881
Steps:   0%| | 76/1000000 [01:29<325:39:11,  1.17s/it, deep_loss=0.0309, grad_norm=1.1, loss_final=1.37, loss_mean=1.37, los[[34m2025-10-03 23:57:35[39m] Step: 76, Training Logs: loss_final: 1.366411, loss_mean: 1.370227, proj_loss: -0.146990, loss_mean_cls: 0.113738, deep_loss: 0.029436, grad_norm: 0.933985
Steps:   0%| | 77/1000000 [01:30<327:36:36,  1.18s/it, deep_loss=0.0294, grad_norm=0.934, loss_final=1.37, loss_mean=1.37, l[[34m2025-10-03 23:57:36[39m] Step: 77, Training Logs: loss_final: 1.356328, loss_mean: 1.359780, proj_loss: -0.146771, loss_mean_cls: 0.113466, deep_loss: 0.029852, grad_norm: 1.082046
Steps:   0%| | 78/1000000 [01:31<328:16:30,  1.18s/it, deep_loss=0.0299, grad_norm=1.08, loss_final=1.36, loss_mean=1.36, lo[[34m2025-10-03 23:57:37[39m] Step: 78, Training Logs: loss_final: 1.360895, loss_mean: 1.365696, proj_loss: -0.148422, loss_mean_cls: 0.113016, deep_loss: 0.030604, grad_norm: 0.817053
Steps:   0%| | 79/1000000 [01:32<328:32:59,  1.18s/it, deep_loss=0.0306, grad_norm=0.817, loss_final=1.36, loss_mean=1.37, l[[34m2025-10-03 23:57:38[39m] Step: 79, Training Logs: loss_final: 1.369056, loss_mean: 1.372239, proj_loss: -0.147313, loss_mean_cls: 0.113260, deep_loss: 0.030870, grad_norm: 1.530940
Steps:   0%| | 80/1000000 [01:33<328:23:17,  1.18s/it, deep_loss=0.0309, grad_norm=1.53, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:57:39[39m] Step: 80, Training Logs: loss_final: 1.384825, loss_mean: 1.388645, proj_loss: -0.147505, loss_mean_cls: 0.112891, deep_loss: 0.030794, grad_norm: 2.823335
Steps:   0%| | 81/1000000 [01:35<321:38:55,  1.16s/it, deep_loss=0.0308, grad_norm=2.82, loss_final=1.38, loss_mean=1.39, lo[[34m2025-10-03 23:57:41[39m] Step: 81, Training Logs: loss_final: 1.440961, loss_mean: 1.444645, proj_loss: -0.147700, loss_mean_cls: 0.112266, deep_loss: 0.031750, grad_norm: 5.418567
Steps:   0%| | 82/1000000 [01:35<290:51:47,  1.05s/it, deep_loss=0.0318, grad_norm=5.42, loss_final=1.44, loss_mean=1.44, lo[[34m2025-10-03 23:57:41[39m] Step: 82, Training Logs: loss_final: 1.423729, loss_mean: 1.426088, proj_loss: -0.147246, loss_mean_cls: 0.112825, deep_loss: 0.032063, grad_norm: 4.602059
Steps:   0%| | 83/1000000 [01:36<269:19:20,  1.03it/s, deep_loss=0.0321, grad_norm=4.6, loss_final=1.42, loss_mean=1.43, los[[34m2025-10-03 23:57:42[39m] Step: 83, Training Logs: loss_final: 1.461623, loss_mean: 1.465880, proj_loss: -0.149582, loss_mean_cls: 0.112458, deep_loss: 0.032867, grad_norm: 5.929204
Steps:   0%| | 84/1000000 [01:37<255:39:00,  1.09it/s, deep_loss=0.0329, grad_norm=5.93, loss_final=1.46, loss_mean=1.47, lo[[34m2025-10-03 23:57:43[39m] Step: 84, Training Logs: loss_final: 1.382555, loss_mean: 1.384605, proj_loss: -0.145112, loss_mean_cls: 0.112559, deep_loss: 0.030504, grad_norm: 3.733061
Steps:   0%| | 85/1000000 [01:38<274:50:57,  1.01it/s, deep_loss=0.0305, grad_norm=3.73, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:57:44[39m] Step: 85, Training Logs: loss_final: 1.403642, loss_mean: 1.406309, proj_loss: -0.145545, loss_mean_cls: 0.112321, deep_loss: 0.030557, grad_norm: 5.205406
Steps:   0%| | 86/1000000 [01:39<291:16:19,  1.05s/it, deep_loss=0.0306, grad_norm=5.21, loss_final=1.4, loss_mean=1.41, los[[34m2025-10-03 23:57:45[39m] Step: 86, Training Logs: loss_final: 1.439991, loss_mean: 1.441501, proj_loss: -0.146265, loss_mean_cls: 0.113149, deep_loss: 0.031606, grad_norm: 6.494482
Steps:   0%| | 87/1000000 [01:40<302:53:53,  1.09s/it, deep_loss=0.0316, grad_norm=6.49, loss_final=1.44, loss_mean=1.44, lo[[34m2025-10-03 23:57:46[39m] Step: 87, Training Logs: loss_final: 1.443421, loss_mean: 1.446446, proj_loss: -0.146703, loss_mean_cls: 0.112418, deep_loss: 0.031260, grad_norm: 4.951910
Steps:   0%| | 88/1000000 [01:42<310:20:54,  1.12s/it, deep_loss=0.0313, grad_norm=4.95, loss_final=1.44, loss_mean=1.45, lo[[34m2025-10-03 23:57:48[39m] Step: 88, Training Logs: loss_final: 1.417078, loss_mean: 1.420932, proj_loss: -0.146790, loss_mean_cls: 0.112228, deep_loss: 0.030709, grad_norm: 4.037041
Steps:   0%| | 89/1000000 [01:43<314:09:39,  1.13s/it, deep_loss=0.0307, grad_norm=4.04, loss_final=1.42, loss_mean=1.42, lo[[34m2025-10-03 23:57:49[39m] Step: 89, Training Logs: loss_final: 1.387619, loss_mean: 1.391297, proj_loss: -0.146852, loss_mean_cls: 0.112696, deep_loss: 0.030478, grad_norm: 4.455070
Steps:   0%| | 90/1000000 [01:44<316:49:00,  1.14s/it, deep_loss=0.0305, grad_norm=4.46, loss_final=1.39, loss_mean=1.39, lo[[34m2025-10-03 23:57:50[39m] Step: 90, Training Logs: loss_final: 1.400875, loss_mean: 1.405630, proj_loss: -0.148256, loss_mean_cls: 0.111702, deep_loss: 0.031799, grad_norm: 4.740033
Steps:   0%| | 91/1000000 [01:45<319:57:07,  1.15s/it, deep_loss=0.0318, grad_norm=4.74, loss_final=1.4, loss_mean=1.41, los[[34m2025-10-03 23:57:51[39m] Step: 91, Training Logs: loss_final: 1.392017, loss_mean: 1.395713, proj_loss: -0.147516, loss_mean_cls: 0.112161, deep_loss: 0.031659, grad_norm: 4.008111
Steps:   0%| | 92/1000000 [01:46<321:49:38,  1.16s/it, deep_loss=0.0317, grad_norm=4.01, loss_final=1.39, loss_mean=1.4, los[[34m2025-10-03 23:57:52[39m] Step: 92, Training Logs: loss_final: 1.368492, loss_mean: 1.373436, proj_loss: -0.148698, loss_mean_cls: 0.112450, deep_loss: 0.031304, grad_norm: 3.328374
Steps:   0%| | 93/1000000 [01:47<322:39:54,  1.16s/it, deep_loss=0.0313, grad_norm=3.33, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:57:53[39m] Step: 93, Training Logs: loss_final: 1.432232, loss_mean: 1.435383, proj_loss: -0.145895, loss_mean_cls: 0.110843, deep_loss: 0.031901, grad_norm: 6.071809
Steps:   0%| | 94/1000000 [01:49<325:20:33,  1.17s/it, deep_loss=0.0319, grad_norm=6.07, loss_final=1.43, loss_mean=1.44, lo[[34m2025-10-03 23:57:55[39m] Step: 94, Training Logs: loss_final: 1.411152, loss_mean: 1.414548, proj_loss: -0.147499, loss_mean_cls: 0.112322, deep_loss: 0.031781, grad_norm: 6.073527
Steps:   0%| | 95/1000000 [01:50<324:37:32,  1.17s/it, deep_loss=0.0318, grad_norm=6.07, loss_final=1.41, loss_mean=1.41, lo[[34m2025-10-03 23:57:56[39m] Step: 95, Training Logs: loss_final: 1.390439, loss_mean: 1.394565, proj_loss: -0.146051, loss_mean_cls: 0.111306, deep_loss: 0.030620, grad_norm: 4.706511
Steps:   0%| | 96/1000000 [01:51<325:02:44,  1.17s/it, deep_loss=0.0306, grad_norm=4.71, loss_final=1.39, loss_mean=1.39, lo[[34m2025-10-03 23:57:57[39m] Step: 96, Training Logs: loss_final: 1.407484, loss_mean: 1.410173, proj_loss: -0.145999, loss_mean_cls: 0.111606, deep_loss: 0.031704, grad_norm: 4.277789
Steps:   0%| | 97/1000000 [01:52<325:44:36,  1.17s/it, deep_loss=0.0317, grad_norm=4.28, loss_final=1.41, loss_mean=1.41, lo[[34m2025-10-03 23:57:58[39m] Step: 97, Training Logs: loss_final: 1.405840, loss_mean: 1.409546, proj_loss: -0.147118, loss_mean_cls: 0.111485, deep_loss: 0.031927, grad_norm: 4.165754
Steps:   0%| | 98/1000000 [01:53<325:52:04,  1.17s/it, deep_loss=0.0319, grad_norm=4.17, loss_final=1.41, loss_mean=1.41, lo[[34m2025-10-03 23:57:59[39m] Step: 98, Training Logs: loss_final: 1.381798, loss_mean: 1.384669, proj_loss: -0.145776, loss_mean_cls: 0.111808, deep_loss: 0.031096, grad_norm: 4.558535
Steps:   0%| | 99/1000000 [01:55<326:31:30,  1.18s/it, deep_loss=0.0311, grad_norm=4.56, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:58:01[39m] Step: 99, Training Logs: loss_final: 1.395613, loss_mean: 1.399707, proj_loss: -0.146257, loss_mean_cls: 0.111265, deep_loss: 0.030898, grad_norm: 4.266659
Steps:   0%| | 100/1000000 [01:56<325:57:53,  1.17s/it, deep_loss=0.0309, grad_norm=4.27, loss_final=1.4, loss_mean=1.4, los[[34m2025-10-03 23:58:02[39m] Step: 100, Training Logs: loss_final: 1.388451, loss_mean: 1.391130, proj_loss: -0.145840, loss_mean_cls: 0.112046, deep_loss: 0.031116, grad_norm: 3.422319
Steps:   0%| | 101/1000000 [01:57<326:44:34,  1.18s/it, deep_loss=0.0311, grad_norm=3.42, loss_final=1.39, loss_mean=1.39, l[[34m2025-10-03 23:58:03[39m] Step: 101, Training Logs: loss_final: 1.377474, loss_mean: 1.379470, proj_loss: -0.144481, loss_mean_cls: 0.111824, deep_loss: 0.030660, grad_norm: 3.203753
Steps:   0%| | 101/1000000 [01:57<326:44:34,  1.18s/it, deep_loss=0.0307, grad_norm=3.2, loss_final=1.38, loss_mean=1.38, lo
Steps:   0%| | 103/1000000 [01:59<327:50:57,  1.18s/it, deep_loss=0.0305, grad_norm=3.83, loss_final=1.38, loss_mean=1.38, l[[34m2025-10-03 23:58:05[39m] Step: 103, Training Logs: loss_final: 1.394678, loss_mean: 1.399425, proj_loss: -0.148023, loss_mean_cls: 0.111715, deep_loss: 0.031562, grad_norm: 3.899208
Steps:   0%| | 103/1000000 [01:59<327:50:57,  1.18s/it, deep_loss=0.0316, grad_norm=3.9, loss_final=1.39, loss_mean=1.4, los
Steps:   0%| | 105/1000000 [02:02<327:22:02,  1.18s/it, deep_loss=0.0312, grad_norm=3.7, loss_final=1.39, loss_mean=1.39, lo[[34m2025-10-03 23:58:08[39m] Step: 105, Training Logs: loss_final: 1.375609, loss_mean: 1.378464, proj_loss: -0.145318, loss_mean_cls: 0.111275, deep_loss: 0.031188, grad_norm: 2.582890
Steps:   0%| | 105/1000000 [02:02<327:22:02,  1.18s/it, deep_loss=0.0312, grad_norm=2.58, loss_final=1.38, loss_mean=1.38, l
Steps:   0%| | 107/1000000 [02:04<326:25:59,  1.18s/it, deep_loss=0.031, grad_norm=3.32, loss_final=1.37, loss_mean=1.38, lo[[34m2025-10-03 23:58:10[39m] Step: 107, Training Logs: loss_final: 1.376047, loss_mean: 1.378537, proj_loss: -0.144855, loss_mean_cls: 0.111290, deep_loss: 0.031076, grad_norm: 4.864861
Steps:   0%| | 107/1000000 [02:04<326:25:59,  1.18s/it, deep_loss=0.0311, grad_norm=4.86, loss_final=1.38, loss_mean=1.38, l
Steps:   0%| | 108/1000000 [02:05<325:14:28,  1.17s/it, deep_loss=0.0302, grad_norm=4.79, loss_final=1.37, loss_mean=1.37, l[[34m2025-10-03 23:58:10[39m] Step: 107, Training Logs: loss_final: 1.376047, loss_mean: 1.378537, proj_loss: -0.144855, loss_mean_cls: 0.111290, deep_loss: 0.031076, grad_norm: 4.864861
Steps:   0%| | 110/1000000 [02:08<324:39:45,  1.17s/it, deep_loss=0.0326, grad_norm=11.2, loss_final=1.49, loss_mean=1.49, l[[34m2025-10-03 23:58:12[39m] Step: 109, Training Logs: loss_final: 1.420607, loss_mean: 1.420973, proj_loss: -0.144675, loss_mean_cls: 0.111140, deep_loss: 0.033168, grad_norm: 5.973158
Steps:   0%| | 112/1000000 [02:10<308:44:14,  1.11s/it, deep_loss=0.0326, grad_norm=6.65, loss_final=1.44, loss_mean=1.44, l[[34m2025-10-03 23:58:15[39m] Step: 111, Training Logs: loss_final: 1.412373, loss_mean: 1.411072, proj_loss: -0.143300, loss_mean_cls: 0.112307, deep_loss: 0.032294, grad_norm: 6.431697
Steps:   0%| | 115/1000000 [02:12<250:29:35,  1.11it/s, deep_loss=0.0321, grad_norm=6.3, loss_final=1.41, loss_mean=1.4, los[[34m2025-10-03 23:58:18[39m] Step: 115, Training Logs: loss_final: 1.419509, loss_mean: 1.414680, proj_loss: -0.138806, loss_mean_cls: 0.111954, deep_loss: 0.031682, grad_norm: 7.337322
Steps:   0%| | 115/1000000 [02:12<250:29:35,  1.11it/s, deep_loss=0.0317, grad_norm=7.34, loss_final=1.42, loss_mean=1.41, l
Steps:   0%| | 117/1000000 [02:14<271:18:26,  1.02it/s, deep_loss=0.0326, grad_norm=6.65, loss_final=1.44, loss_mean=1.43, l[[34m2025-10-03 23:58:20[39m] Step: 117, Training Logs: loss_final: 1.446118, loss_mean: 1.440975, proj_loss: -0.139143, loss_mean_cls: 0.111480, deep_loss: 0.032805, grad_norm: 8.565838
Steps:   0%| | 117/1000000 [02:14<271:18:26,  1.02it/s, deep_loss=0.0328, grad_norm=8.57, loss_final=1.45, loss_mean=1.44, l
Steps:   0%| | 118/1000000 [02:15<287:14:21,  1.03s/it, deep_loss=0.0342, grad_norm=12.4, loss_final=1.49, loss_mean=1.48, l[[34m2025-10-03 23:58:20[39m] Step: 117, Training Logs: loss_final: 1.446118, loss_mean: 1.440975, proj_loss: -0.139143, loss_mean_cls: 0.111480, deep_loss: 0.032805, grad_norm: 8.565838
Steps:   0%| | 120/1000000 [02:18<305:55:40,  1.10s/it, deep_loss=0.0329, grad_norm=10.4, loss_final=1.48, loss_mean=1.47, l[[34m2025-10-03 23:58:22[39m] Step: 119, Training Logs: loss_final: 1.439624, loss_mean: 1.432233, proj_loss: -0.136944, loss_mean_cls: 0.112559, deep_loss: 0.031777, grad_norm: 8.194375
Steps:   0%| | 122/1000000 [02:20<316:56:21,  1.14s/it, deep_loss=0.033, grad_norm=9.19, loss_final=1.41, loss_mean=1.4, los[[34m2025-10-03 23:58:25[39m] Step: 121, Training Logs: loss_final: 1.441338, loss_mean: 1.434832, proj_loss: -0.137485, loss_mean_cls: 0.111407, deep_loss: 0.032583, grad_norm: 7.180409
Steps:   0%| | 123/1000000 [02:21<319:07:44,  1.15s/it, deep_loss=0.033, grad_norm=9.19, loss_final=1.41, loss_mean=1.4, los[[34m2025-10-03 23:58:27[39m] Step: 123, Training Logs: loss_final: 1.430111, loss_mean: 1.423921, proj_loss: -0.138187, loss_mean_cls: 0.111753, deep_loss: 0.032624, grad_norm: 7.128738
Steps:   0%| | 125/1000000 [02:23<322:53:22,  1.16s/it, deep_loss=0.0325, grad_norm=6.5, loss_final=1.42, loss_mean=1.41, lo[[34m2025-10-03 23:58:29[39m] Step: 125, Training Logs: loss_final: 1.454381, loss_mean: 1.446456, proj_loss: -0.137341, loss_mean_cls: 0.112470, deep_loss: 0.032796, grad_norm: 9.843773
Steps:   0%| | 127/1000000 [02:26<324:40:21,  1.17s/it, deep_loss=0.0321, grad_norm=10.5, loss_final=1.45, loss_mean=1.44, l[[34m2025-10-03 23:58:32[39m] Step: 127, Training Logs: loss_final: 1.422576, loss_mean: 1.414071, proj_loss: -0.136217, loss_mean_cls: 0.111604, deep_loss: 0.033118, grad_norm: 7.541412
Steps:   0%| | 129/1000000 [02:28<326:54:52,  1.18s/it, deep_loss=0.0319, grad_norm=7.04, loss_final=1.4, loss_mean=1.4, los[[34m2025-10-03 23:58:32[39m] Step: 127, Training Logs: loss_final: 1.422576, loss_mean: 1.414071, proj_loss: -0.136217, loss_mean_cls: 0.111604, deep_loss: 0.033118, grad_norm: 7.541412
Steps:   0%| | 130/1000000 [02:29<325:49:42,  1.17s/it, deep_loss=0.0327, grad_norm=7.68, loss_final=1.43, loss_mean=1.43, l[[34m2025-10-03 23:58:34[39m] Step: 129, Training Logs: loss_final: 1.456673, loss_mean: 1.447665, proj_loss: -0.134932, loss_mean_cls: 0.111787, deep_loss: 0.032152, grad_norm: 11.411099
Steps:   0%| | 132/1000000 [02:32<326:41:55,  1.18s/it, deep_loss=0.0307, grad_norm=6.73, loss_final=1.4, loss_mean=1.39, lo[[34m2025-10-03 23:58:36[39m] Step: 131, Training Logs: loss_final: 1.435496, loss_mean: 1.423670, proj_loss: -0.133455, loss_mean_cls: 0.112058, deep_loss: 0.033223, grad_norm: 8.8745469
Steps:   0%| | 134/1000000 [02:34<325:53:14,  1.17s/it, deep_loss=0.0323, grad_norm=6.23, loss_final=1.43, loss_mean=1.42, l[[34m2025-10-03 23:58:39[39m] Step: 133, Training Logs: loss_final: 1.426845, loss_mean: 1.415861, proj_loss: -0.133244, loss_mean_cls: 0.112302, deep_loss: 0.031927, grad_norm: 7.8677239
Steps:   0%| | 135/1000000 [02:35<327:00:26,  1.18s/it, deep_loss=0.0323, grad_norm=6.23, loss_final=1.43, loss_mean=1.42, l[[34m2025-10-03 23:58:41[39m] Step: 135, Training Logs: loss_final: 1.421074, loss_mean: 1.410875, proj_loss: -0.133535, loss_mean_cls: 0.111781, deep_loss: 0.031953, grad_norm: 6.2005089
Steps:   0%| | 137/1000000 [02:38<326:09:43,  1.17s/it, deep_loss=0.0312, grad_norm=5.57, loss_final=1.41, loss_mean=1.39, l[[34m2025-10-03 23:58:44[39m] Step: 137, Training Logs: loss_final: 1.396626, loss_mean: 1.383763, proj_loss: -0.131089, loss_mean_cls: 0.112886, deep_loss: 0.031066, grad_norm: 5.4779999
Steps:   0%| | 138/1000000 [02:39<326:58:45,  1.18s/it, deep_loss=0.0316, grad_norm=5.73, loss_final=1.38, loss_mean=1.37, l[[34m2025-10-03 23:58:44[39m] Step: 137, Training Logs: loss_final: 1.396626, loss_mean: 1.383763, proj_loss: -0.131089, loss_mean_cls: 0.112886, deep_loss: 0.031066, grad_norm: 5.4779999
Steps:   0%| | 140/1000000 [02:42<352:29:11,  1.27s/it, deep_loss=0.0327, grad_norm=7.4, loss_final=1.42, loss_mean=1.41, lo[[34m2025-10-03 23:58:46[39m] Step: 139, Training Logs: loss_final: 1.377941, loss_mean: 1.366252, proj_loss: -0.132125, loss_mean_cls: 0.112426, deep_loss: 0.031389, grad_norm: 5.9326119
Steps:   0%| | 142/1000000 [02:44<338:37:34,  1.22s/it, deep_loss=0.0315, grad_norm=8.7, loss_final=1.42, loss_mean=1.41, lo[[34m2025-10-03 23:58:49[39m] Step: 141, Training Logs: loss_final: 1.402072, loss_mean: 1.389329, proj_loss: -0.132399, loss_mean_cls: 0.112886, deep_loss: 0.032256, grad_norm: 7.3343389
Steps:   0%| | 144/1000000 [02:46<293:30:25,  1.06s/it, deep_loss=0.0311, grad_norm=7.16, loss_final=1.38, loss_mean=1.36, l[[34m2025-10-03 23:58:51[39m] Step: 143, Training Logs: loss_final: 1.409198, loss_mean: 1.398161, proj_loss: -0.133121, loss_mean_cls: 0.112000, deep_loss: 0.032159, grad_norm: 10.367977
Steps:   0%| | 146/1000000 [02:47<255:32:15,  1.09it/s, deep_loss=0.0324, grad_norm=8.87, loss_final=1.45, loss_mean=1.43, l[[34m2025-10-03 23:58:52[39m] Step: 145, Training Logs: loss_final: 1.408830, loss_mean: 1.394783, proj_loss: -0.130293, loss_mean_cls: 0.113039, deep_loss: 0.031302, grad_norm: 7.0993747
Steps:   0%| | 148/1000000 [02:50<284:29:05,  1.02s/it, deep_loss=0.0325, grad_norm=9.86, loss_final=1.44, loss_mean=1.43, l[[34m2025-10-03 23:58:54[39m] Step: 147, Training Logs: loss_final: 1.401962, loss_mean: 1.387802, proj_loss: -0.129234, loss_mean_cls: 0.112444, deep_loss: 0.030950, grad_norm: 5.2155837
Steps:   0%| | 150/1000000 [02:52<306:57:19,  1.11s/it, deep_loss=0.0316, grad_norm=10.4, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:58:57[39m] Step: 149, Training Logs: loss_final: 1.386958, loss_mean: 1.371302, proj_loss: -0.127526, loss_mean_cls: 0.112432, deep_loss: 0.030749, grad_norm: 6.2370937
Steps:   0%| | 151/1000000 [02:53<313:00:33,  1.13s/it, deep_loss=0.0316, grad_norm=10.4, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:58:59[39m] Step: 151, Training Logs: loss_final: 1.413008, loss_mean: 1.396850, proj_loss: -0.128073, loss_mean_cls: 0.112050, deep_loss: 0.032181, grad_norm: 7.1898827
Steps:   0%| | 153/1000000 [02:55<319:23:30,  1.15s/it, deep_loss=0.0314, grad_norm=8.95, loss_final=1.41, loss_mean=1.4, lo[[34m2025-10-03 23:59:01[39m] Step: 153, Training Logs: loss_final: 1.406703, loss_mean: 1.390897, proj_loss: -0.128146, loss_mean_cls: 0.112557, deep_loss: 0.031395, grad_norm: 7.3476797
Steps:   0%| | 155/1000000 [02:58<323:11:57,  1.16s/it, deep_loss=0.0314, grad_norm=6.46, loss_final=1.41, loss_mean=1.39, l[[34m2025-10-03 23:59:04[39m] Step: 155, Training Logs: loss_final: 1.410531, loss_mean: 1.393546, proj_loss: -0.125720, loss_mean_cls: 0.111791, deep_loss: 0.030914, grad_norm: 7.2276127
Steps:   0%| | 157/1000000 [03:00<324:27:53,  1.17s/it, deep_loss=0.0297, grad_norm=4.46, loss_final=1.36, loss_mean=1.34, l[[34m2025-10-03 23:59:06[39m] Step: 157, Training Logs: loss_final: 1.410842, loss_mean: 1.391657, proj_loss: -0.123715, loss_mean_cls: 0.111946, deep_loss: 0.030954, grad_norm: 7.8578987
Steps:   0%| | 158/1000000 [03:01<324:54:45,  1.17s/it, deep_loss=0.0317, grad_norm=6.56, loss_final=1.42, loss_mean=1.39, l[[34m2025-10-03 23:59:06[39m] Step: 157, Training Logs: loss_final: 1.410842, loss_mean: 1.391657, proj_loss: -0.123715, loss_mean_cls: 0.111946, deep_loss: 0.030954, grad_norm: 7.8578987
Steps:   0%| | 160/1000000 [03:04<323:53:59,  1.17s/it, deep_loss=0.0316, grad_norm=8.21, loss_final=1.41, loss_mean=1.39, l[[34m2025-10-03 23:59:08[39m] Step: 159, Training Logs: loss_final: 1.384148, loss_mean: 1.362717, proj_loss: -0.122211, loss_mean_cls: 0.112500, deep_loss: 0.031142, grad_norm: 6.4066527
Steps:   0%| | 162/1000000 [03:06<325:03:16,  1.17s/it, deep_loss=0.0312, grad_norm=6.25, loss_final=1.4, loss_mean=1.37, lo[[34m2025-10-03 23:59:11[39m] Step: 161, Training Logs: loss_final: 1.381868, loss_mean: 1.356239, proj_loss: -0.117437, loss_mean_cls: 0.112438, deep_loss: 0.030627, grad_norm: 5.4195717
Steps:   0%| | 163/1000000 [03:07<325:43:02,  1.17s/it, deep_loss=0.0312, grad_norm=6.25, loss_final=1.4, loss_mean=1.37, lo[[34m2025-10-03 23:59:13[39m] Step: 163, Training Logs: loss_final: 1.386840, loss_mean: 1.361463, proj_loss: -0.117456, loss_mean_cls: 0.112219, deep_loss: 0.030614, grad_norm: 5.4869727
Steps:   0%| | 165/1000000 [03:09<325:34:06,  1.17s/it, deep_loss=0.03, grad_norm=4.79, loss_final=1.36, loss_mean=1.33, los[[34m2025-10-03 23:59:15[39m] Step: 165, Training Logs: loss_final: 1.424311, loss_mean: 1.393166, proj_loss: -0.113733, loss_mean_cls: 0.112744, deep_loss: 0.032134, grad_norm: 6.5139777
Steps:   0%| | 167/1000000 [03:12<326:46:29,  1.18s/it, deep_loss=0.0303, grad_norm=5.77, loss_final=1.38, loss_mean=1.35, l[[34m2025-10-03 23:59:18[39m] Step: 167, Training Logs: loss_final: 1.391214, loss_mean: 1.357184, proj_loss: -0.109545, loss_mean_cls: 0.112940, deep_loss: 0.030635, grad_norm: 5.7306297
Steps:   0%| | 169/1000000 [03:14<326:34:26,  1.18s/it, deep_loss=0.0302, grad_norm=4.46, loss_final=1.37, loss_mean=1.33, l[[34m2025-10-03 23:59:20[39m] Step: 169, Training Logs: loss_final: 1.396361, loss_mean: 1.359473, proj_loss: -0.107222, loss_mean_cls: 0.112657, deep_loss: 0.031453, grad_norm: 6.8473637
Steps:   0%| | 170/1000000 [03:15<326:47:40,  1.18s/it, deep_loss=0.0316, grad_norm=5.91, loss_final=1.4, loss_mean=1.36, lo[[34m2025-10-03 23:59:20[39m] Step: 169, Training Logs: loss_final: 1.396361, loss_mean: 1.359473, proj_loss: -0.107222, loss_mean_cls: 0.112657, deep_loss: 0.031453, grad_norm: 6.8473637
Steps:   0%| | 172/1000000 [03:18<327:17:44,  1.18s/it, deep_loss=0.0303, grad_norm=6.25, loss_final=1.38, loss_mean=1.34, l[[34m2025-10-03 23:59:22[39m] Step: 171, Training Logs: loss_final: 1.407154, loss_mean: 1.367088, proj_loss: -0.104075, loss_mean_cls: 0.112391, deep_loss: 0.031750, grad_norm: 6.3617537
Steps:   0%| | 174/1000000 [03:20<319:13:03,  1.15s/it, deep_loss=0.0304, grad_norm=6.86, loss_final=1.39, loss_mean=1.35, l[[34m2025-10-03 23:59:25[39m] Step: 173, Training Logs: loss_final: 1.397784, loss_mean: 1.355842, proj_loss: -0.102051, loss_mean_cls: 0.112696, deep_loss: 0.031297, grad_norm: 4.5291477
Steps:   0%| | 176/1000000 [03:22<267:50:40,  1.04it/s, deep_loss=0.0305, grad_norm=4.58, loss_final=1.39, loss_mean=1.34, l[[34m2025-10-03 23:59:27[39m] Step: 175, Training Logs: loss_final: 1.396561, loss_mean: 1.350042, proj_loss: -0.096812, loss_mean_cls: 0.112171, deep_loss: 0.031161, grad_norm: 6.0554277
Steps:   0%| | 178/1000000 [03:24<278:37:41,  1.00s/it, deep_loss=0.0315, grad_norm=6.98, loss_final=1.41, loss_mean=1.36, l[[34m2025-10-03 23:59:28[39m] Step: 177, Training Logs: loss_final: 1.407187, loss_mean: 1.358467, proj_loss: -0.094500, loss_mean_cls: 0.111844, deep_loss: 0.031377, grad_norm: 4.8723467
Steps:   0%| | 180/1000000 [03:26<302:50:57,  1.09s/it, deep_loss=0.0318, grad_norm=5.55, loss_final=1.41, loss_mean=1.35, l[[34m2025-10-03 23:59:31[39m] Step: 179, Training Logs: loss_final: 1.393180, loss_mean: 1.336624, proj_loss: -0.086836, loss_mean_cls: 0.112596, deep_loss: 0.030796, grad_norm: 6.0542247
Steps:   0%| | 182/1000000 [03:28<312:52:01,  1.13s/it, deep_loss=0.0305, grad_norm=6.83, loss_final=1.38, loss_mean=1.31, l[[34m2025-10-03 23:59:33[39m] Step: 181, Training Logs: loss_final: 1.410015, loss_mean: 1.345552, proj_loss: -0.080815, loss_mean_cls: 0.113632, deep_loss: 0.031646, grad_norm: 8.6399107
Steps:   0%| | 183/1000000 [03:29<315:32:39,  1.14s/it, deep_loss=0.0305, grad_norm=6.83, loss_final=1.38, loss_mean=1.31, l[[34m2025-10-03 23:59:35[39m] Step: 183, Training Logs: loss_final: 1.433541, loss_mean: 1.368788, proj_loss: -0.078893, loss_mean_cls: 0.112426, deep_loss: 0.031219, grad_norm: 9.1178727
Steps:   0%| | 185/1000000 [03:32<320:30:25,  1.15s/it, deep_loss=0.0314, grad_norm=9.19, loss_final=1.42, loss_mean=1.35, l[[34m2025-10-03 23:59:38[39m] Step: 185, Training Logs: loss_final: 1.393178, loss_mean: 1.326488, proj_loss: -0.076787, loss_mean_cls: 0.112381, deep_loss: 0.031096, grad_norm: 7.3027387
Steps:   0%| | 187/1000000 [03:34<322:02:35,  1.16s/it, deep_loss=0.0326, grad_norm=6.68, loss_final=1.45, loss_mean=1.38, l[[34m2025-10-03 23:59:40[39m] Step: 187, Training Logs: loss_final: 1.417116, loss_mean: 1.345590, proj_loss: -0.073379, loss_mean_cls: 0.112819, deep_loss: 0.032086, grad_norm: 9.6657097
Steps:   0%| | 188/1000000 [03:35<323:33:53,  1.17s/it, deep_loss=0.0331, grad_norm=11.9, loss_final=1.43, loss_mean=1.35, l[[34m2025-10-03 23:59:40[39m] Step: 187, Training Logs: loss_final: 1.417116, loss_mean: 1.345590, proj_loss: -0.073379, loss_mean_cls: 0.112819, deep_loss: 0.032086, grad_norm: 9.6657097
Steps:   0%| | 190/1000000 [03:38<324:32:10,  1.17s/it, deep_loss=0.0316, grad_norm=9.67, loss_final=1.45, loss_mean=1.37, l[[34m2025-10-03 23:59:42[39m] Step: 189, Training Logs: loss_final: 1.410329, loss_mean: 1.336902, proj_loss: -0.070178, loss_mean_cls: 0.112835, deep_loss: 0.030770, grad_norm: 7.6772667
Steps:   0%| | 192/1000000 [03:40<325:35:44,  1.17s/it, deep_loss=0.0313, grad_norm=12.9, loss_final=1.47, loss_mean=1.39, l[[34m2025-10-03 23:59:45[39m] Step: 191, Training Logs: loss_final: 1.457509, loss_mean: 1.372502, proj_loss: -0.060177, loss_mean_cls: 0.112643, deep_loss: 0.032541, grad_norm: 13.947860
Steps:   0%| | 194/1000000 [03:42<325:52:23,  1.17s/it, deep_loss=0.0329, grad_norm=8.98, loss_final=1.47, loss_mean=1.38, l[[34m2025-10-03 23:59:47[39m] Step: 193, Training Logs: loss_final: 1.446572, loss_mean: 1.366657, proj_loss: -0.064651, loss_mean_cls: 0.112145, deep_loss: 0.032422, grad_norm: 10.097665
Steps:   0%| | 195/1000000 [03:43<325:50:07,  1.17s/it, deep_loss=0.0329, grad_norm=8.98, loss_final=1.47, loss_mean=1.38, l[[34m2025-10-03 23:59:49[39m] Step: 195, Training Logs: loss_final: 1.465387, loss_mean: 1.384788, proj_loss: -0.063458, loss_mean_cls: 0.112423, deep_loss: 0.031634, grad_norm: 11.188003
Steps:   0%| | 197/1000000 [03:46<325:29:53,  1.17s/it, deep_loss=0.0331, grad_norm=7.7, loss_final=1.45, loss_mean=1.37, lo[[34m2025-10-03 23:59:52[39m] Step: 197, Training Logs: loss_final: 1.485050, loss_mean: 1.402481, proj_loss: -0.064406, loss_mean_cls: 0.111985, deep_loss: 0.034990, grad_norm: 11.089597
Steps:   0%| | 199/1000000 [03:48<325:55:22,  1.17s/it, deep_loss=0.0335, grad_norm=12.6, loss_final=1.5, loss_mean=1.42, lo[[34m2025-10-03 23:59:54[39m] Step: 199, Training Logs: loss_final: 1.462065, loss_mean: 1.378173, proj_loss: -0.061002, loss_mean_cls: 0.111897, deep_loss: 0.032997, grad_norm: 9.6093697
Steps:   0%| | 200/1000000 [03:49<326:05:16,  1.17s/it, deep_loss=0.0339, grad_norm=11.2, loss_final=1.51, loss_mean=1.42, l[[34m2025-10-03 23:59:54[39m] Step: 199, Training Logs: loss_final: 1.462065, loss_mean: 1.378173, proj_loss: -0.061002, loss_mean_cls: 0.111897, deep_loss: 0.032997, grad_norm: 9.6093697
Steps:   0%| | 202/1000000 [03:52<326:43:37,  1.18s/it, deep_loss=0.0342, grad_norm=9.72, loss_final=1.49, loss_mean=1.4, lo[[34m2025-10-03 23:59:56[39m] Step: 201, Training Logs: loss_final: 1.482757, loss_mean: 1.394521, proj_loss: -0.059321, loss_mean_cls: 0.112806, deep_loss: 0.034751, grad_norm: 6.7224707
Steps:   0%| | 204/1000000 [03:54<326:18:32,  1.17s/it, deep_loss=0.035, grad_norm=12.2, loss_final=1.5, loss_mean=1.4, loss[[34m2025-10-03 23:59:59[39m] Step: 203, Training Logs: loss_final: 1.496475, loss_mean: 1.406298, proj_loss: -0.058448, loss_mean_cls: 0.113607, deep_loss: 0.035018, grad_norm: 10.310780
Steps:   0%| | 206/1000000 [03:56<281:35:27,  1.01s/it, deep_loss=0.0357, grad_norm=22.7, loss_final=1.59, loss_mean=1.5, lo[[34m2025-10-04 00:00:01[39m] Step: 205, Training Logs: loss_final: 1.481592, loss_mean: 1.388447, proj_loss: -0.054812, loss_mean_cls: 0.113172, deep_loss: 0.034785, grad_norm: 6.7139750
Steps:   0%| | 208/1000000 [03:58<267:48:30,  1.04it/s, deep_loss=0.0368, grad_norm=25.2, loss_final=1.61, loss_mean=1.51, l[[34m2025-10-04 00:00:03[39m] Step: 207, Training Logs: loss_final: 1.516349, loss_mean: 1.420927, proj_loss: -0.052497, loss_mean_cls: 0.113763, deep_loss: 0.034155, grad_norm: 14.589533
Steps:   0%| | 210/1000000 [04:00<296:26:15,  1.07s/it, deep_loss=0.0356, grad_norm=13.4, loss_final=1.54, loss_mean=1.44, l[[34m2025-10-04 00:00:05[39m] Step: 209, Training Logs: loss_final: 1.561224, loss_mean: 1.464035, proj_loss: -0.052321, loss_mean_cls: 0.113356, deep_loss: 0.036153, grad_norm: 22.096781
Steps:   0%| | 212/1000000 [04:02<311:07:34,  1.12s/it, deep_loss=0.0381, grad_norm=21.5, loss_final=1.61, loss_mean=1.52, l[[34m2025-10-04 00:00:07[39m] Step: 211, Training Logs: loss_final: 1.572848, loss_mean: 1.479635, proj_loss: -0.057573, loss_mean_cls: 0.113042, deep_loss: 0.037744, grad_norm: 16.920336
Steps:   0%| | 214/1000000 [04:05<319:22:21,  1.15s/it, deep_loss=0.0343, grad_norm=10, loss_final=1.53, loss_mean=1.43, los[[34m2025-10-04 00:00:09[39m] Step: 213, Training Logs: loss_final: 1.568796, loss_mean: 1.474875, proj_loss: -0.055329, loss_mean_cls: 0.112563, deep_loss: 0.036687, grad_norm: 16.601238
Steps:   0%| | 215/1000000 [04:06<322:46:12,  1.16s/it, deep_loss=0.0343, grad_norm=10, loss_final=1.53, loss_mean=1.43, los[[34m2025-10-04 00:00:12[39m] Step: 215, Training Logs: loss_final: 1.535105, loss_mean: 1.440672, proj_loss: -0.052512, loss_mean_cls: 0.112802, deep_loss: 0.034143, grad_norm: 12.634494
Steps:   0%| | 217/1000000 [04:08<325:08:27,  1.17s/it, deep_loss=0.0353, grad_norm=16.4, loss_final=1.54, loss_mean=1.45, l[[34m2025-10-04 00:00:14[39m] Step: 217, Training Logs: loss_final: 1.504296, loss_mean: 1.406374, proj_loss: -0.050816, loss_mean_cls: 0.113160, deep_loss: 0.035577, grad_norm: 13.944531
Steps:   0%| | 219/1000000 [04:10<324:22:09,  1.17s/it, deep_loss=0.0367, grad_norm=9.72, loss_final=1.51, loss_mean=1.41, l[[34m2025-10-04 00:00:16[39m] Step: 219, Training Logs: loss_final: 1.525250, loss_mean: 1.427677, proj_loss: -0.050801, loss_mean_cls: 0.113182, deep_loss: 0.035192, grad_norm: 12.925051
Steps:   0%| | 221/1000000 [04:13<327:00:12,  1.18s/it, deep_loss=0.0342, grad_norm=14.7, loss_final=1.51, loss_mean=1.41, l[[34m2025-10-04 00:00:19[39m] Step: 221, Training Logs: loss_final: 1.497947, loss_mean: 1.397530, proj_loss: -0.046798, loss_mean_cls: 0.112750, deep_loss: 0.034465, grad_norm: 12.756423
Steps:   0%| | 222/1000000 [04:14<325:55:22,  1.17s/it, deep_loss=0.0353, grad_norm=11.8, loss_final=1.51, loss_mean=1.42, l[[34m2025-10-04 00:00:19[39m] Step: 221, Training Logs: loss_final: 1.497947, loss_mean: 1.397530, proj_loss: -0.046798, loss_mean_cls: 0.112750, deep_loss: 0.034465, grad_norm: 12.756423
Steps:   0%| | 224/1000000 [04:16<325:36:41,  1.17s/it, deep_loss=0.0336, grad_norm=12.9, loss_final=1.49, loss_mean=1.39, l[[34m2025-10-04 00:00:21[39m] Step: 223, Training Logs: loss_final: 1.536991, loss_mean: 1.437549, proj_loss: -0.048127, loss_mean_cls: 0.112205, deep_loss: 0.035363, grad_norm: 14.733963
Steps:   0%| | 226/1000000 [04:19<326:17:33,  1.17s/it, deep_loss=0.0369, grad_norm=37.7, loss_final=1.7, loss_mean=1.59, lo[[34m2025-10-04 00:00:24[39m] Step: 225, Training Logs: loss_final: 1.480745, loss_mean: 1.379720, proj_loss: -0.045850, loss_mean_cls: 0.113652, deep_loss: 0.033223, grad_norm: 9.5564143
Steps:   0%| | 227/1000000 [04:20<327:49:04,  1.18s/it, deep_loss=0.0369, grad_norm=37.7, loss_final=1.7, loss_mean=1.59, lo[[34m2025-10-04 00:00:26[39m] Step: 227, Training Logs: loss_final: 1.585356, loss_mean: 1.479231, proj_loss: -0.041500, loss_mean_cls: 0.113484, deep_loss: 0.034140, grad_norm: 29.914881
Steps:   0%| | 229/1000000 [04:22<326:54:21,  1.18s/it, deep_loss=0.036, grad_norm=23.1, loss_final=1.55, loss_mean=1.44, lo[[34m2025-10-04 00:00:28[39m] Step: 229, Training Logs: loss_final: 1.515741, loss_mean: 1.406838, proj_loss: -0.039850, loss_mean_cls: 0.114133, deep_loss: 0.034620, grad_norm: 20.487936
Steps:   0%| | 231/1000000 [04:25<328:00:39,  1.18s/it, deep_loss=0.0349, grad_norm=23.8, loss_final=1.56, loss_mean=1.45, l[[34m2025-10-04 00:00:31[39m] Step: 231, Training Logs: loss_final: 1.537135, loss_mean: 1.432882, proj_loss: -0.043106, loss_mean_cls: 0.112422, deep_loss: 0.034937, grad_norm: 17.656729
Steps:   0%| | 233/1000000 [04:27<326:28:07,  1.18s/it, deep_loss=0.033, grad_norm=11.4, loss_final=1.52, loss_mean=1.41, lo[[34m2025-10-04 00:00:33[39m] Step: 233, Training Logs: loss_final: 1.542351, loss_mean: 1.440377, proj_loss: -0.044151, loss_mean_cls: 0.112825, deep_loss: 0.033300, grad_norm: 16.794102
Steps:   0%| | 234/1000000 [04:28<326:18:58,  1.18s/it, deep_loss=0.0339, grad_norm=18.6, loss_final=1.55, loss_mean=1.44, l[[34m2025-10-04 00:00:33[39m] Step: 233, Training Logs: loss_final: 1.542351, loss_mean: 1.440377, proj_loss: -0.044151, loss_mean_cls: 0.112825, deep_loss: 0.033300, grad_norm: 16.794102
Steps:   0%| | 237/1000000 [04:31<269:20:48,  1.03it/s, deep_loss=0.034, grad_norm=9.61, loss_final=1.49, loss_mean=1.39, lo[[34m2025-10-04 00:00:37[39m] Step: 237, Training Logs: loss_final: 1.513816, loss_mean: 1.407120, proj_loss: -0.039396, loss_mean_cls: 0.113081, deep_loss: 0.033012, grad_norm: 13.420139
Steps:   0%| | 239/1000000 [04:32<243:35:53,  1.14it/s, deep_loss=0.034, grad_norm=11.6, loss_final=1.5, loss_mean=1.4, loss[[34m2025-10-04 00:00:38[39m] Step: 239, Training Logs: loss_final: 1.518381, loss_mean: 1.411531, proj_loss: -0.041192, loss_mean_cls: 0.113645, deep_loss: 0.034397, grad_norm: 10.207598
Steps:   0%| | 241/1000000 [04:35<278:15:52,  1.00s/it, deep_loss=0.0338, grad_norm=12, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-04 00:00:41[39m] Step: 241, Training Logs: loss_final: 1.501503, loss_mean: 1.394577, proj_loss: -0.039384, loss_mean_cls: 0.113178, deep_loss: 0.033131, grad_norm: 11.301592
Steps:   0%| | 243/1000000 [04:37<303:24:23,  1.09s/it, deep_loss=0.0328, grad_norm=8.43, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-04 00:00:43[39m] Step: 243, Training Logs: loss_final: 1.489606, loss_mean: 1.381562, proj_loss: -0.038521, loss_mean_cls: 0.113197, deep_loss: 0.033369, grad_norm: 11.273098
Steps:   0%| | 244/1000000 [04:38<311:15:47,  1.12s/it, deep_loss=0.0346, grad_norm=11, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-04 00:00:43[39m] Step: 243, Training Logs: loss_final: 1.489606, loss_mean: 1.381562, proj_loss: -0.038521, loss_mean_cls: 0.113197, deep_loss: 0.033369, grad_norm: 11.273098
Steps:   0%| | 246/1000000 [04:41<319:47:43,  1.15s/it, deep_loss=0.0326, grad_norm=9.79, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-04 00:00:45[39m] Step: 245, Training Logs: loss_final: 1.479867, loss_mean: 1.370654, proj_loss: -0.037355, loss_mean_cls: 0.113306, deep_loss: 0.033262, grad_norm: 8.3121438
Steps:   0%| | 248/1000000 [04:43<322:38:32,  1.16s/it, deep_loss=0.0322, grad_norm=15.8, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-04 00:00:48[39m] Step: 247, Training Logs: loss_final: 1.484354, loss_mean: 1.376573, proj_loss: -0.037848, loss_mean_cls: 0.113287, deep_loss: 0.032342, grad_norm: 8.0843368
Steps:   0%| | 249/1000000 [04:44<322:54:03,  1.16s/it, deep_loss=0.0322, grad_norm=15.8, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-04 00:00:50[39m] Step: 249, Training Logs: loss_final: 1.480053, loss_mean: 1.370050, proj_loss: -0.035465, loss_mean_cls: 0.113266, deep_loss: 0.032202, grad_norm: 13.202952
Steps:   0%| | 251/1000000 [04:46<324:46:19,  1.17s/it, deep_loss=0.0327, grad_norm=12.6, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-04 00:00:52[39m] Step: 251, Training Logs: loss_final: 1.488651, loss_mean: 1.376224, proj_loss: -0.033314, loss_mean_cls: 0.113512, deep_loss: 0.032228, grad_norm: 16.626486
Steps:   0%| | 253/1000000 [04:49<325:39:59,  1.17s/it, deep_loss=0.0322, grad_norm=9.68, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-04 00:00:55[39m] Step: 253, Training Logs: loss_final: 1.481219, loss_mean: 1.368936, proj_loss: -0.032498, loss_mean_cls: 0.112809, deep_loss: 0.031972, grad_norm: 10.234221
Steps:   0%| | 254/1000000 [04:50<325:22:50,  1.17s/it, deep_loss=0.0339, grad_norm=20, loss_final=1.54, loss_mean=1.42, los[[34m2025-10-04 00:00:55[39m] Step: 253, Training Logs: loss_final: 1.481219, loss_mean: 1.368936, proj_loss: -0.032498, loss_mean_cls: 0.112809, deep_loss: 0.031972, grad_norm: 10.234221
Steps:   0%| | 256/1000000 [04:52<325:56:21,  1.17s/it, deep_loss=0.0319, grad_norm=14.5, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-04 00:00:57[39m] Step: 255, Training Logs: loss_final: 1.470961, loss_mean: 1.353189, proj_loss: -0.029015, loss_mean_cls: 0.113658, deep_loss: 0.033129, grad_norm: 9.1484001
Steps:   0%| | 258/1000000 [04:55<326:45:20,  1.18s/it, deep_loss=0.0335, grad_norm=9.68, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-04 00:00:59[39m] Step: 257, Training Logs: loss_final: 1.496227, loss_mean: 1.378411, proj_loss: -0.028626, loss_mean_cls: 0.113790, deep_loss: 0.032652, grad_norm: 15.839291
Steps:   0%| | 260/1000000 [04:57<326:55:47,  1.18s/it, deep_loss=0.0334, grad_norm=16.6, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-04 00:01:02[39m] Step: 259, Training Logs: loss_final: 1.497849, loss_mean: 1.380134, proj_loss: -0.028079, loss_mean_cls: 0.113736, deep_loss: 0.032058, grad_norm: 13.755634
Steps:   0%| | 261/1000000 [04:58<327:20:38,  1.18s/it, deep_loss=0.0334, grad_norm=16.6, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-04 00:01:04[39m] Step: 261, Training Logs: loss_final: 1.476081, loss_mean: 1.354855, proj_loss: -0.026120, loss_mean_cls: 0.114161, deep_loss: 0.033185, grad_norm: 10.414713
Steps:   0%| | 263/1000000 [05:01<326:35:48,  1.18s/it, deep_loss=0.0321, grad_norm=13.9, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-04 00:01:06[39m] Step: 263, Training Logs: loss_final: 1.526273, loss_mean: 1.405298, proj_loss: -0.024811, loss_mean_cls: 0.112724, deep_loss: 0.033063, grad_norm: 15.882940
Steps:   0%| | 265/1000000 [05:03<325:34:36,  1.17s/it, deep_loss=0.0329, grad_norm=12.3, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:01:09[39m] Step: 265, Training Logs: loss_final: 1.511631, loss_mean: 1.387627, proj_loss: -0.022388, loss_mean_cls: 0.113838, deep_loss: 0.032553, grad_norm: 12.980903
Steps:   0%| | 267/1000000 [05:05<316:57:15,  1.14s/it, deep_loss=0.033, grad_norm=16.7, loss_final=1.49, loss_mean=1.37, lo[[34m2025-10-04 00:01:09[39m] Step: 265, Training Logs: loss_final: 1.511631, loss_mean: 1.387627, proj_loss: -0.022388, loss_mean_cls: 0.113838, deep_loss: 0.032553, grad_norm: 12.980903
Steps:   0%| | 269/1000000 [05:07<266:52:20,  1.04it/s, deep_loss=0.0325, grad_norm=16, loss_final=1.49, loss_mean=1.37, los[[34m2025-10-04 00:01:13[39m] Step: 269, Training Logs: loss_final: 1.535552, loss_mean: 1.410004, proj_loss: -0.021562, loss_mean_cls: 0.114373, deep_loss: 0.032738, grad_norm: 18.019751
Steps:   0%| | 271/1000000 [05:09<278:54:35,  1.00s/it, deep_loss=0.0321, grad_norm=22.2, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-04 00:01:15[39m] Step: 271, Training Logs: loss_final: 1.517434, loss_mean: 1.393446, proj_loss: -0.023266, loss_mean_cls: 0.114089, deep_loss: 0.033165, grad_norm: 14.388453
Steps:   0%| | 273/1000000 [05:11<302:36:29,  1.09s/it, deep_loss=0.0342, grad_norm=31.6, loss_final=1.56, loss_mean=1.43, l[[34m2025-10-04 00:01:17[39m] Step: 273, Training Logs: loss_final: 1.516803, loss_mean: 1.392817, proj_loss: -0.023070, loss_mean_cls: 0.114041, deep_loss: 0.033014, grad_norm: 20.045990
Steps:   0%| | 274/1000000 [05:12<309:29:04,  1.11s/it, deep_loss=0.0337, grad_norm=37.5, loss_final=1.6, loss_mean=1.48, lo[[34m2025-10-04 00:01:17[39m] Step: 273, Training Logs: loss_final: 1.516803, loss_mean: 1.392817, proj_loss: -0.023070, loss_mean_cls: 0.114041, deep_loss: 0.033014, grad_norm: 20.045990
Steps:   0%| | 276/1000000 [05:15<319:13:30,  1.15s/it, deep_loss=0.0345, grad_norm=35.1, loss_final=1.59, loss_mean=1.46, l[[34m2025-10-04 00:01:19[39m] Step: 275, Training Logs: loss_final: 1.547673, loss_mean: 1.425473, proj_loss: -0.023216, loss_mean_cls: 0.113335, deep_loss: 0.032081, grad_norm: 26.649580
Steps:   0%| | 278/1000000 [05:17<322:34:38,  1.16s/it, deep_loss=0.0333, grad_norm=22.8, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-04 00:01:22[39m] Step: 277, Training Logs: loss_final: 1.578205, loss_mean: 1.451703, proj_loss: -0.021396, loss_mean_cls: 0.113665, deep_loss: 0.034234, grad_norm: 33.061680
Steps:   0%| | 279/1000000 [05:18<323:26:07,  1.16s/it, deep_loss=0.0333, grad_norm=22.8, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-04 00:01:24[39m] Step: 279, Training Logs: loss_final: 1.566353, loss_mean: 1.440760, proj_loss: -0.022025, loss_mean_cls: 0.113892, deep_loss: 0.033726, grad_norm: 28.398235
Steps:   0%| | 281/1000000 [05:20<326:24:30,  1.18s/it, deep_loss=0.0343, grad_norm=24.3, loss_final=1.53, loss_mean=1.4, lo[[34m2025-10-04 00:01:26[39m] Step: 281, Training Logs: loss_final: 1.567079, loss_mean: 1.440541, proj_loss: -0.020688, loss_mean_cls: 0.113707, deep_loss: 0.033519, grad_norm: 25.372869
Steps:   0%| | 283/1000000 [05:23<326:52:26,  1.18s/it, deep_loss=0.0336, grad_norm=25.9, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-04 00:01:29[39m] Step: 283, Training Logs: loss_final: 1.515940, loss_mean: 1.391395, proj_loss: -0.023334, loss_mean_cls: 0.114408, deep_loss: 0.033472, grad_norm: 22.017365
Steps:   0%| | 284/1000000 [05:24<327:02:14,  1.18s/it, deep_loss=0.032, grad_norm=23.9, loss_final=1.52, loss_mean=1.4, los[[34m2025-10-04 00:01:29[39m] Step: 283, Training Logs: loss_final: 1.515940, loss_mean: 1.391395, proj_loss: -0.023334, loss_mean_cls: 0.114408, deep_loss: 0.033472, grad_norm: 22.017365
Steps:   0%| | 286/1000000 [05:26<326:55:24,  1.18s/it, deep_loss=0.0336, grad_norm=17.8, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:01:31[39m] Step: 285, Training Logs: loss_final: 1.529778, loss_mean: 1.404525, proj_loss: -0.021997, loss_mean_cls: 0.114167, deep_loss: 0.033083, grad_norm: 24.760592
Steps:   0%| | 288/1000000 [05:29<326:49:58,  1.18s/it, deep_loss=0.0333, grad_norm=20.1, loss_final=1.51, loss_mean=1.38, l[[34m2025-10-04 00:01:34[39m] Step: 287, Training Logs: loss_final: 1.520792, loss_mean: 1.394716, proj_loss: -0.020822, loss_mean_cls: 0.113330, deep_loss: 0.033567, grad_norm: 25.407948
Steps:   0%| | 290/1000000 [05:31<325:49:07,  1.17s/it, deep_loss=0.0338, grad_norm=24.6, loss_final=1.5, loss_mean=1.37, lo[[34m2025-10-04 00:01:36[39m] Step: 289, Training Logs: loss_final: 1.520754, loss_mean: 1.394506, proj_loss: -0.020699, loss_mean_cls: 0.113363, deep_loss: 0.033583, grad_norm: 23.813856
Steps:   0%| | 291/1000000 [05:32<325:29:01,  1.17s/it, deep_loss=0.0338, grad_norm=24.6, loss_final=1.5, loss_mean=1.37, lo[[34m2025-10-04 00:01:38[39m] Step: 291, Training Logs: loss_final: 1.489681, loss_mean: 1.364052, proj_loss: -0.021009, loss_mean_cls: 0.113395, deep_loss: 0.033242, grad_norm: 20.380802
Steps:   0%| | 293/1000000 [05:35<326:19:05,  1.18s/it, deep_loss=0.0313, grad_norm=21.5, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:01:41[39m] Step: 293, Training Logs: loss_final: 1.486654, loss_mean: 1.361781, proj_loss: -0.020857, loss_mean_cls: 0.114051, deep_loss: 0.031679, grad_norm: 19.369986
Steps:   0%| | 295/1000000 [05:37<325:25:07,  1.17s/it, deep_loss=0.032, grad_norm=18.8, loss_final=1.49, loss_mean=1.37, lo[[34m2025-10-04 00:01:43[39m] Step: 295, Training Logs: loss_final: 1.493494, loss_mean: 1.367714, proj_loss: -0.019533, loss_mean_cls: 0.113981, deep_loss: 0.031332, grad_norm: 20.591784
Steps:   0%| | 296/1000000 [05:38<325:03:31,  1.17s/it, deep_loss=0.0318, grad_norm=20.3, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:01:43[39m] Step: 295, Training Logs: loss_final: 1.493494, loss_mean: 1.367714, proj_loss: -0.019533, loss_mean_cls: 0.113981, deep_loss: 0.031332, grad_norm: 20.591784
Steps:   0%| | 299/1000000 [05:41<275:24:39,  1.01it/s, deep_loss=0.0325, grad_norm=16.6, loss_final=1.48, loss_mean=1.36, l[[34m2025-10-04 00:01:47[39m] Step: 299, Training Logs: loss_final: 1.499766, loss_mean: 1.373363, proj_loss: -0.020121, loss_mean_cls: 0.112957, deep_loss: 0.033566, grad_norm: 17.076757
Steps:   0%| | 301/1000000 [05:43<273:56:00,  1.01it/s, deep_loss=0.0335, grad_norm=14.6, loss_final=1.5, loss_mean=1.37, lo[[34m2025-10-04 00:01:49[39m] Step: 301, Training Logs: loss_final: 1.478163, loss_mean: 1.351223, proj_loss: -0.018479, loss_mean_cls: 0.113043, deep_loss: 0.032375, grad_norm: 15.840508
Steps:   0%| | 303/1000000 [05:45<300:38:41,  1.08s/it, deep_loss=0.0318, grad_norm=15.9, loss_final=1.48, loss_mean=1.36, l[[34m2025-10-04 00:01:51[39m] Step: 303, Training Logs: loss_final: 1.472959, loss_mean: 1.347602, proj_loss: -0.020071, loss_mean_cls: 0.113628, deep_loss: 0.031800, grad_norm: 17.599674
Steps:   0%| | 304/1000000 [05:46<308:11:40,  1.11s/it, deep_loss=0.0315, grad_norm=16.7, loss_final=1.46, loss_mean=1.33, l[[34m2025-10-04 00:01:51[39m] Step: 303, Training Logs: loss_final: 1.472959, loss_mean: 1.347602, proj_loss: -0.020071, loss_mean_cls: 0.113628, deep_loss: 0.031800, grad_norm: 17.599674
Steps:   0%| | 306/1000000 [05:49<318:06:41,  1.15s/it, deep_loss=0.031, grad_norm=19.8, loss_final=1.45, loss_mean=1.32, lo[[34m2025-10-04 00:01:54[39m] Step: 305, Training Logs: loss_final: 1.426913, loss_mean: 1.301425, proj_loss: -0.019515, loss_mean_cls: 0.114953, deep_loss: 0.030049, grad_norm: 12.558902
Steps:   0%| | 308/1000000 [05:51<321:59:15,  1.16s/it, deep_loss=0.0307, grad_norm=16.6, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:01:56[39m] Step: 307, Training Logs: loss_final: 1.448058, loss_mean: 1.324421, proj_loss: -0.020854, loss_mean_cls: 0.112974, deep_loss: 0.031517, grad_norm: 12.957324
Steps:   0%| | 309/1000000 [05:52<323:11:22,  1.16s/it, deep_loss=0.0307, grad_norm=16.6, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:01:58[39m] Step: 309, Training Logs: loss_final: 1.482473, loss_mean: 1.355267, proj_loss: -0.018633, loss_mean_cls: 0.113344, deep_loss: 0.032495, grad_norm: 16.492201
Steps:   0%| | 311/1000000 [05:55<324:45:59,  1.17s/it, deep_loss=0.0312, grad_norm=15.8, loss_final=1.47, loss_mean=1.35, l[[34m2025-10-04 00:02:01[39m] Step: 311, Training Logs: loss_final: 1.477899, loss_mean: 1.351443, proj_loss: -0.019364, loss_mean_cls: 0.114172, deep_loss: 0.031647, grad_norm: 15.346721
Steps:   0%| | 313/1000000 [05:57<324:50:53,  1.17s/it, deep_loss=0.0321, grad_norm=16.1, loss_final=1.48, loss_mean=1.35, l[[34m2025-10-04 00:02:03[39m] Step: 313, Training Logs: loss_final: 1.480949, loss_mean: 1.355920, proj_loss: -0.019741, loss_mean_cls: 0.113853, deep_loss: 0.030917, grad_norm: 21.291897
Steps:   0%| | 315/1000000 [05:59<285:37:45,  1.03s/it, deep_loss=0.0327, grad_norm=15.6, loss_final=1.48, loss_mean=1.35, l[[34m2025-10-04 00:02:05[39m] Step: 315, Training Logs: loss_final: 1.491853, loss_mean: 1.364885, proj_loss: -0.018400, loss_mean_cls: 0.113757, deep_loss: 0.031611, grad_norm: 24.198902
Steps:   0%| | 318/1000000 [06:01<246:21:13,  1.13it/s, deep_loss=0.0315, grad_norm=18.2, loss_final=1.48, loss_mean=1.35, l[[34m2025-10-04 00:02:06[39m] Step: 317, Training Logs: loss_final: 1.478709, loss_mean: 1.347166, proj_loss: -0.017133, loss_mean_cls: 0.114367, deep_loss: 0.034309, grad_norm: 18.451750
Steps:   0%| | 320/1000000 [06:03<235:31:31,  1.18it/s, deep_loss=0.0311, grad_norm=12.1, loss_final=1.48, loss_mean=1.35, l[[34m2025-10-04 00:02:08[39m] Step: 319, Training Logs: loss_final: 1.466677, loss_mean: 1.337478, proj_loss: -0.017375, loss_mean_cls: 0.114569, deep_loss: 0.032006, grad_norm: 12.756605
Steps:   0%| | 323/1000000 [06:05<228:17:32,  1.22it/s, deep_loss=0.0327, grad_norm=19.1, loss_final=1.47, loss_mean=1.34, l[[34m2025-10-04 00:02:11[39m] Step: 323, Training Logs: loss_final: 1.467701, loss_mean: 1.339785, proj_loss: -0.017221, loss_mean_cls: 0.113703, deep_loss: 0.031434, grad_norm: 15.044535
Steps:   0%| | 325/1000000 [06:07<226:28:27,  1.23it/s, deep_loss=0.0337, grad_norm=23.1, loss_final=1.49, loss_mean=1.36, l[[34m2025-10-04 00:02:13[39m] Step: 325, Training Logs: loss_final: 1.465597, loss_mean: 1.334458, proj_loss: -0.018023, loss_mean_cls: 0.115061, deep_loss: 0.034102, grad_norm: 15.704202
Steps:   0%| | 329/1000000 [06:09<167:37:52,  1.66it/s, deep_loss=0.0321, grad_norm=20.5, loss_final=1.45, loss_mean=1.33, l[[34m2025-10-04 00:02:15[39m] Step: 329, Training Logs: loss_final: 1.494852, loss_mean: 1.366862, proj_loss: -0.019083, loss_mean_cls: 0.114151, deep_loss: 0.032923, grad_norm: 25.496435
Steps:   0%| | 334/1000000 [06:11<122:57:58,  2.26it/s, deep_loss=0.0339, grad_norm=21.2, loss_final=1.48, loss_mean=1.35, l[[34m2025-10-04 00:02:17[39m] Step: 333, Training Logs: loss_final: 1.467105, loss_mean: 1.339161, proj_loss: -0.018675, loss_mean_cls: 0.114209, deep_loss: 0.032409, grad_norm: 19.654465
Steps:   0%| | 338/1000000 [06:13<140:09:41,  1.98it/s, deep_loss=0.0322, grad_norm=21.5, loss_final=1.46, loss_mean=1.33, l[[34m2025-10-04 00:02:18[39m] Step: 337, Training Logs: loss_final: 1.475537, loss_mean: 1.347917, proj_loss: -0.018404, loss_mean_cls: 0.114359, deep_loss: 0.031664, grad_norm: 21.445913
Steps:   0%| | 340/1000000 [06:15<183:49:58,  1.51it/s, deep_loss=0.0324, grad_norm=21, loss_final=1.48, loss_mean=1.35, los[[34m2025-10-04 00:02:20[39m] Step: 339, Training Logs: loss_final: 1.469818, loss_mean: 1.341701, proj_loss: -0.019563, loss_mean_cls: 0.114029, deep_loss: 0.033650, grad_norm: 16.315407
Steps:   0%| | 343/1000000 [06:17<210:50:07,  1.32it/s, deep_loss=0.0322, grad_norm=14.8, loss_final=1.48, loss_mean=1.36, l[[34m2025-10-04 00:02:23[39m] Step: 343, Training Logs: loss_final: 1.456461, loss_mean: 1.330327, proj_loss: -0.020389, loss_mean_cls: 0.114205, deep_loss: 0.032318, grad_norm: 12.197879
Steps:   0%| | 345/1000000 [06:19<218:33:10,  1.27it/s, deep_loss=0.032, grad_norm=15.3, loss_final=1.48, loss_mean=1.35, lo[[34m2025-10-04 00:02:25[39m] Step: 345, Training Logs: loss_final: 1.459162, loss_mean: 1.333305, proj_loss: -0.021023, loss_mean_cls: 0.114268, deep_loss: 0.032612, grad_norm: 11.471508
Steps:   0%| | 347/1000000 [06:21<221:39:30,  1.25it/s, deep_loss=0.0312, grad_norm=13.8, loss_final=1.47, loss_mean=1.34, l[[34m2025-10-04 00:02:27[39m] Step: 347, Training Logs: loss_final: 1.459570, loss_mean: 1.333027, proj_loss: -0.020092, loss_mean_cls: 0.114105, deep_loss: 0.032530, grad_norm: 15.430247
Steps:   0%| | 350/1000000 [06:23<224:06:09,  1.24it/s, deep_loss=0.0318, grad_norm=14.3, loss_final=1.47, loss_mean=1.35, l[[34m2025-10-04 00:02:28[39m] Step: 349, Training Logs: loss_final: 1.463277, loss_mean: 1.337708, proj_loss: -0.020986, loss_mean_cls: 0.114561, deep_loss: 0.031994, grad_norm: 13.752559
Steps:   0%| | 353/1000000 [06:25<224:44:48,  1.24it/s, deep_loss=0.0319, grad_norm=16, loss_final=1.48, loss_mean=1.35, los[[34m2025-10-04 00:02:30[39m] Step: 351, Training Logs: loss_final: 1.467713, loss_mean: 1.342558, proj_loss: -0.020262, loss_mean_cls: 0.114033, deep_loss: 0.031384, grad_norm: 20.463120
Steps:   0%| | 355/1000000 [06:27<225:40:18,  1.23it/s, deep_loss=0.0329, grad_norm=22.2, loss_final=1.47, loss_mean=1.35, l[[34m2025-10-04 00:02:33[39m] Step: 355, Training Logs: loss_final: 1.477540, loss_mean: 1.350744, proj_loss: -0.019848, loss_mean_cls: 0.114457, deep_loss: 0.032186, grad_norm: 19.408991
Steps:   0%| | 357/1000000 [06:29<227:01:42,  1.22it/s, deep_loss=0.0309, grad_norm=22, loss_final=1.45, loss_mean=1.33, los[[34m2025-10-04 00:02:35[39m] Step: 357, Training Logs: loss_final: 1.483307, loss_mean: 1.360289, proj_loss: -0.022371, loss_mean_cls: 0.113962, deep_loss: 0.031427, grad_norm: 21.307915
Steps:   0%| | 360/1000000 [06:31<226:51:52,  1.22it/s, deep_loss=0.0306, grad_norm=19, loss_final=1.44, loss_mean=1.31, los[[34m2025-10-04 00:02:36[39m] Step: 359, Training Logs: loss_final: 1.474596, loss_mean: 1.348570, proj_loss: -0.020337, loss_mean_cls: 0.114609, deep_loss: 0.031754, grad_norm: 19.660053
Steps:   0%| | 362/1000000 [06:33<225:36:50,  1.23it/s, deep_loss=0.0308, grad_norm=14.8, loss_final=1.46, loss_mean=1.33, l[[34m2025-10-04 00:02:38[39m] Step: 361, Training Logs: loss_final: 1.478996, loss_mean: 1.352193, proj_loss: -0.020816, loss_mean_cls: 0.115356, deep_loss: 0.032262, grad_norm: 17.793285
Steps:   0%| | 365/1000000 [06:35<183:41:44,  1.51it/s, deep_loss=0.032, grad_norm=16.9, loss_final=1.47, loss_mean=1.35, lo[[34m2025-10-04 00:02:41[39m] Step: 365, Training Logs: loss_final: 1.468290, loss_mean: 1.342656, proj_loss: -0.020770, loss_mean_cls: 0.114803, deep_loss: 0.031601, grad_norm: 18.317446
