
Steps:   0%|                                                                       | 1/1000000 [00:05<1422:11:59,  5.12s/it][[34m2025-10-03 23:25:54[39m] Generating EMA samples done.
[[34m2025-10-03 23:25:54[39m] Step: 1, Training Logs: loss_final: 1.852024, loss_mean: 1.685077, proj_loss: -0.001562, loss_mean_cls: 0.118509, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 2/1000000 [00:06<774:11:48,  2.79s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.85, loss_mean=1.69, loss_m[[34m2025-10-03 23:25:55[39m] Step: 2, Training Logs: loss_final: 1.857074, loss_mean: 1.690185, proj_loss: -0.001133, loss_mean_cls: 0.118023, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 3/1000000 [00:07<565:30:12,  2.04s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_m[[34m2025-10-03 23:25:56[39m] Step: 3, Training Logs: loss_final: 1.893526, loss_mean: 1.725911, proj_loss: -0.000692, loss_mean_cls: 0.118307, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 4/1000000 [00:08<467:31:40,  1.68s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.89, loss_mean=1.73, loss_m[[34m2025-10-03 23:25:57[39m] Step: 4, Training Logs: loss_final: 1.863802, loss_mean: 1.696726, proj_loss: -0.000918, loss_mean_cls: 0.117994, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 5/1000000 [00:09<414:13:16,  1.49s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.7, loss_me[[34m2025-10-03 23:25:58[39m] Step: 5, Training Logs: loss_final: 1.876213, loss_mean: 1.708497, proj_loss: -0.001132, loss_mean_cls: 0.118849, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 6/1000000 [00:10<382:05:55,  1.38s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.88, loss_mean=1.71, loss_m[[34m2025-10-03 23:25:59[39m] Step: 6, Training Logs: loss_final: 1.861109, loss_mean: 1.693091, proj_loss: -0.000262, loss_mean_cls: 0.118281, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 7/1000000 [00:12<362:22:41,  1.30s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_m[[34m2025-10-03 23:26:01[39m] Step: 7, Training Logs: loss_final: 1.855225, loss_mean: 1.687699, proj_loss: -0.000456, loss_mean_cls: 0.117981, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 8/1000000 [00:13<348:44:36,  1.26s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_m[[34m2025-10-03 23:26:02[39m] Step: 8, Training Logs: loss_final: 1.865341, loss_mean: 1.697358, proj_loss: -0.000295, loss_mean_cls: 0.118278, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 9/1000000 [00:14<339:45:15,  1.22s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.87, loss_mean=1.7, loss_me[[34m2025-10-03 23:26:03[39m] Step: 9, Training Logs: loss_final: 1.856894, loss_mean: 1.689859, proj_loss: -0.001537, loss_mean_cls: 0.118572, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 10/1000000 [00:15<334:30:47,  1.20s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:26:04[39m] Step: 10, Training Logs: loss_final: 1.880090, loss_mean: 1.711735, proj_loss: 0.000060, loss_mean_cls: 0.118295, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 11/1000000 [00:16<329:10:23,  1.19s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.88, loss_mean=1.71, loss_[[34m2025-10-03 23:26:05[39m] Step: 11, Training Logs: loss_final: 1.858421, loss_mean: 1.690543, proj_loss: -0.000472, loss_mean_cls: 0.118350, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 12/1000000 [00:17<326:41:01,  1.18s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:26:06[39m] Step: 12, Training Logs: loss_final: 1.876679, loss_mean: 1.708093, proj_loss: 0.000305, loss_mean_cls: 0.118281, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 13/1000000 [00:18<324:30:41,  1.17s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.88, loss_mean=1.71, loss_[[34m2025-10-03 23:26:07[39m] Step: 13, Training Logs: loss_final: 1.844913, loss_mean: 1.677251, proj_loss: -0.000555, loss_mean_cls: 0.118217, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 14/1000000 [00:20<323:08:43,  1.16s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.84, loss_mean=1.68, loss_[[34m2025-10-03 23:26:09[39m] Step: 14, Training Logs: loss_final: 1.860075, loss_mean: 1.692572, proj_loss: -0.000743, loss_mean_cls: 0.118246, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 15/1000000 [00:21<322:42:50,  1.16s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:26:10[39m] Step: 15, Training Logs: loss_final: 1.858943, loss_mean: 1.690525, proj_loss: 0.000005, loss_mean_cls: 0.118413, deep_loss: 0.050000, grad_norm: nan
Steps:   0%| | 16/1000000 [00:22<321:46:50,  1.16s/it, deep_loss=0.05, grad_norm=nan, loss_final=1.86, loss_mean=1.69, loss_[[34m2025-10-03 23:26:11[39m] Step: 16, Training Logs: loss_final: 1.882615, loss_mean: 1.715268, proj_loss: -0.000550, loss_mean_cls: 0.117897, deep_loss: 0.050000, grad_norm: inf
Steps:   0%| | 17/1000000 [00:23<321:41:43,  1.16s/it, deep_loss=0.05, grad_norm=inf, loss_final=1.88, loss_mean=1.72, loss_[[34m2025-10-03 23:26:12[39m] Step: 17, Training Logs: loss_final: 1.849142, loss_mean: 1.680075, proj_loss: 0.000387, loss_mean_cls: 0.118681, deep_loss: 0.050000, grad_norm: inf
Steps:   0%| | 18/1000000 [00:24<327:02:54,  1.18s/it, deep_loss=0.05, grad_norm=inf, loss_final=1.85, loss_mean=1.68, loss_[[34m2025-10-03 23:26:13[39m] Step: 18, Training Logs: loss_final: 1.846045, loss_mean: 1.678042, proj_loss: -0.000140, loss_mean_cls: 0.118143, deep_loss: 0.050000, grad_norm: 3722890.000000
Steps:   0%| | 19/1000000 [00:25<325:22:02,  1.17s/it, deep_loss=0.05, grad_norm=3.72e+6, loss_final=1.85, loss_mean=1.68, l[[34m2025-10-03 23:26:15[39m] Step: 19, Training Logs: loss_final: 1.857450, loss_mean: 1.695266, proj_loss: -0.001839, loss_mean_cls: 0.118697, deep_loss: 0.045326, grad_norm: 1.190755
Steps:   0%| | 20/1000000 [00:27<325:07:19,  1.17s/it, deep_loss=0.0453, grad_norm=1.19, loss_final=1.86, loss_mean=1.7, los[[34m2025-10-03 23:26:16[39m] Step: 20, Training Logs: loss_final: 1.844619, loss_mean: 1.702542, proj_loss: -0.020595, loss_mean_cls: 0.118579, deep_loss: 0.044093, grad_norm: 1.050217
Steps:   0%| | 21/1000000 [00:28<324:28:19,  1.17s/it, deep_loss=0.0441, grad_norm=1.05, loss_final=1.84, loss_mean=1.7, los[[34m2025-10-03 23:26:17[39m] Step: 21, Training Logs: loss_final: 1.800544, loss_mean: 1.677884, proj_loss: -0.039088, loss_mean_cls: 0.118060, deep_loss: 0.043688, grad_norm: 0.775306
Steps:   0%| | 22/1000000 [00:29<324:49:25,  1.17s/it, deep_loss=0.0437, grad_norm=0.775, loss_final=1.8, loss_mean=1.68, lo[[34m2025-10-03 23:26:18[39m] Step: 22, Training Logs: loss_final: 1.779429, loss_mean: 1.675088, proj_loss: -0.057046, loss_mean_cls: 0.118154, deep_loss: 0.043234, grad_norm: 0.852297
Steps:   0%| | 23/1000000 [00:30<324:41:00,  1.17s/it, deep_loss=0.0432, grad_norm=0.852, loss_final=1.78, loss_mean=1.68, l[[34m2025-10-03 23:26:19[39m] Step: 23, Training Logs: loss_final: 1.779888, loss_mean: 1.684882, proj_loss: -0.066553, loss_mean_cls: 0.118888, deep_loss: 0.042671, grad_norm: 0.965044
Steps:   0%| | 24/1000000 [00:31<325:24:25,  1.17s/it, deep_loss=0.0427, grad_norm=0.965, loss_final=1.78, loss_mean=1.68, l[[34m2025-10-03 23:26:20[39m] Step: 24, Training Logs: loss_final: 1.732833, loss_mean: 1.650599, proj_loss: -0.077307, loss_mean_cls: 0.118220, deep_loss: 0.041321, grad_norm: 0.960293
Steps:   0%| | 25/1000000 [00:32<317:06:50,  1.14s/it, deep_loss=0.0413, grad_norm=0.96, loss_final=1.73, loss_mean=1.65, lo[[34m2025-10-03 23:26:21[39m] Step: 25, Training Logs: loss_final: 1.747092, loss_mean: 1.675151, proj_loss: -0.083633, loss_mean_cls: 0.117665, deep_loss: 0.037908, grad_norm: 1.071154
Steps:   0%| | 26/1000000 [00:33<287:29:39,  1.04s/it, deep_loss=0.0379, grad_norm=1.07, loss_final=1.75, loss_mean=1.68, lo[[34m2025-10-03 23:26:22[39m] Step: 26, Training Logs: loss_final: 1.732247, loss_mean: 1.664828, proj_loss: -0.086854, loss_mean_cls: 0.118246, deep_loss: 0.036027, grad_norm: 1.194038
Steps:   0%| | 27/1000000 [00:34<266:31:37,  1.04it/s, deep_loss=0.036, grad_norm=1.19, loss_final=1.73, loss_mean=1.66, los[[34m2025-10-03 23:26:23[39m] Step: 27, Training Logs: loss_final: 1.740818, loss_mean: 1.677012, proj_loss: -0.090684, loss_mean_cls: 0.117870, deep_loss: 0.036620, grad_norm: 1.458346
Steps:   0%| | 28/1000000 [00:35<252:34:15,  1.10it/s, deep_loss=0.0366, grad_norm=1.46, loss_final=1.74, loss_mean=1.68, lo[[34m2025-10-03 23:26:24[39m] Step: 28, Training Logs: loss_final: 1.726117, loss_mean: 1.666409, proj_loss: -0.095203, loss_mean_cls: 0.118141, deep_loss: 0.036770, grad_norm: 1.446737
Steps:   0%| | 29/1000000 [00:36<246:26:38,  1.13it/s, deep_loss=0.0368, grad_norm=1.45, loss_final=1.73, loss_mean=1.67, lo[[34m2025-10-03 23:26:25[39m] Step: 29, Training Logs: loss_final: 1.709269, loss_mean: 1.651642, proj_loss: -0.096746, loss_mean_cls: 0.118754, deep_loss: 0.035619, grad_norm: 1.320680
Steps:   0%| | 30/1000000 [00:37<269:31:31,  1.03it/s, deep_loss=0.0356, grad_norm=1.32, loss_final=1.71, loss_mean=1.65, lo[[34m2025-10-03 23:26:26[39m] Step: 30, Training Logs: loss_final: 1.716177, loss_mean: 1.663823, proj_loss: -0.099535, loss_mean_cls: 0.117709, deep_loss: 0.034179, grad_norm: 1.129575
Steps:   0%| | 31/1000000 [00:38<286:57:02,  1.03s/it, deep_loss=0.0342, grad_norm=1.13, loss_final=1.72, loss_mean=1.66, lo[[34m2025-10-03 23:26:27[39m] Step: 31, Training Logs: loss_final: 1.678647, loss_mean: 1.629526, proj_loss: -0.103071, loss_mean_cls: 0.117498, deep_loss: 0.034694, grad_norm: 0.943847
Steps:   0%| | 32/1000000 [00:39<298:13:34,  1.07s/it, deep_loss=0.0347, grad_norm=0.944, loss_final=1.68, loss_mean=1.63, l[[34m2025-10-03 23:26:28[39m] Step: 32, Training Logs: loss_final: 1.682899, loss_mean: 1.635468, proj_loss: -0.103929, loss_mean_cls: 0.117073, deep_loss: 0.034288, grad_norm: 1.005134
Steps:   0%| | 33/1000000 [00:40<306:45:41,  1.10s/it, deep_loss=0.0343, grad_norm=1.01, loss_final=1.68, loss_mean=1.64, lo[[34m2025-10-03 23:26:29[39m] Step: 33, Training Logs: loss_final: 1.691422, loss_mean: 1.647628, proj_loss: -0.107760, loss_mean_cls: 0.117478, deep_loss: 0.034075, grad_norm: 1.045364
Steps:   0%| | 34/1000000 [00:41<313:09:09,  1.13s/it, deep_loss=0.0341, grad_norm=1.05, loss_final=1.69, loss_mean=1.65, lo[[34m2025-10-03 23:26:30[39m] Step: 34, Training Logs: loss_final: 1.660637, loss_mean: 1.617001, proj_loss: -0.107513, loss_mean_cls: 0.117152, deep_loss: 0.033998, grad_norm: 0.942616
Steps:   0%| | 35/1000000 [00:43<316:09:29,  1.14s/it, deep_loss=0.034, grad_norm=0.943, loss_final=1.66, loss_mean=1.62, lo[[34m2025-10-03 23:26:32[39m] Step: 35, Training Logs: loss_final: 1.684045, loss_mean: 1.645791, proj_loss: -0.112052, loss_mean_cls: 0.117595, deep_loss: 0.032713, grad_norm: 0.913674
Steps:   0%| | 36/1000000 [00:44<318:59:46,  1.15s/it, deep_loss=0.0327, grad_norm=0.914, loss_final=1.68, loss_mean=1.65, l[[34m2025-10-03 23:26:33[39m] Step: 36, Training Logs: loss_final: 1.642717, loss_mean: 1.604280, proj_loss: -0.112842, loss_mean_cls: 0.117412, deep_loss: 0.033867, grad_norm: 0.967890
Steps:   0%| | 37/1000000 [00:45<321:26:07,  1.16s/it, deep_loss=0.0339, grad_norm=0.968, loss_final=1.64, loss_mean=1.6, lo[[34m2025-10-03 23:26:34[39m] Step: 37, Training Logs: loss_final: 1.644093, loss_mean: 1.610562, proj_loss: -0.116153, loss_mean_cls: 0.116967, deep_loss: 0.032716, grad_norm: 1.056014
Steps:   0%| | 38/1000000 [00:46<323:05:35,  1.16s/it, deep_loss=0.0327, grad_norm=1.06, loss_final=1.64, loss_mean=1.61, lo[[34m2025-10-03 23:26:35[39m] Step: 38, Training Logs: loss_final: 1.658207, loss_mean: 1.626789, proj_loss: -0.119257, loss_mean_cls: 0.117879, deep_loss: 0.032796, grad_norm: 0.941455
Steps:   0%| | 39/1000000 [00:47<324:12:47,  1.17s/it, deep_loss=0.0328, grad_norm=0.941, loss_final=1.66, loss_mean=1.63, l[[34m2025-10-03 23:26:36[39m] Step: 39, Training Logs: loss_final: 1.624300, loss_mean: 1.596063, proj_loss: -0.121545, loss_mean_cls: 0.116626, deep_loss: 0.033156, grad_norm: 0.905618
Steps:   0%| | 40/1000000 [00:48<324:16:39,  1.17s/it, deep_loss=0.0332, grad_norm=0.906, loss_final=1.62, loss_mean=1.6, lo[[34m2025-10-03 23:26:38[39m] Step: 40, Training Logs: loss_final: 1.621074, loss_mean: 1.597490, proj_loss: -0.126396, loss_mean_cls: 0.117717, deep_loss: 0.032264, grad_norm: 0.846665
Steps:   0%| | 41/1000000 [00:50<324:49:01,  1.17s/it, deep_loss=0.0323, grad_norm=0.847, loss_final=1.62, loss_mean=1.6, lo[[34m2025-10-03 23:26:39[39m] Step: 41, Training Logs: loss_final: 1.600162, loss_mean: 1.578737, proj_loss: -0.127753, loss_mean_cls: 0.117250, deep_loss: 0.031929, grad_norm: 0.821030
Steps:   0%| | 42/1000000 [00:51<325:31:38,  1.17s/it, deep_loss=0.0319, grad_norm=0.821, loss_final=1.6, loss_mean=1.58, lo[[34m2025-10-03 23:26:40[39m] Step: 42, Training Logs: loss_final: 1.595330, loss_mean: 1.575721, proj_loss: -0.128980, loss_mean_cls: 0.116559, deep_loss: 0.032031, grad_norm: 0.798184
Steps:   0%| | 43/1000000 [00:52<325:02:23,  1.17s/it, deep_loss=0.032, grad_norm=0.798, loss_final=1.6, loss_mean=1.58, los[[34m2025-10-03 23:26:41[39m] Step: 43, Training Logs: loss_final: 1.575297, loss_mean: 1.557883, proj_loss: -0.131369, loss_mean_cls: 0.116795, deep_loss: 0.031988, grad_norm: 0.750102
Steps:   0%| | 44/1000000 [00:53<324:09:00,  1.17s/it, deep_loss=0.032, grad_norm=0.75, loss_final=1.58, loss_mean=1.56, los[[34m2025-10-03 23:26:42[39m] Step: 44, Training Logs: loss_final: 1.556523, loss_mean: 1.540485, proj_loss: -0.132291, loss_mean_cls: 0.116392, deep_loss: 0.031938, grad_norm: 0.677275
Steps:   0%| | 45/1000000 [00:54<325:48:17,  1.17s/it, deep_loss=0.0319, grad_norm=0.677, loss_final=1.56, loss_mean=1.54, l[[34m2025-10-03 23:26:43[39m] Step: 45, Training Logs: loss_final: 1.542782, loss_mean: 1.526733, proj_loss: -0.133216, loss_mean_cls: 0.116787, deep_loss: 0.032479, grad_norm: 0.920515
Steps:   0%| | 46/1000000 [00:55<326:13:24,  1.17s/it, deep_loss=0.0325, grad_norm=0.921, loss_final=1.54, loss_mean=1.53, l[[34m2025-10-03 23:26:45[39m] Step: 46, Training Logs: loss_final: 1.553559, loss_mean: 1.540362, proj_loss: -0.136130, loss_mean_cls: 0.116073, deep_loss: 0.033254, grad_norm: 1.154952
Steps:   0%| | 47/1000000 [00:57<325:13:49,  1.17s/it, deep_loss=0.0333, grad_norm=1.15, loss_final=1.55, loss_mean=1.54, lo[[34m2025-10-03 23:26:46[39m] Step: 47, Training Logs: loss_final: 1.524724, loss_mean: 1.512530, proj_loss: -0.136114, loss_mean_cls: 0.115780, deep_loss: 0.032527, grad_norm: 0.574934
Steps:   0%| | 48/1000000 [00:58<325:27:12,  1.17s/it, deep_loss=0.0325, grad_norm=0.575, loss_final=1.52, loss_mean=1.51, l[[34m2025-10-03 23:26:47[39m] Step: 48, Training Logs: loss_final: 1.535114, loss_mean: 1.525505, proj_loss: -0.138066, loss_mean_cls: 0.115778, deep_loss: 0.031898, grad_norm: 0.724633
Steps:   0%| | 49/1000000 [00:59<324:36:09,  1.17s/it, deep_loss=0.0319, grad_norm=0.725, loss_final=1.54, loss_mean=1.53, l[[34m2025-10-03 23:26:48[39m] Step: 49, Training Logs: loss_final: 1.537916, loss_mean: 1.528954, proj_loss: -0.138894, loss_mean_cls: 0.116406, deep_loss: 0.031451, grad_norm: 1.132510
Steps:   0%| | 50/1000000 [01:00<325:20:54,  1.17s/it, deep_loss=0.0315, grad_norm=1.13, loss_final=1.54, loss_mean=1.53, lo[[34m2025-10-03 23:26:49[39m] Step: 50, Training Logs: loss_final: 1.539016, loss_mean: 1.530019, proj_loss: -0.139757, loss_mean_cls: 0.116018, deep_loss: 0.032736, grad_norm: 1.625239
Steps:   0%| | 51/1000000 [01:01<325:01:04,  1.17s/it, deep_loss=0.0327, grad_norm=1.63, loss_final=1.54, loss_mean=1.53, lo[[34m2025-10-03 23:26:50[39m] Step: 51, Training Logs: loss_final: 1.527546, loss_mean: 1.520394, proj_loss: -0.139677, loss_mean_cls: 0.115794, deep_loss: 0.031035, grad_norm: 0.747811
Steps:   0%| | 52/1000000 [01:03<325:36:55,  1.17s/it, deep_loss=0.031, grad_norm=0.748, loss_final=1.53, loss_mean=1.52, lo[[34m2025-10-03 23:26:52[39m] Step: 52, Training Logs: loss_final: 1.519969, loss_mean: 1.515359, proj_loss: -0.142827, loss_mean_cls: 0.115316, deep_loss: 0.032121, grad_norm: 2.238130
Steps:   0%| | 53/1000000 [01:04<325:45:43,  1.17s/it, deep_loss=0.0321, grad_norm=2.24, loss_final=1.52, loss_mean=1.52, lo[[34m2025-10-03 23:26:53[39m] Step: 53, Training Logs: loss_final: 1.527988, loss_mean: 1.522946, proj_loss: -0.141904, loss_mean_cls: 0.115068, deep_loss: 0.031879, grad_norm: 2.138056
Steps:   0%| | 54/1000000 [01:05<325:48:45,  1.17s/it, deep_loss=0.0319, grad_norm=2.14, loss_final=1.53, loss_mean=1.52, lo[[34m2025-10-03 23:26:54[39m] Step: 54, Training Logs: loss_final: 1.516918, loss_mean: 1.511791, proj_loss: -0.141808, loss_mean_cls: 0.115613, deep_loss: 0.031322, grad_norm: 0.726289
Steps:   0%| | 55/1000000 [01:06<325:28:30,  1.17s/it, deep_loss=0.0313, grad_norm=0.726, loss_final=1.52, loss_mean=1.51, l[[34m2025-10-03 23:26:55[39m] Step: 55, Training Logs: loss_final: 1.494459, loss_mean: 1.491334, proj_loss: -0.144274, loss_mean_cls: 0.115734, deep_loss: 0.031664, grad_norm: 1.594608
Steps:   0%| | 56/1000000 [01:07<325:10:00,  1.17s/it, deep_loss=0.0317, grad_norm=1.59, loss_final=1.49, loss_mean=1.49, lo[[34m2025-10-03 23:26:56[39m] Step: 56, Training Logs: loss_final: 1.481288, loss_mean: 1.478377, proj_loss: -0.144289, loss_mean_cls: 0.115039, deep_loss: 0.032160, grad_norm: 0.670814
Steps:   0%| | 57/1000000 [01:08<306:23:47,  1.10s/it, deep_loss=0.0322, grad_norm=0.671, loss_final=1.48, loss_mean=1.48, l[[34m2025-10-03 23:26:57[39m] Step: 57, Training Logs: loss_final: 1.512715, loss_mean: 1.510837, proj_loss: -0.145601, loss_mean_cls: 0.115395, deep_loss: 0.032084, grad_norm: 2.114520
Steps:   0%| | 58/1000000 [01:09<280:12:16,  1.01s/it, deep_loss=0.0321, grad_norm=2.11, loss_final=1.51, loss_mean=1.51, lo[[34m2025-10-03 23:26:58[39m] Step: 58, Training Logs: loss_final: 1.448089, loss_mean: 1.446415, proj_loss: -0.144876, loss_mean_cls: 0.115128, deep_loss: 0.031422, grad_norm: 0.723061
Steps:   0%| | 59/1000000 [01:10<262:09:06,  1.06it/s, deep_loss=0.0314, grad_norm=0.723, loss_final=1.45, loss_mean=1.45, l[[34m2025-10-03 23:26:59[39m] Step: 59, Training Logs: loss_final: 1.428188, loss_mean: 1.426179, proj_loss: -0.144035, loss_mean_cls: 0.115210, deep_loss: 0.030834, grad_norm: 1.141568
Steps:   0%| | 60/1000000 [01:11<249:31:20,  1.11it/s, deep_loss=0.0308, grad_norm=1.14, loss_final=1.43, loss_mean=1.43, lo[[34m2025-10-03 23:27:00[39m] Step: 60, Training Logs: loss_final: 1.476831, loss_mean: 1.476496, proj_loss: -0.145646, loss_mean_cls: 0.114250, deep_loss: 0.031731, grad_norm: 2.082066
Steps:   0%| | 61/1000000 [01:11<240:09:24,  1.16it/s, deep_loss=0.0317, grad_norm=2.08, loss_final=1.48, loss_mean=1.48, lo[[34m2025-10-03 23:27:00[39m] Step: 61, Training Logs: loss_final: 1.393705, loss_mean: 1.395781, proj_loss: -0.147238, loss_mean_cls: 0.115313, deep_loss: 0.029849, grad_norm: 1.035394
Steps:   0%| | 62/1000000 [01:12<260:34:49,  1.07it/s, deep_loss=0.0298, grad_norm=1.04, loss_final=1.39, loss_mean=1.4, los[[34m2025-10-03 23:27:01[39m] Step: 62, Training Logs: loss_final: 1.400578, loss_mean: 1.401154, proj_loss: -0.146095, loss_mean_cls: 0.114267, deep_loss: 0.031252, grad_norm: 0.954926
Steps:   0%| | 63/1000000 [01:14<279:41:18,  1.01s/it, deep_loss=0.0313, grad_norm=0.955, loss_final=1.4, loss_mean=1.4, los[[34m2025-10-03 23:27:03[39m] Step: 63, Training Logs: loss_final: 1.388429, loss_mean: 1.388480, proj_loss: -0.145884, loss_mean_cls: 0.115715, deep_loss: 0.030118, grad_norm: 1.281565
Steps:   0%| | 64/1000000 [01:15<293:28:01,  1.06s/it, deep_loss=0.0301, grad_norm=1.28, loss_final=1.39, loss_mean=1.39, lo[[34m2025-10-03 23:27:04[39m] Step: 64, Training Logs: loss_final: 1.382161, loss_mean: 1.382112, proj_loss: -0.145757, loss_mean_cls: 0.114735, deep_loss: 0.031071, grad_norm: 1.001003
Steps:   0%| | 65/1000000 [01:16<303:04:46,  1.09s/it, deep_loss=0.0311, grad_norm=1, loss_final=1.38, loss_mean=1.38, loss_[[34m2025-10-03 23:27:05[39m] Step: 65, Training Logs: loss_final: 1.458098, loss_mean: 1.459059, proj_loss: -0.147491, loss_mean_cls: 0.113281, deep_loss: 0.033249, grad_norm: 2.132532
Steps:   0%| | 66/1000000 [01:17<310:23:32,  1.12s/it, deep_loss=0.0332, grad_norm=2.13, loss_final=1.46, loss_mean=1.46, lo[[34m2025-10-03 23:27:06[39m] Step: 66, Training Logs: loss_final: 1.386988, loss_mean: 1.388404, proj_loss: -0.146428, loss_mean_cls: 0.114051, deep_loss: 0.030961, grad_norm: 1.060534
Steps:   0%| | 67/1000000 [01:18<315:25:42,  1.14s/it, deep_loss=0.031, grad_norm=1.06, loss_final=1.39, loss_mean=1.39, los[[34m2025-10-03 23:27:07[39m] Step: 67, Training Logs: loss_final: 1.397485, loss_mean: 1.399305, proj_loss: -0.147793, loss_mean_cls: 0.114210, deep_loss: 0.031764, grad_norm: 2.177401
Steps:   0%| | 68/1000000 [01:19<318:33:38,  1.15s/it, deep_loss=0.0318, grad_norm=2.18, loss_final=1.4, loss_mean=1.4, loss[[34m2025-10-03 23:27:09[39m] Step: 68, Training Logs: loss_final: 1.400687, loss_mean: 1.402426, proj_loss: -0.147175, loss_mean_cls: 0.113290, deep_loss: 0.032146, grad_norm: 1.870404
Steps:   0%| | 69/1000000 [01:21<320:12:01,  1.15s/it, deep_loss=0.0321, grad_norm=1.87, loss_final=1.4, loss_mean=1.4, loss[[34m2025-10-03 23:27:10[39m] Step: 69, Training Logs: loss_final: 1.380020, loss_mean: 1.380151, proj_loss: -0.145695, loss_mean_cls: 0.114052, deep_loss: 0.031512, grad_norm: 1.201892
Steps:   0%| | 70/1000000 [01:22<321:54:32,  1.16s/it, deep_loss=0.0315, grad_norm=1.2, loss_final=1.38, loss_mean=1.38, los[[34m2025-10-03 23:27:11[39m] Step: 70, Training Logs: loss_final: 1.365879, loss_mean: 1.370807, proj_loss: -0.148653, loss_mean_cls: 0.113368, deep_loss: 0.030356, grad_norm: 1.435735
Steps:   0%| | 71/1000000 [01:23<322:36:41,  1.16s/it, deep_loss=0.0304, grad_norm=1.44, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:12[39m] Step: 71, Training Logs: loss_final: 1.434862, loss_mean: 1.437857, proj_loss: -0.148359, loss_mean_cls: 0.113269, deep_loss: 0.032095, grad_norm: 1.761425
Steps:   0%| | 72/1000000 [01:24<323:29:22,  1.16s/it, deep_loss=0.0321, grad_norm=1.76, loss_final=1.43, loss_mean=1.44, lo[[34m2025-10-03 23:27:13[39m] Step: 72, Training Logs: loss_final: 1.370749, loss_mean: 1.374900, proj_loss: -0.148432, loss_mean_cls: 0.113149, deep_loss: 0.031131, grad_norm: 1.393311
Steps:   0%| | 73/1000000 [01:25<324:07:10,  1.17s/it, deep_loss=0.0311, grad_norm=1.39, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:14[39m] Step: 73, Training Logs: loss_final: 1.372904, loss_mean: 1.376174, proj_loss: -0.147473, loss_mean_cls: 0.113760, deep_loss: 0.030442, grad_norm: 0.760629
Steps:   0%| | 74/1000000 [01:26<325:01:01,  1.17s/it, deep_loss=0.0304, grad_norm=0.761, loss_final=1.37, loss_mean=1.38, l[[34m2025-10-03 23:27:16[39m] Step: 74, Training Logs: loss_final: 1.384867, loss_mean: 1.388312, proj_loss: -0.148247, loss_mean_cls: 0.113291, deep_loss: 0.031510, grad_norm: 1.227866
Steps:   0%| | 75/1000000 [01:28<325:43:18,  1.17s/it, deep_loss=0.0315, grad_norm=1.23, loss_final=1.38, loss_mean=1.39, lo[[34m2025-10-03 23:27:17[39m] Step: 75, Training Logs: loss_final: 1.367743, loss_mean: 1.369634, proj_loss: -0.147108, loss_mean_cls: 0.114157, deep_loss: 0.031061, grad_norm: 1.356719
Steps:   0%| | 76/1000000 [01:29<325:22:01,  1.17s/it, deep_loss=0.0311, grad_norm=1.36, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:18[39m] Step: 76, Training Logs: loss_final: 1.360975, loss_mean: 1.364668, proj_loss: -0.146848, loss_mean_cls: 0.113721, deep_loss: 0.029435, grad_norm: 1.091693
Steps:   0%| | 77/1000000 [01:30<325:00:32,  1.17s/it, deep_loss=0.0294, grad_norm=1.09, loss_final=1.36, loss_mean=1.36, lo[[34m2025-10-03 23:27:19[39m] Step: 77, Training Logs: loss_final: 1.355385, loss_mean: 1.358471, proj_loss: -0.146537, loss_mean_cls: 0.113439, deep_loss: 0.030012, grad_norm: 1.606235
Steps:   0%| | 78/1000000 [01:31<324:22:36,  1.17s/it, deep_loss=0.03, grad_norm=1.61, loss_final=1.36, loss_mean=1.36, loss[[34m2025-10-03 23:27:20[39m] Step: 78, Training Logs: loss_final: 1.365222, loss_mean: 1.369626, proj_loss: -0.148251, loss_mean_cls: 0.113004, deep_loss: 0.030844, grad_norm: 1.505935
Steps:   0%| | 79/1000000 [01:32<325:10:24,  1.17s/it, deep_loss=0.0308, grad_norm=1.51, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:21[39m] Step: 79, Training Logs: loss_final: 1.376589, loss_mean: 1.379272, proj_loss: -0.147050, loss_mean_cls: 0.113281, deep_loss: 0.031085, grad_norm: 2.025146
Steps:   0%| | 80/1000000 [01:34<325:23:12,  1.17s/it, deep_loss=0.0311, grad_norm=2.03, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:27:23[39m] Step: 80, Training Logs: loss_final: 1.376840, loss_mean: 1.380692, proj_loss: -0.147420, loss_mean_cls: 0.112921, deep_loss: 0.030646, grad_norm: 2.270174
Steps:   0%| | 81/1000000 [01:35<325:03:38,  1.17s/it, deep_loss=0.0306, grad_norm=2.27, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:27:24[39m] Step: 81, Training Logs: loss_final: 1.409921, loss_mean: 1.412698, proj_loss: -0.147436, loss_mean_cls: 0.112306, deep_loss: 0.032353, grad_norm: 4.125180
Steps:   0%| | 82/1000000 [01:36<325:16:48,  1.17s/it, deep_loss=0.0324, grad_norm=4.13, loss_final=1.41, loss_mean=1.41, lo[[34m2025-10-03 23:27:25[39m] Step: 82, Training Logs: loss_final: 1.422737, loss_mean: 1.425087, proj_loss: -0.147333, loss_mean_cls: 0.112843, deep_loss: 0.032139, grad_norm: 4.488738
Steps:   0%| | 83/1000000 [01:37<325:25:01,  1.17s/it, deep_loss=0.0321, grad_norm=4.49, loss_final=1.42, loss_mean=1.43, lo[[34m2025-10-03 23:27:26[39m] Step: 83, Training Logs: loss_final: 1.456409, loss_mean: 1.460819, proj_loss: -0.150044, loss_mean_cls: 0.112475, deep_loss: 0.033158, grad_norm: 5.539126
Steps:   0%| | 84/1000000 [01:38<325:30:44,  1.17s/it, deep_loss=0.0332, grad_norm=5.54, loss_final=1.46, loss_mean=1.46, lo[[34m2025-10-03 23:27:27[39m] Step: 84, Training Logs: loss_final: 1.377733, loss_mean: 1.379817, proj_loss: -0.145715, loss_mean_cls: 0.112586, deep_loss: 0.031045, grad_norm: 3.640758
Steps:   0%| | 85/1000000 [01:39<325:19:30,  1.17s/it, deep_loss=0.031, grad_norm=3.64, loss_final=1.38, loss_mean=1.38, los[[34m2025-10-03 23:27:28[39m] Step: 85, Training Logs: loss_final: 1.393870, loss_mean: 1.396511, proj_loss: -0.146169, loss_mean_cls: 0.112365, deep_loss: 0.031163, grad_norm: 5.068495
Steps:   0%| | 86/1000000 [01:41<326:16:15,  1.17s/it, deep_loss=0.0312, grad_norm=5.07, loss_final=1.39, loss_mean=1.4, los[[34m2025-10-03 23:27:30[39m] Step: 86, Training Logs: loss_final: 1.403761, loss_mean: 1.406604, proj_loss: -0.147029, loss_mean_cls: 0.113158, deep_loss: 0.031029, grad_norm: 5.224255
Steps:   0%| | 87/1000000 [01:42<326:02:23,  1.17s/it, deep_loss=0.031, grad_norm=5.22, loss_final=1.4, loss_mean=1.41, loss[[34m2025-10-03 23:27:31[39m] Step: 87, Training Logs: loss_final: 1.413681, loss_mean: 1.417472, proj_loss: -0.147366, loss_mean_cls: 0.112464, deep_loss: 0.031111, grad_norm: 3.899454
Steps:   0%| | 88/1000000 [01:43<326:17:43,  1.17s/it, deep_loss=0.0311, grad_norm=3.9, loss_final=1.41, loss_mean=1.42, los[[34m2025-10-03 23:27:32[39m] Step: 88, Training Logs: loss_final: 1.436558, loss_mean: 1.437461, proj_loss: -0.146537, loss_mean_cls: 0.112322, deep_loss: 0.033312, grad_norm: 5.843190
Steps:   0%| | 89/1000000 [01:44<314:07:54,  1.13s/it, deep_loss=0.0333, grad_norm=5.84, loss_final=1.44, loss_mean=1.44, lo[[34m2025-10-03 23:27:33[39m] Step: 89, Training Logs: loss_final: 1.366597, loss_mean: 1.369687, proj_loss: -0.147070, loss_mean_cls: 0.112711, deep_loss: 0.031269, grad_norm: 4.328040
Steps:   0%| | 90/1000000 [01:45<285:47:58,  1.03s/it, deep_loss=0.0313, grad_norm=4.33, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:34[39m] Step: 90, Training Logs: loss_final: 1.383086, loss_mean: 1.388854, proj_loss: -0.148631, loss_mean_cls: 0.111718, deep_loss: 0.031144, grad_norm: 4.337485
Steps:   0%| | 91/1000000 [01:46<266:05:29,  1.04it/s, deep_loss=0.0311, grad_norm=4.34, loss_final=1.38, loss_mean=1.39, lo[[34m2025-10-03 23:27:35[39m] Step: 91, Training Logs: loss_final: 1.373240, loss_mean: 1.377749, proj_loss: -0.148036, loss_mean_cls: 0.112222, deep_loss: 0.031305, grad_norm: 3.572266
Steps:   0%| | 92/1000000 [01:46<252:39:16,  1.10it/s, deep_loss=0.0313, grad_norm=3.57, loss_final=1.37, loss_mean=1.38, lo[[34m2025-10-03 23:27:35[39m] Step: 92, Training Logs: loss_final: 1.368219, loss_mean: 1.373355, proj_loss: -0.149216, loss_mean_cls: 0.112549, deep_loss: 0.031532, grad_norm: 4.128796
Steps:   0%| | 93/1000000 [01:47<242:32:29,  1.15it/s, deep_loss=0.0315, grad_norm=4.13, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:36[39m] Step: 93, Training Logs: loss_final: 1.396704, loss_mean: 1.401251, proj_loss: -0.146881, loss_mean_cls: 0.111034, deep_loss: 0.031300, grad_norm: 4.254699
Steps:   0%| | 94/1000000 [01:48<235:52:18,  1.18it/s, deep_loss=0.0313, grad_norm=4.25, loss_final=1.4, loss_mean=1.4, loss[[34m2025-10-03 23:27:37[39m] Step: 94, Training Logs: loss_final: 1.377566, loss_mean: 1.382129, proj_loss: -0.148522, loss_mean_cls: 0.112532, deep_loss: 0.031427, grad_norm: 4.286557
Steps:   0%| | 95/1000000 [01:49<230:41:38,  1.20it/s, deep_loss=0.0314, grad_norm=4.29, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:27:38[39m] Step: 95, Training Logs: loss_final: 1.377148, loss_mean: 1.381670, proj_loss: -0.146720, loss_mean_cls: 0.111505, deep_loss: 0.030692, grad_norm: 4.186183
Steps:   0%| | 96/1000000 [01:50<251:38:26,  1.10it/s, deep_loss=0.0307, grad_norm=4.19, loss_final=1.38, loss_mean=1.38, lo[[34m2025-10-03 23:27:39[39m] Step: 96, Training Logs: loss_final: 1.398079, loss_mean: 1.401095, proj_loss: -0.146536, loss_mean_cls: 0.111871, deep_loss: 0.031649, grad_norm: 4.013966
Steps:   0%| | 97/1000000 [01:51<273:55:55,  1.01it/s, deep_loss=0.0316, grad_norm=4.01, loss_final=1.4, loss_mean=1.4, loss[[34m2025-10-03 23:27:40[39m] Step: 97, Training Logs: loss_final: 1.383999, loss_mean: 1.388237, proj_loss: -0.147856, loss_mean_cls: 0.111881, deep_loss: 0.031737, grad_norm: 2.514960
Steps:   0%| | 98/1000000 [01:52<289:26:29,  1.04s/it, deep_loss=0.0317, grad_norm=2.51, loss_final=1.38, loss_mean=1.39, lo[[34m2025-10-03 23:27:41[39m] Step: 98, Training Logs: loss_final: 1.365075, loss_mean: 1.367155, proj_loss: -0.146178, loss_mean_cls: 0.112190, deep_loss: 0.031908, grad_norm: 3.305807
Steps:   0%| | 99/1000000 [01:53<300:42:24,  1.08s/it, deep_loss=0.0319, grad_norm=3.31, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:42[39m] Step: 99, Training Logs: loss_final: 1.385798, loss_mean: 1.389102, proj_loss: -0.146884, loss_mean_cls: 0.111630, deep_loss: 0.031951, grad_norm: 3.520928
Steps:   0%| | 101/1000000 [01:56<313:41:26,  1.13s/it, deep_loss=0.0307, grad_norm=2.62, loss_final=1.37, loss_mean=1.38, l[[34m2025-10-03 23:27:45[39m] Step: 101, Training Logs: loss_final: 1.369577, loss_mean: 1.372960, proj_loss: -0.145414, loss_mean_cls: 0.112113, deep_loss: 0.029918, grad_norm: 3.708468
Steps:   0%| | 101/1000000 [01:56<313:41:26,  1.13s/it, deep_loss=0.0307, grad_norm=2.62, loss_final=1.37, loss_mean=1.38, l[[34m2025-10-03 23:27:45[39m] Step: 101, Training Logs: loss_final: 1.369577, loss_mean: 1.372960, proj_loss: -0.145414, loss_mean_cls: 0.112113, deep_loss: 0.029918, grad_norm: 3.708468
Steps:   0%| | 103/1000000 [01:58<318:46:02,  1.15s/it, deep_loss=0.0318, grad_norm=3.27, loss_final=1.37, loss_mean=1.37, l[[34m2025-10-03 23:27:46[39m] Step: 102, Training Logs: loss_final: 1.360885, loss_mean: 1.366501, proj_loss: -0.148089, loss_mean_cls: 0.111916, deep_loss: 0.030556, grad_norm: 3.726048
Steps:   0%| | 103/1000000 [01:58<318:46:02,  1.15s/it, deep_loss=0.0306, grad_norm=3.73, loss_final=1.36, loss_mean=1.37, l[[34m2025-10-03 23:27:47[39m] Step: 103, Training Logs: loss_final: 1.369436, loss_mean: 1.374147, proj_loss: -0.148711, loss_mean_cls: 0.112178, deep_loss: 0.031821, grad_norm: 3.273155
Steps:   0%| | 105/1000000 [02:00<322:03:37,  1.16s/it, deep_loss=0.0321, grad_norm=5.96, loss_final=1.39, loss_mean=1.39, l[[34m2025-10-03 23:27:48[39m] Step: 104, Training Logs: loss_final: 1.371068, loss_mean: 1.375049, proj_loss: -0.146559, loss_mean_cls: 0.111396, deep_loss: 0.031182, grad_norm: 4.075589
Steps:   0%| | 105/1000000 [02:00<322:03:37,  1.16s/it, deep_loss=0.0312, grad_norm=4.08, loss_final=1.37, loss_mean=1.38, l[[34m2025-10-03 23:27:49[39m] Step: 105, Training Logs: loss_final: 1.388678, loss_mean: 1.390479, proj_loss: -0.145680, loss_mean_cls: 0.111729, deep_loss: 0.032149, grad_norm: 5.957345
Steps:   0%| | 106/1000000 [02:01<323:08:26,  1.16s/it, deep_loss=0.0321, grad_norm=5.96, loss_final=1.39, loss_mean=1.39, l[[34m2025-10-03 23:27:51[39m] Step: 106, Training Logs: loss_final: 1.452505, loss_mean: 1.454541, proj_loss: -0.146827, loss_mean_cls: 0.112081, deep_loss: 0.032710, grad_norm: 9.355639
Steps:   0%| | 106/1000000 [02:02<323:08:26,  1.16s/it, deep_loss=0.0327, grad_norm=9.36, loss_final=1.45, loss_mean=1.45, l
Steps:   0%| | 108/1000000 [02:04<324:51:09,  1.17s/it, deep_loss=0.0314, grad_norm=4.9, loss_final=1.37, loss_mean=1.37, lo[[34m2025-10-03 23:27:53[39m] Step: 108, Training Logs: loss_final: 1.388630, loss_mean: 1.390730, proj_loss: -0.145891, loss_mean_cls: 0.112462, deep_loss: 0.031329, grad_norm: 6.167366
Steps:   0%| | 108/1000000 [02:04<324:51:09,  1.17s/it, deep_loss=0.0313, grad_norm=6.17, loss_final=1.39, loss_mean=1.39, l
Steps:   0%| | 110/1000000 [02:06<325:38:48,  1.17s/it, deep_loss=0.0328, grad_norm=5.78, loss_final=1.43, loss_mean=1.43, l[[34m2025-10-03 23:27:55[39m] Step: 110, Training Logs: loss_final: 1.400452, loss_mean: 1.402396, proj_loss: -0.144890, loss_mean_cls: 0.111834, deep_loss: 0.031112, grad_norm: 4.741098
Steps:   0%| | 110/1000000 [02:06<325:38:48,  1.17s/it, deep_loss=0.0311, grad_norm=4.74, loss_final=1.4, loss_mean=1.4, los
Steps:   0%| | 111/1000000 [02:07<325:38:22,  1.17s/it, deep_loss=0.0313, grad_norm=4.08, loss_final=1.4, loss_mean=1.4, los[[34m2025-10-03 23:27:55[39m] Step: 110, Training Logs: loss_final: 1.400452, loss_mean: 1.402396, proj_loss: -0.144890, loss_mean_cls: 0.111834, deep_loss: 0.031112, grad_norm: 4.741098
Steps:   0%| | 113/1000000 [02:10<325:21:33,  1.17s/it, deep_loss=0.0312, grad_norm=5.04, loss_final=1.39, loss_mean=1.39, l[[34m2025-10-03 23:27:58[39m] Step: 112, Training Logs: loss_final: 1.428136, loss_mean: 1.427764, proj_loss: -0.143889, loss_mean_cls: 0.112098, deep_loss: 0.032162, grad_norm: 5.197307
Steps:   0%| | 115/1000000 [02:12<325:31:20,  1.17s/it, deep_loss=0.0309, grad_norm=4.25, loss_final=1.38, loss_mean=1.38, l[[34m2025-10-03 23:28:00[39m] Step: 114, Training Logs: loss_final: 1.381123, loss_mean: 1.382056, proj_loss: -0.144733, loss_mean_cls: 0.112059, deep_loss: 0.031741, grad_norm: 4.201500
Steps:   0%| | 117/1000000 [02:14<325:14:31,  1.17s/it, deep_loss=0.0323, grad_norm=4.31, loss_final=1.39, loss_mean=1.39, l[[34m2025-10-03 23:28:02[39m] Step: 116, Training Logs: loss_final: 1.406655, loss_mean: 1.404388, proj_loss: -0.142440, loss_mean_cls: 0.112616, deep_loss: 0.032091, grad_norm: 4.541863
Steps:   0%| | 118/1000000 [02:16<325:23:32,  1.17s/it, deep_loss=0.0323, grad_norm=4.31, loss_final=1.39, loss_mean=1.39, l[[34m2025-10-03 23:28:05[39m] Step: 118, Training Logs: loss_final: 1.393821, loss_mean: 1.390884, proj_loss: -0.141203, loss_mean_cls: 0.112582, deep_loss: 0.031558, grad_norm: 7.052070
Steps:   0%| | 120/1000000 [02:18<325:50:46,  1.17s/it, deep_loss=0.0318, grad_norm=5.61, loss_final=1.39, loss_mean=1.38, l[[34m2025-10-03 23:28:07[39m] Step: 120, Training Logs: loss_final: 1.398700, loss_mean: 1.395452, proj_loss: -0.140958, loss_mean_cls: 0.112007, deep_loss: 0.032199, grad_norm: 5.643440
Steps:   0%| | 122/1000000 [02:20<325:00:25,  1.17s/it, deep_loss=0.0332, grad_norm=9.38, loss_final=1.45, loss_mean=1.45, l[[34m2025-10-03 23:28:09[39m] Step: 122, Training Logs: loss_final: 1.451224, loss_mean: 1.445203, proj_loss: -0.140288, loss_mean_cls: 0.113352, deep_loss: 0.032956, grad_norm: 13.141263
Steps:   0%| | 124/1000000 [02:22<286:59:11,  1.03s/it, deep_loss=0.0327, grad_norm=7.01, loss_final=1.41, loss_mean=1.4, lo[[34m2025-10-03 23:28:11[39m] Step: 124, Training Logs: loss_final: 1.469845, loss_mean: 1.463537, proj_loss: -0.139446, loss_mean_cls: 0.112322, deep_loss: 0.033432, grad_norm: 10.974236
Steps:   0%| | 127/1000000 [02:24<241:30:00,  1.15it/s, deep_loss=0.033, grad_norm=8.72, loss_final=1.45, loss_mean=1.44, lo[[34m2025-10-03 23:28:13[39m] Step: 126, Training Logs: loss_final: 1.424301, loss_mean: 1.416788, proj_loss: -0.137156, loss_mean_cls: 0.112553, deep_loss: 0.032116, grad_norm: 7.9843776
Steps:   0%| | 129/1000000 [02:26<250:20:55,  1.11it/s, deep_loss=0.0334, grad_norm=9.06, loss_final=1.43, loss_mean=1.42, l[[34m2025-10-03 23:28:14[39m] Step: 128, Training Logs: loss_final: 1.427860, loss_mean: 1.420069, proj_loss: -0.137004, loss_mean_cls: 0.111306, deep_loss: 0.033489, grad_norm: 8.5255546
Steps:   0%| | 130/1000000 [02:27<273:27:35,  1.02it/s, deep_loss=0.0334, grad_norm=9.06, loss_final=1.43, loss_mean=1.42, l[[34m2025-10-03 23:28:17[39m] Step: 130, Training Logs: loss_final: 1.434410, loss_mean: 1.427559, proj_loss: -0.137928, loss_mean_cls: 0.111002, deep_loss: 0.033777, grad_norm: 7.2489046
Steps:   0%| | 132/1000000 [02:30<299:25:51,  1.08s/it, deep_loss=0.0329, grad_norm=7.63, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:28:19[39m] Step: 132, Training Logs: loss_final: 1.380185, loss_mean: 1.372767, proj_loss: -0.136360, loss_mean_cls: 0.112922, deep_loss: 0.030856, grad_norm: 4.9408846
Steps:   0%| | 134/1000000 [02:32<312:17:24,  1.12s/it, deep_loss=0.0325, grad_norm=6.7, loss_final=1.41, loss_mean=1.4, los[[34m2025-10-03 23:28:21[39m] Step: 134, Training Logs: loss_final: 1.415871, loss_mean: 1.408394, proj_loss: -0.135964, loss_mean_cls: 0.111398, deep_loss: 0.032042, grad_norm: 6.0861796
Steps:   0%| | 136/1000000 [02:34<318:27:08,  1.15s/it, deep_loss=0.0332, grad_norm=10.2, loss_final=1.45, loss_mean=1.44, l[[34m2025-10-03 23:28:24[39m] Step: 136, Training Logs: loss_final: 1.423965, loss_mean: 1.412838, proj_loss: -0.134279, loss_mean_cls: 0.112524, deep_loss: 0.032883, grad_norm: 9.0126166
Steps:   0%| | 137/1000000 [02:36<321:03:00,  1.16s/it, deep_loss=0.0315, grad_norm=6.66, loss_final=1.39, loss_mean=1.38, l[[34m2025-10-03 23:28:24[39m] Step: 136, Training Logs: loss_final: 1.423965, loss_mean: 1.412838, proj_loss: -0.134279, loss_mean_cls: 0.112524, deep_loss: 0.032883, grad_norm: 9.0126166
Steps:   0%| | 139/1000000 [02:38<352:02:44,  1.27s/it, deep_loss=0.0324, grad_norm=9.77, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:28:26[39m] Step: 138, Training Logs: loss_final: 1.423571, loss_mean: 1.413944, proj_loss: -0.135181, loss_mean_cls: 0.112473, deep_loss: 0.032335, grad_norm: 10.574692
Steps:   0%| | 140/1000000 [02:39<343:45:15,  1.24s/it, deep_loss=0.0324, grad_norm=9.77, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:28:29[39m] Step: 140, Training Logs: loss_final: 1.423257, loss_mean: 1.412309, proj_loss: -0.133872, loss_mean_cls: 0.111963, deep_loss: 0.032857, grad_norm: 6.9173572
Steps:   0%| | 142/1000000 [02:42<333:50:54,  1.20s/it, deep_loss=0.0335, grad_norm=9.87, loss_final=1.43, loss_mean=1.42, l[[34m2025-10-03 23:28:31[39m] Step: 142, Training Logs: loss_final: 1.404531, loss_mean: 1.395299, proj_loss: -0.134755, loss_mean_cls: 0.112686, deep_loss: 0.031301, grad_norm: 6.7961752
Steps:   0%| | 144/1000000 [02:44<329:32:40,  1.19s/it, deep_loss=0.0314, grad_norm=9.32, loss_final=1.4, loss_mean=1.39, lo[[34m2025-10-03 23:28:33[39m] Step: 144, Training Logs: loss_final: 1.370990, loss_mean: 1.361726, proj_loss: -0.135116, loss_mean_cls: 0.112369, deep_loss: 0.032011, grad_norm: 6.7742552
Steps:   0%| | 146/1000000 [02:46<327:23:05,  1.18s/it, deep_loss=0.0318, grad_norm=8.07, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:28:36[39m] Step: 146, Training Logs: loss_final: 1.423231, loss_mean: 1.412597, proj_loss: -0.133784, loss_mean_cls: 0.111545, deep_loss: 0.032872, grad_norm: 6.8087432
Steps:   0%| | 147/1000000 [02:48<326:51:02,  1.18s/it, deep_loss=0.0312, grad_norm=7.66, loss_final=1.42, loss_mean=1.41, l[[34m2025-10-03 23:28:36[39m] Step: 146, Training Logs: loss_final: 1.423231, loss_mean: 1.412597, proj_loss: -0.133784, loss_mean_cls: 0.111545, deep_loss: 0.032872, grad_norm: 6.8087432
Steps:   0%| | 149/1000000 [02:50<325:53:54,  1.17s/it, deep_loss=0.0315, grad_norm=5.08, loss_final=1.37, loss_mean=1.36, l[[34m2025-10-03 23:28:38[39m] Step: 148, Training Logs: loss_final: 1.407819, loss_mean: 1.396954, proj_loss: -0.133068, loss_mean_cls: 0.111922, deep_loss: 0.032011, grad_norm: 6.7206112
Steps:   0%| | 151/1000000 [02:52<326:03:57,  1.17s/it, deep_loss=0.0315, grad_norm=4.44, loss_final=1.39, loss_mean=1.37, l[[34m2025-10-03 23:28:40[39m] Step: 150, Training Logs: loss_final: 1.384568, loss_mean: 1.372156, proj_loss: -0.131717, loss_mean_cls: 0.112788, deep_loss: 0.031341, grad_norm: 6.8318672
Steps:   0%| | 152/1000000 [02:54<326:48:06,  1.18s/it, deep_loss=0.0315, grad_norm=4.44, loss_final=1.39, loss_mean=1.37, l[[34m2025-10-03 23:28:43[39m] Step: 152, Training Logs: loss_final: 1.379476, loss_mean: 1.366643, proj_loss: -0.130722, loss_mean_cls: 0.112015, deep_loss: 0.031540, grad_norm: 6.6847582
Steps:   0%| | 154/1000000 [02:56<326:09:04,  1.17s/it, deep_loss=0.0325, grad_norm=7.25, loss_final=1.39, loss_mean=1.38, l[[34m2025-10-03 23:28:45[39m] Step: 154, Training Logs: loss_final: 1.400274, loss_mean: 1.385999, proj_loss: -0.130424, loss_mean_cls: 0.112136, deep_loss: 0.032562, grad_norm: 6.7906182
Steps:   0%| | 156/1000000 [02:58<307:40:16,  1.11s/it, deep_loss=0.0307, grad_norm=7.42, loss_final=1.4, loss_mean=1.39, lo[[34m2025-10-03 23:28:47[39m] Step: 156, Training Logs: loss_final: 1.348887, loss_mean: 1.332829, proj_loss: -0.127816, loss_mean_cls: 0.113660, deep_loss: 0.030214, grad_norm: 5.7789792
Steps:   0%| | 159/1000000 [03:00<249:28:33,  1.11it/s, deep_loss=0.0315, grad_norm=9.47, loss_final=1.4, loss_mean=1.39, lo[[34m2025-10-03 23:28:49[39m] Step: 158, Training Logs: loss_final: 1.399638, loss_mean: 1.378208, proj_loss: -0.122745, loss_mean_cls: 0.112939, deep_loss: 0.031237, grad_norm: 5.9990912
Steps:   0%| | 161/1000000 [03:02<234:49:17,  1.18it/s, deep_loss=0.0318, grad_norm=7.52, loss_final=1.39, loss_mean=1.37, l[[34m2025-10-03 23:28:50[39m] Step: 160, Training Logs: loss_final: 1.398175, loss_mean: 1.378119, proj_loss: -0.123715, loss_mean_cls: 0.111835, deep_loss: 0.031936, grad_norm: 6.4524852
Steps:   0%| | 163/1000000 [03:04<278:29:16,  1.00s/it, deep_loss=0.0309, grad_norm=5.21, loss_final=1.38, loss_mean=1.36, l[[34m2025-10-03 23:28:52[39m] Step: 162, Training Logs: loss_final: 1.399625, loss_mean: 1.375181, proj_loss: -0.119834, loss_mean_cls: 0.112951, deep_loss: 0.031326, grad_norm: 6.9860732
Steps:   0%| | 164/1000000 [03:05<293:15:29,  1.06s/it, deep_loss=0.0309, grad_norm=5.21, loss_final=1.38, loss_mean=1.36, l[[34m2025-10-03 23:28:55[39m] Step: 164, Training Logs: loss_final: 1.383909, loss_mean: 1.356377, proj_loss: -0.116781, loss_mean_cls: 0.113115, deep_loss: 0.031198, grad_norm: 8.2818882
Steps:   0%| | 166/1000000 [03:08<309:40:39,  1.12s/it, deep_loss=0.0325, grad_norm=7.59, loss_final=1.43, loss_mean=1.4, lo[[34m2025-10-03 23:28:57[39m] Step: 166, Training Logs: loss_final: 1.379403, loss_mean: 1.350715, proj_loss: -0.115866, loss_mean_cls: 0.113182, deep_loss: 0.031372, grad_norm: 6.4019782
Steps:   0%| | 168/1000000 [03:10<317:05:53,  1.14s/it, deep_loss=0.032, grad_norm=10.3, loss_final=1.42, loss_mean=1.38, lo[[34m2025-10-03 23:28:59[39m] Step: 168, Training Logs: loss_final: 1.375115, loss_mean: 1.340219, proj_loss: -0.109764, loss_mean_cls: 0.113311, deep_loss: 0.031348, grad_norm: 6.9563212
Steps:   0%| | 170/1000000 [03:12<321:22:27,  1.16s/it, deep_loss=0.0316, grad_norm=8.95, loss_final=1.4, loss_mean=1.37, lo[[34m2025-10-03 23:29:02[39m] Step: 170, Training Logs: loss_final: 1.405192, loss_mean: 1.370042, proj_loss: -0.109189, loss_mean_cls: 0.112478, deep_loss: 0.031861, grad_norm: 8.3838812
Steps:   0%| | 171/1000000 [03:14<322:15:12,  1.16s/it, deep_loss=0.0328, grad_norm=8.98, loss_final=1.42, loss_mean=1.39, l[[34m2025-10-03 23:29:02[39m] Step: 170, Training Logs: loss_final: 1.405192, loss_mean: 1.370042, proj_loss: -0.109189, loss_mean_cls: 0.112478, deep_loss: 0.031861, grad_norm: 8.3838812
Steps:   0%| | 173/1000000 [03:16<324:52:36,  1.17s/it, deep_loss=0.0315, grad_norm=5.86, loss_final=1.4, loss_mean=1.37, lo[[34m2025-10-03 23:29:04[39m] Step: 172, Training Logs: loss_final: 1.389766, loss_mean: 1.348792, proj_loss: -0.103739, loss_mean_cls: 0.113364, deep_loss: 0.031349, grad_norm: 8.4487392
Steps:   0%| | 175/1000000 [03:18<324:32:44,  1.17s/it, deep_loss=0.0325, grad_norm=10.2, loss_final=1.42, loss_mean=1.38, l[[34m2025-10-03 23:29:06[39m] Step: 174, Training Logs: loss_final: 1.402457, loss_mean: 1.360868, proj_loss: -0.102728, loss_mean_cls: 0.113030, deep_loss: 0.031286, grad_norm: 8.6488262
Steps:   0%| | 176/1000000 [03:20<325:27:36,  1.17s/it, deep_loss=0.0325, grad_norm=10.2, loss_final=1.42, loss_mean=1.38, l[[34m2025-10-03 23:29:09[39m] Step: 176, Training Logs: loss_final: 1.396255, loss_mean: 1.353704, proj_loss: -0.100426, loss_mean_cls: 0.111898, deep_loss: 0.031079, grad_norm: 7.6254932
Steps:   0%| | 178/1000000 [03:22<325:03:44,  1.17s/it, deep_loss=0.0317, grad_norm=4.36, loss_final=1.4, loss_mean=1.35, lo[[34m2025-10-03 23:29:11[39m] Step: 178, Training Logs: loss_final: 1.403165, loss_mean: 1.355837, proj_loss: -0.097419, loss_mean_cls: 0.112871, deep_loss: 0.031876, grad_norm: 6.8951652
Steps:   0%| | 180/1000000 [03:24<324:07:32,  1.17s/it, deep_loss=0.031, grad_norm=7.75, loss_final=1.39, loss_mean=1.34, lo[[34m2025-10-03 23:29:13[39m] Step: 180, Training Logs: loss_final: 1.398921, loss_mean: 1.348161, proj_loss: -0.093213, loss_mean_cls: 0.112516, deep_loss: 0.031457, grad_norm: 6.3112162
Steps:   0%| | 182/1000000 [03:27<324:32:52,  1.17s/it, deep_loss=0.0314, grad_norm=6.44, loss_final=1.38, loss_mean=1.33, l[[34m2025-10-03 23:29:16[39m] Step: 182, Training Logs: loss_final: 1.362164, loss_mean: 1.312003, proj_loss: -0.093475, loss_mean_cls: 0.112565, deep_loss: 0.031070, grad_norm: 7.5435332
Steps:   0%| | 183/1000000 [03:28<324:28:14,  1.17s/it, deep_loss=0.031, grad_norm=6, loss_final=1.4, loss_mean=1.35, loss_m[[34m2025-10-03 23:29:16[39m] Step: 182, Training Logs: loss_final: 1.362164, loss_mean: 1.312003, proj_loss: -0.093475, loss_mean_cls: 0.112565, deep_loss: 0.031070, grad_norm: 7.5435332
Steps:   0%| | 185/1000000 [03:30<325:09:37,  1.17s/it, deep_loss=0.0312, grad_norm=8.97, loss_final=1.39, loss_mean=1.34, l[[34m2025-10-03 23:29:18[39m] Step: 184, Training Logs: loss_final: 1.413031, loss_mean: 1.354998, proj_loss: -0.086784, loss_mean_cls: 0.113160, deep_loss: 0.031656, grad_norm: 9.8564442
Steps:   0%| | 187/1000000 [03:32<325:06:04,  1.17s/it, deep_loss=0.0313, grad_norm=8.32, loss_final=1.4, loss_mean=1.34, lo[[34m2025-10-03 23:29:20[39m] Step: 186, Training Logs: loss_final: 1.443590, loss_mean: 1.384870, proj_loss: -0.085698, loss_mean_cls: 0.111669, deep_loss: 0.032748, grad_norm: 7.2628012
Steps:   0%| | 189/1000000 [03:35<313:41:35,  1.13s/it, deep_loss=0.0313, grad_norm=11.9, loss_final=1.43, loss_mean=1.37, l[[34m2025-10-03 23:29:23[39m] Step: 188, Training Logs: loss_final: 1.411583, loss_mean: 1.348082, proj_loss: -0.080918, loss_mean_cls: 0.112746, deep_loss: 0.031673, grad_norm: 11.007234
Steps:   0%| | 191/1000000 [03:36<265:07:13,  1.05it/s, deep_loss=0.0315, grad_norm=10.8, loss_final=1.44, loss_mean=1.38, l[[34m2025-10-03 23:29:24[39m] Step: 190, Training Logs: loss_final: 1.471140, loss_mean: 1.410117, proj_loss: -0.082934, loss_mean_cls: 0.111642, deep_loss: 0.032315, grad_norm: 12.619130
Steps:   0%| | 193/1000000 [03:38<274:27:02,  1.01it/s, deep_loss=0.0319, grad_norm=8.61, loss_final=1.43, loss_mean=1.37, l[[34m2025-10-03 23:29:26[39m] Step: 192, Training Logs: loss_final: 1.444223, loss_mean: 1.381376, proj_loss: -0.081665, loss_mean_cls: 0.112851, deep_loss: 0.031661, grad_norm: 9.0360860
Steps:   0%| | 195/1000000 [03:41<301:11:39,  1.08s/it, deep_loss=0.0328, grad_norm=9.85, loss_final=1.44, loss_mean=1.37, l[[34m2025-10-03 23:29:28[39m] Step: 194, Training Logs: loss_final: 1.446906, loss_mean: 1.379024, proj_loss: -0.077870, loss_mean_cls: 0.113173, deep_loss: 0.032579, grad_norm: 8.6110910
Steps:   0%| | 196/1000000 [03:42<308:02:55,  1.11s/it, deep_loss=0.0328, grad_norm=9.85, loss_final=1.44, loss_mean=1.37, l[[34m2025-10-03 23:29:31[39m] Step: 196, Training Logs: loss_final: 1.443901, loss_mean: 1.375011, proj_loss: -0.076441, loss_mean_cls: 0.112756, deep_loss: 0.032575, grad_norm: 11.171990
Steps:   0%| | 198/1000000 [03:44<316:17:37,  1.14s/it, deep_loss=0.0339, grad_norm=9.23, loss_final=1.45, loss_mean=1.38, l[[34m2025-10-03 23:29:33[39m] Step: 198, Training Logs: loss_final: 1.466645, loss_mean: 1.393279, proj_loss: -0.073469, loss_mean_cls: 0.112603, deep_loss: 0.034233, grad_norm: 11.352879
Steps:   0%| | 200/1000000 [03:46<320:04:49,  1.15s/it, deep_loss=0.0321, grad_norm=9.89, loss_final=1.43, loss_mean=1.36, l[[34m2025-10-03 23:29:35[39m] Step: 200, Training Logs: loss_final: 1.500439, loss_mean: 1.426507, proj_loss: -0.071807, loss_mean_cls: 0.112147, deep_loss: 0.033592, grad_norm: 14.541034
Steps:   0%| | 202/1000000 [03:49<322:42:22,  1.16s/it, deep_loss=0.0337, grad_norm=9.72, loss_final=1.47, loss_mean=1.4, lo[[34m2025-10-03 23:29:38[39m] Step: 202, Training Logs: loss_final: 1.444530, loss_mean: 1.371321, proj_loss: -0.072400, loss_mean_cls: 0.113007, deep_loss: 0.032602, grad_norm: 8.1068794
Steps:   0%| | 203/1000000 [03:50<322:49:10,  1.16s/it, deep_loss=0.0336, grad_norm=11.5, loss_final=1.48, loss_mean=1.41, l[[34m2025-10-03 23:29:38[39m] Step: 202, Training Logs: loss_final: 1.444530, loss_mean: 1.371321, proj_loss: -0.072400, loss_mean_cls: 0.113007, deep_loss: 0.032602, grad_norm: 8.1068794
Steps:   0%| | 205/1000000 [03:52<323:21:54,  1.16s/it, deep_loss=0.0334, grad_norm=12.9, loss_final=1.5, loss_mean=1.42, lo[[34m2025-10-03 23:29:40[39m] Step: 204, Training Logs: loss_final: 1.488223, loss_mean: 1.414891, proj_loss: -0.072679, loss_mean_cls: 0.112777, deep_loss: 0.033235, grad_norm: 13.384549
Steps:   0%| | 207/1000000 [03:55<324:04:26,  1.17s/it, deep_loss=0.0324, grad_norm=7.74, loss_final=1.45, loss_mean=1.38, l[[34m2025-10-03 23:29:42[39m] Step: 206, Training Logs: loss_final: 1.482721, loss_mean: 1.410698, proj_loss: -0.072495, loss_mean_cls: 0.111660, deep_loss: 0.032859, grad_norm: 8.7554569
Steps:   0%| | 208/1000000 [03:56<324:38:57,  1.17s/it, deep_loss=0.0324, grad_norm=7.74, loss_final=1.45, loss_mean=1.38, l[[34m2025-10-03 23:29:45[39m] Step: 208, Training Logs: loss_final: 1.470688, loss_mean: 1.394011, proj_loss: -0.069394, loss_mean_cls: 0.112552, deep_loss: 0.033519, grad_norm: 9.4653299
Steps:   0%| | 210/1000000 [03:58<324:30:17,  1.17s/it, deep_loss=0.034, grad_norm=9.67, loss_final=1.45, loss_mean=1.38, lo[[34m2025-10-03 23:29:47[39m] Step: 210, Training Logs: loss_final: 1.459300, loss_mean: 1.383540, proj_loss: -0.069496, loss_mean_cls: 0.111930, deep_loss: 0.033327, grad_norm: 6.8746769
Steps:   0%| | 212/1000000 [04:00<324:16:51,  1.17s/it, deep_loss=0.0334, grad_norm=11.6, loss_final=1.5, loss_mean=1.42, lo[[34m2025-10-03 23:29:49[39m] Step: 212, Training Logs: loss_final: 1.476429, loss_mean: 1.402185, proj_loss: -0.070033, loss_mean_cls: 0.111576, deep_loss: 0.032701, grad_norm: 8.8011009
Steps:   0%| | 214/1000000 [04:03<324:48:14,  1.17s/it, deep_loss=0.0346, grad_norm=14.7, loss_final=1.52, loss_mean=1.44, l[[34m2025-10-03 23:29:52[39m] Step: 214, Training Logs: loss_final: 1.468176, loss_mean: 1.388440, proj_loss: -0.065164, loss_mean_cls: 0.112085, deep_loss: 0.032815, grad_norm: 10.195918
Steps:   0%| | 215/1000000 [04:04<325:02:49,  1.17s/it, deep_loss=0.0327, grad_norm=10.6, loss_final=1.46, loss_mean=1.38, l[[34m2025-10-03 23:29:52[39m] Step: 214, Training Logs: loss_final: 1.468176, loss_mean: 1.388440, proj_loss: -0.065164, loss_mean_cls: 0.112085, deep_loss: 0.032815, grad_norm: 10.195918
Steps:   0%| | 217/1000000 [04:06<325:07:52,  1.17s/it, deep_loss=0.0317, grad_norm=10.3, loss_final=1.42, loss_mean=1.33, l[[34m2025-10-03 23:29:54[39m] Step: 216, Training Logs: loss_final: 1.439855, loss_mean: 1.361138, proj_loss: -0.066223, loss_mean_cls: 0.112416, deep_loss: 0.032524, grad_norm: 9.5469908
Steps:   0%| | 219/1000000 [04:09<325:44:41,  1.17s/it, deep_loss=0.0329, grad_norm=11.3, loss_final=1.46, loss_mean=1.38, l[[34m2025-10-03 23:29:56[39m] Step: 218, Training Logs: loss_final: 1.456714, loss_mean: 1.375347, proj_loss: -0.064493, loss_mean_cls: 0.112759, deep_loss: 0.033102, grad_norm: 12.340514
Steps:   0%| | 221/1000000 [04:10<282:48:53,  1.02s/it, deep_loss=0.0335, grad_norm=18.8, loss_final=1.5, loss_mean=1.42, lo[[34m2025-10-03 23:29:59[39m] Step: 220, Training Logs: loss_final: 1.522101, loss_mean: 1.431254, proj_loss: -0.057078, loss_mean_cls: 0.113080, deep_loss: 0.034844, grad_norm: 20.129248
Steps:   0%| | 223/1000000 [04:12<250:02:57,  1.11it/s, deep_loss=0.0347, grad_norm=14.6, loss_final=1.52, loss_mean=1.44, l[[34m2025-10-03 23:30:00[39m] Step: 222, Training Logs: loss_final: 1.521256, loss_mean: 1.440631, proj_loss: -0.065822, loss_mean_cls: 0.111751, deep_loss: 0.034696, grad_norm: 16.351147
Steps:   0%| | 225/1000000 [04:14<283:35:29,  1.02s/it, deep_loss=0.0321, grad_norm=10.8, loss_final=1.47, loss_mean=1.39, l[[34m2025-10-03 23:30:02[39m] Step: 224, Training Logs: loss_final: 1.463663, loss_mean: 1.381855, proj_loss: -0.064458, loss_mean_cls: 0.113307, deep_loss: 0.032959, grad_norm: 11.955624
Steps:   0%| | 227/1000000 [04:17<304:45:42,  1.10s/it, deep_loss=0.0328, grad_norm=13.9, loss_final=1.47, loss_mean=1.38, l[[34m2025-10-03 23:30:04[39m] Step: 226, Training Logs: loss_final: 1.501134, loss_mean: 1.417265, proj_loss: -0.061095, loss_mean_cls: 0.112315, deep_loss: 0.032648, grad_norm: 12.031693
Steps:   0%| | 228/1000000 [04:18<310:41:31,  1.12s/it, deep_loss=0.0328, grad_norm=13.9, loss_final=1.47, loss_mean=1.38, l[[34m2025-10-03 23:30:07[39m] Step: 228, Training Logs: loss_final: 1.471458, loss_mean: 1.384978, proj_loss: -0.058088, loss_mean_cls: 0.112433, deep_loss: 0.032136, grad_norm: 11.937671
Steps:   0%| | 230/1000000 [04:20<318:24:33,  1.15s/it, deep_loss=0.032, grad_norm=11.3, loss_final=1.44, loss_mean=1.36, lo[[34m2025-10-03 23:30:09[39m] Step: 230, Training Logs: loss_final: 1.449107, loss_mean: 1.363540, proj_loss: -0.059158, loss_mean_cls: 0.111914, deep_loss: 0.032811, grad_norm: 9.5812011
Steps:   0%| | 232/1000000 [04:22<321:39:54,  1.16s/it, deep_loss=0.0332, grad_norm=10.6, loss_final=1.48, loss_mean=1.4, lo[[34m2025-10-03 23:30:11[39m] Step: 232, Training Logs: loss_final: 1.449200, loss_mean: 1.362059, proj_loss: -0.057046, loss_mean_cls: 0.112812, deep_loss: 0.031375, grad_norm: 5.6791701
Steps:   0%| | 234/1000000 [04:25<323:30:03,  1.16s/it, deep_loss=0.0335, grad_norm=18.6, loss_final=1.54, loss_mean=1.45, l[[34m2025-10-03 23:30:14[39m] Step: 234, Training Logs: loss_final: 1.484689, loss_mean: 1.398094, proj_loss: -0.059144, loss_mean_cls: 0.111611, deep_loss: 0.034128, grad_norm: 14.846298
Steps:   0%| | 235/1000000 [04:26<323:45:38,  1.17s/it, deep_loss=0.0322, grad_norm=10, loss_final=1.43, loss_mean=1.34, los[[34m2025-10-03 23:30:14[39m] Step: 234, Training Logs: loss_final: 1.484689, loss_mean: 1.398094, proj_loss: -0.059144, loss_mean_cls: 0.111611, deep_loss: 0.034128, grad_norm: 14.846298
Steps:   0%| | 237/1000000 [04:28<323:43:43,  1.17s/it, deep_loss=0.0314, grad_norm=13.4, loss_final=1.45, loss_mean=1.36, l[[34m2025-10-03 23:30:16[39m] Step: 236, Training Logs: loss_final: 1.459354, loss_mean: 1.372871, proj_loss: -0.058607, loss_mean_cls: 0.112673, deep_loss: 0.032416, grad_norm: 14.439604
Steps:   0%| | 239/1000000 [04:31<324:40:11,  1.17s/it, deep_loss=0.032, grad_norm=8.83, loss_final=1.47, loss_mean=1.38, lo[[34m2025-10-03 23:30:18[39m] Step: 238, Training Logs: loss_final: 1.455533, loss_mean: 1.366196, proj_loss: -0.054648, loss_mean_cls: 0.111797, deep_loss: 0.032187, grad_norm: 12.375463
Steps:   0%| | 240/1000000 [04:32<324:27:57,  1.17s/it, deep_loss=0.032, grad_norm=8.83, loss_final=1.47, loss_mean=1.38, lo[[34m2025-10-03 23:30:21[39m] Step: 240, Training Logs: loss_final: 1.415484, loss_mean: 1.328746, proj_loss: -0.056906, loss_mean_cls: 0.112814, deep_loss: 0.030830, grad_norm: 7.2671083
Steps:   0%| | 242/1000000 [04:34<325:05:35,  1.17s/it, deep_loss=0.0313, grad_norm=10.3, loss_final=1.44, loss_mean=1.35, l[[34m2025-10-03 23:30:23[39m] Step: 242, Training Logs: loss_final: 1.428613, loss_mean: 1.339693, proj_loss: -0.054656, loss_mean_cls: 0.112233, deep_loss: 0.031342, grad_norm: 9.4714353
Steps:   0%| | 244/1000000 [04:36<324:48:41,  1.17s/it, deep_loss=0.031, grad_norm=7.15, loss_final=1.41, loss_mean=1.32, lo[[34m2025-10-03 23:30:25[39m] Step: 244, Training Logs: loss_final: 1.508846, loss_mean: 1.409900, proj_loss: -0.047595, loss_mean_cls: 0.112628, deep_loss: 0.033913, grad_norm: 17.083809
Steps:   0%| | 246/1000000 [04:39<325:43:49,  1.17s/it, deep_loss=0.0324, grad_norm=14.1, loss_final=1.46, loss_mean=1.37, l[[34m2025-10-03 23:30:28[39m] Step: 246, Training Logs: loss_final: 1.467833, loss_mean: 1.375445, proj_loss: -0.052816, loss_mean_cls: 0.112579, deep_loss: 0.032626, grad_norm: 13.490535
Steps:   0%| | 247/1000000 [04:40<325:17:29,  1.17s/it, deep_loss=0.0315, grad_norm=10.4, loss_final=1.46, loss_mean=1.36, l[[34m2025-10-03 23:30:28[39m] Step: 246, Training Logs: loss_final: 1.467833, loss_mean: 1.375445, proj_loss: -0.052816, loss_mean_cls: 0.112579, deep_loss: 0.032626, grad_norm: 13.490535
Steps:   0%| | 249/1000000 [04:42<324:40:00,  1.17s/it, deep_loss=0.0318, grad_norm=13.4, loss_final=1.46, loss_mean=1.36, l[[34m2025-10-03 23:30:30[39m] Step: 248, Training Logs: loss_final: 1.480990, loss_mean: 1.380153, proj_loss: -0.044360, loss_mean_cls: 0.112961, deep_loss: 0.032236, grad_norm: 16.277384
Steps:   0%| | 251/1000000 [04:45<316:43:24,  1.14s/it, deep_loss=0.0335, grad_norm=17.7, loss_final=1.48, loss_mean=1.39, l[[34m2025-10-03 23:30:32[39m] Step: 250, Training Logs: loss_final: 1.501701, loss_mean: 1.405885, proj_loss: -0.049720, loss_mean_cls: 0.112285, deep_loss: 0.033251, grad_norm: 14.693225
Steps:   0%| | 254/1000000 [04:47<252:46:35,  1.10it/s, deep_loss=0.0325, grad_norm=13.2, loss_final=1.47, loss_mean=1.38, l[[34m2025-10-03 23:30:36[39m] Step: 254, Training Logs: loss_final: 1.499816, loss_mean: 1.402485, proj_loss: -0.046734, loss_mean_cls: 0.111808, deep_loss: 0.032257, grad_norm: 13.169455
Steps:   0%| | 255/1000000 [04:48<271:35:41,  1.02it/s, deep_loss=0.0306, grad_norm=8.47, loss_final=1.43, loss_mean=1.34, l[[34m2025-10-03 23:30:36[39m] Step: 254, Training Logs: loss_final: 1.499816, loss_mean: 1.402485, proj_loss: -0.046734, loss_mean_cls: 0.111808, deep_loss: 0.032257, grad_norm: 13.169455
Steps:   0%| | 257/1000000 [04:50<298:46:01,  1.08s/it, deep_loss=0.033, grad_norm=19.6, loss_final=1.52, loss_mean=1.43, lo[[34m2025-10-03 23:30:38[39m] Step: 256, Training Logs: loss_final: 1.472191, loss_mean: 1.383074, proj_loss: -0.054486, loss_mean_cls: 0.111876, deep_loss: 0.031727, grad_norm: 11.601804
Steps:   0%| | 259/1000000 [04:53<312:13:48,  1.12s/it, deep_loss=0.0309, grad_norm=10.3, loss_final=1.46, loss_mean=1.37, l[[34m2025-10-03 23:30:41[39m] Step: 258, Training Logs: loss_final: 1.529552, loss_mean: 1.441303, proj_loss: -0.056984, loss_mean_cls: 0.112343, deep_loss: 0.032889, grad_norm: 17.439146
Steps:   0%| | 260/1000000 [04:54<315:31:41,  1.14s/it, deep_loss=0.0309, grad_norm=10.3, loss_final=1.46, loss_mean=1.37, l[[34m2025-10-03 23:30:43[39m] Step: 260, Training Logs: loss_final: 1.431213, loss_mean: 1.337948, proj_loss: -0.051338, loss_mean_cls: 0.113163, deep_loss: 0.031439, grad_norm: 5.8197326
Steps:   0%| | 262/1000000 [04:56<319:38:00,  1.15s/it, deep_loss=0.0314, grad_norm=11.4, loss_final=1.44, loss_mean=1.35, l[[34m2025-10-03 23:30:45[39m] Step: 262, Training Logs: loss_final: 1.460011, loss_mean: 1.366927, proj_loss: -0.050172, loss_mean_cls: 0.111941, deep_loss: 0.031315, grad_norm: 11.801347
Steps:   0%| | 264/1000000 [04:58<321:44:56,  1.16s/it, deep_loss=0.032, grad_norm=7.4, loss_final=1.46, loss_mean=1.37, los[[34m2025-10-03 23:30:48[39m] Step: 264, Training Logs: loss_final: 1.416038, loss_mean: 1.322811, proj_loss: -0.050370, loss_mean_cls: 0.111936, deep_loss: 0.031662, grad_norm: 6.8356467
Steps:   0%| | 266/1000000 [05:01<323:48:28,  1.17s/it, deep_loss=0.0308, grad_norm=6.7, loss_final=1.44, loss_mean=1.34, lo[[34m2025-10-03 23:30:50[39m] Step: 266, Training Logs: loss_final: 1.408563, loss_mean: 1.313537, proj_loss: -0.047922, loss_mean_cls: 0.112879, deep_loss: 0.030068, grad_norm: 7.7428367
Steps:   0%| | 267/1000000 [05:02<323:59:20,  1.17s/it, deep_loss=0.0307, grad_norm=4.68, loss_final=1.4, loss_mean=1.31, lo[[34m2025-10-03 23:30:50[39m] Step: 266, Training Logs: loss_final: 1.408563, loss_mean: 1.313537, proj_loss: -0.047922, loss_mean_cls: 0.112879, deep_loss: 0.030068, grad_norm: 7.7428367
Steps:   0%| | 269/1000000 [05:04<324:57:31,  1.17s/it, deep_loss=0.0311, grad_norm=9.01, loss_final=1.45, loss_mean=1.36, l[[34m2025-10-03 23:30:52[39m] Step: 268, Training Logs: loss_final: 1.402230, loss_mean: 1.306075, proj_loss: -0.047206, loss_mean_cls: 0.113422, deep_loss: 0.029938, grad_norm: 8.3359847
Steps:   0%| | 271/1000000 [05:07<324:32:33,  1.17s/it, deep_loss=0.0317, grad_norm=15.1, loss_final=1.48, loss_mean=1.38, l[[34m2025-10-03 23:30:55[39m] Step: 270, Training Logs: loss_final: 1.403386, loss_mean: 1.307275, proj_loss: -0.046748, loss_mean_cls: 0.113370, deep_loss: 0.029489, grad_norm: 6.3441367
Steps:   0%| | 272/1000000 [05:08<324:02:42,  1.17s/it, deep_loss=0.0317, grad_norm=15.1, loss_final=1.48, loss_mean=1.38, l[[34m2025-10-03 23:30:57[39m] Step: 272, Training Logs: loss_final: 1.420496, loss_mean: 1.321422, proj_loss: -0.044239, loss_mean_cls: 0.112558, deep_loss: 0.030756, grad_norm: 8.7320477
Steps:   0%| | 274/1000000 [05:10<324:43:21,  1.17s/it, deep_loss=0.0311, grad_norm=13.6, loss_final=1.46, loss_mean=1.36, l[[34m2025-10-03 23:30:59[39m] Step: 274, Training Logs: loss_final: 1.461413, loss_mean: 1.359020, proj_loss: -0.041724, loss_mean_cls: 0.112253, deep_loss: 0.031865, grad_norm: 9.5966847
Steps:   0%| | 276/1000000 [05:13<325:50:10,  1.17s/it, deep_loss=0.0303, grad_norm=11.6, loss_final=1.46, loss_mean=1.36, l[[34m2025-10-03 23:31:02[39m] Step: 276, Training Logs: loss_final: 1.468273, loss_mean: 1.366156, proj_loss: -0.041798, loss_mean_cls: 0.112177, deep_loss: 0.031738, grad_norm: 10.658051
Steps:   0%| | 278/1000000 [05:15<326:39:50,  1.18s/it, deep_loss=0.0329, grad_norm=12.8, loss_final=1.5, loss_mean=1.4, los[[34m2025-10-03 23:31:04[39m] Step: 278, Training Logs: loss_final: 1.469942, loss_mean: 1.366557, proj_loss: -0.043224, loss_mean_cls: 0.113471, deep_loss: 0.033138, grad_norm: 10.245526
Steps:   0%| | 279/1000000 [05:16<325:56:42,  1.17s/it, deep_loss=0.0315, grad_norm=8.13, loss_final=1.47, loss_mean=1.38, l[[34m2025-10-03 23:31:04[39m] Step: 278, Training Logs: loss_final: 1.469942, loss_mean: 1.366557, proj_loss: -0.043224, loss_mean_cls: 0.113471, deep_loss: 0.033138, grad_norm: 10.245526
Steps:   0%| | 281/1000000 [05:18<325:45:03,  1.17s/it, deep_loss=0.0317, grad_norm=13.6, loss_final=1.51, loss_mean=1.41, l[[34m2025-10-03 23:31:06[39m] Step: 280, Training Logs: loss_final: 1.481602, loss_mean: 1.382840, proj_loss: -0.044900, loss_mean_cls: 0.112327, deep_loss: 0.031335, grad_norm: 14.048981
Steps:   0%| | 283/1000000 [05:20<285:54:24,  1.03s/it, deep_loss=0.0308, grad_norm=9.45, loss_final=1.44, loss_mean=1.34, l[[34m2025-10-03 23:31:08[39m] Step: 282, Training Logs: loss_final: 1.433485, loss_mean: 1.330360, proj_loss: -0.040615, loss_mean_cls: 0.112706, deep_loss: 0.031033, grad_norm: 7.5924091
Steps:   0%| | 286/1000000 [05:23<274:23:29,  1.01it/s, deep_loss=0.0311, grad_norm=8.42, loss_final=1.45, loss_mean=1.35, l[[34m2025-10-03 23:31:10[39m] Step: 284, Training Logs: loss_final: 1.431772, loss_mean: 1.328650, proj_loss: -0.039312, loss_mean_cls: 0.112838, deep_loss: 0.029595, grad_norm: 5.4900561
Steps:   0%| | 287/1000000 [05:24<290:36:30,  1.05s/it, deep_loss=0.0321, grad_norm=8.67, loss_final=1.45, loss_mean=1.34, l[[34m2025-10-03 23:31:12[39m] Step: 286, Training Logs: loss_final: 1.432677, loss_mean: 1.328508, proj_loss: -0.039883, loss_mean_cls: 0.112860, deep_loss: 0.031192, grad_norm: 10.001864
Steps:   0%| | 289/1000000 [05:27<308:00:41,  1.11s/it, deep_loss=0.0312, grad_norm=6.41, loss_final=1.45, loss_mean=1.35, l[[34m2025-10-03 23:31:14[39m] Step: 288, Training Logs: loss_final: 1.440772, loss_mean: 1.335393, proj_loss: -0.039440, loss_mean_cls: 0.113253, deep_loss: 0.031565, grad_norm: 6.9097414
Steps:   0%| | 291/1000000 [05:29<315:56:25,  1.14s/it, deep_loss=0.0314, grad_norm=9.96, loss_final=1.43, loss_mean=1.33, l[[34m2025-10-03 23:31:17[39m] Step: 290, Training Logs: loss_final: 1.431966, loss_mean: 1.327605, proj_loss: -0.039752, loss_mean_cls: 0.113550, deep_loss: 0.030563, grad_norm: 9.3184414
Steps:   0%| | 292/1000000 [05:30<318:24:53,  1.15s/it, deep_loss=0.0314, grad_norm=9.96, loss_final=1.43, loss_mean=1.33, l[[34m2025-10-03 23:31:19[39m] Step: 292, Training Logs: loss_final: 1.429529, loss_mean: 1.322695, proj_loss: -0.037614, loss_mean_cls: 0.113249, deep_loss: 0.031199, grad_norm: 10.065664
Steps:   0%| | 294/1000000 [05:32<321:02:28,  1.16s/it, deep_loss=0.0312, grad_norm=6.53, loss_final=1.42, loss_mean=1.32, l[[34m2025-10-03 23:31:21[39m] Step: 294, Training Logs: loss_final: 1.437780, loss_mean: 1.330335, proj_loss: -0.037856, loss_mean_cls: 0.113719, deep_loss: 0.031583, grad_norm: 7.5360914
Steps:   0%| | 296/1000000 [05:35<322:55:41,  1.16s/it, deep_loss=0.0308, grad_norm=9.08, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:31:24[39m] Step: 296, Training Logs: loss_final: 1.430983, loss_mean: 1.322862, proj_loss: -0.036624, loss_mean_cls: 0.113683, deep_loss: 0.031061, grad_norm: 10.290722
Steps:   0%| | 298/1000000 [05:37<324:25:26,  1.17s/it, deep_loss=0.0308, grad_norm=8.83, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:31:24[39m] Step: 296, Training Logs: loss_final: 1.430983, loss_mean: 1.322862, proj_loss: -0.036624, loss_mean_cls: 0.113683, deep_loss: 0.031061, grad_norm: 10.290722
Steps:   0%| | 299/1000000 [05:38<323:52:57,  1.17s/it, deep_loss=0.0316, grad_norm=9.84, loss_final=1.45, loss_mean=1.35, l[[34m2025-10-03 23:31:26[39m] Step: 298, Training Logs: loss_final: 1.421591, loss_mean: 1.313662, proj_loss: -0.036564, loss_mean_cls: 0.112746, deep_loss: 0.031747, grad_norm: 4.5569362
Steps:   0%| | 301/1000000 [05:41<325:01:54,  1.17s/it, deep_loss=0.0316, grad_norm=7.37, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:31:28[39m] Step: 300, Training Logs: loss_final: 1.458294, loss_mean: 1.349782, proj_loss: -0.036294, loss_mean_cls: 0.112821, deep_loss: 0.031985, grad_norm: 8.8598852
Steps:   0%| | 303/1000000 [05:43<324:23:55,  1.17s/it, deep_loss=0.0305, grad_norm=13.7, loss_final=1.43, loss_mean=1.33, l[[34m2025-10-03 23:31:31[39m] Step: 302, Training Logs: loss_final: 1.423450, loss_mean: 1.318205, proj_loss: -0.037688, loss_mean_cls: 0.112552, deep_loss: 0.030380, grad_norm: 6.3898202
Steps:   0%| | 304/1000000 [05:44<324:20:04,  1.17s/it, deep_loss=0.0305, grad_norm=13.7, loss_final=1.43, loss_mean=1.33, l[[34m2025-10-03 23:31:33[39m] Step: 304, Training Logs: loss_final: 1.398741, loss_mean: 1.290680, proj_loss: -0.035399, loss_mean_cls: 0.113282, deep_loss: 0.030178, grad_norm: 10.729561
Steps:   0%| | 306/1000000 [05:46<324:14:19,  1.17s/it, deep_loss=0.0299, grad_norm=13.4, loss_final=1.38, loss_mean=1.27, l[[34m2025-10-03 23:31:35[39m] Step: 306, Training Logs: loss_final: 1.381565, loss_mean: 1.271841, proj_loss: -0.033379, loss_mean_cls: 0.113663, deep_loss: 0.029439, grad_norm: 10.486160
Steps:   0%| | 308/1000000 [05:49<326:21:28,  1.18s/it, deep_loss=0.0302, grad_norm=4.83, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:31:38[39m] Step: 308, Training Logs: loss_final: 1.422660, loss_mean: 1.314152, proj_loss: -0.035099, loss_mean_cls: 0.113104, deep_loss: 0.030503, grad_norm: 7.4061550
Steps:   0%| | 309/1000000 [05:50<326:25:42,  1.18s/it, deep_loss=0.0306, grad_norm=8.8, loss_final=1.43, loss_mean=1.33, lo[[34m2025-10-03 23:31:38[39m] Step: 308, Training Logs: loss_final: 1.422660, loss_mean: 1.314152, proj_loss: -0.035099, loss_mean_cls: 0.113104, deep_loss: 0.030503, grad_norm: 7.4061550
Steps:   0%| | 311/1000000 [05:52<326:15:38,  1.17s/it, deep_loss=0.0311, grad_norm=8.54, loss_final=1.42, loss_mean=1.32, l[[34m2025-10-03 23:31:40[39m] Step: 310, Training Logs: loss_final: 1.413424, loss_mean: 1.305936, proj_loss: -0.035748, loss_mean_cls: 0.112353, deep_loss: 0.030883, grad_norm: 6.5913950
Steps:   0%| | 313/1000000 [05:54<309:39:43,  1.12s/it, deep_loss=0.0322, grad_norm=21.4, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:31:43[39m] Step: 312, Training Logs: loss_final: 1.422435, loss_mean: 1.314697, proj_loss: -0.036587, loss_mean_cls: 0.113008, deep_loss: 0.031318, grad_norm: 9.5716460
Steps:   0%| | 316/1000000 [05:57<261:37:02,  1.06it/s, deep_loss=0.0313, grad_norm=13.9, loss_final=1.44, loss_mean=1.33, l[[34m2025-10-03 23:31:46[39m] Step: 316, Training Logs: loss_final: 1.417562, loss_mean: 1.309291, proj_loss: -0.036475, loss_mean_cls: 0.113035, deep_loss: 0.031712, grad_norm: 13.936067
Steps:   0%| | 317/1000000 [05:58<281:28:17,  1.01s/it, deep_loss=0.032, grad_norm=16.3, loss_final=1.43, loss_mean=1.32, lo[[34m2025-10-03 23:31:46[39m] Step: 316, Training Logs: loss_final: 1.417562, loss_mean: 1.309291, proj_loss: -0.036475, loss_mean_cls: 0.113035, deep_loss: 0.031712, grad_norm: 13.936067
Steps:   0%| | 319/1000000 [06:01<304:53:39,  1.10s/it, deep_loss=0.0307, grad_norm=17.5, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:31:48[39m] Step: 318, Training Logs: loss_final: 1.429355, loss_mean: 1.321484, proj_loss: -0.035479, loss_mean_cls: 0.112846, deep_loss: 0.030504, grad_norm: 15.704567
Steps:   0%| | 321/1000000 [06:03<314:57:56,  1.13s/it, deep_loss=0.0305, grad_norm=12.1, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:31:51[39m] Step: 320, Training Logs: loss_final: 1.422285, loss_mean: 1.312272, proj_loss: -0.032450, loss_mean_cls: 0.112392, deep_loss: 0.030071, grad_norm: 10.794660
Steps:   0%| | 322/1000000 [06:04<317:45:50,  1.14s/it, deep_loss=0.0305, grad_norm=12.1, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:31:53[39m] Step: 322, Training Logs: loss_final: 1.417516, loss_mean: 1.311085, proj_loss: -0.035903, loss_mean_cls: 0.111984, deep_loss: 0.030350, grad_norm: 14.373538
Steps:   0%| | 324/1000000 [06:06<321:21:17,  1.16s/it, deep_loss=0.0307, grad_norm=8.18, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:31:55[39m] Step: 324, Training Logs: loss_final: 1.422817, loss_mean: 1.314768, proj_loss: -0.034105, loss_mean_cls: 0.112141, deep_loss: 0.030012, grad_norm: 10.763929
Steps:   0%| | 326/1000000 [06:09<322:56:44,  1.16s/it, deep_loss=0.0296, grad_norm=13.6, loss_final=1.41, loss_mean=1.31, l[[34m2025-10-03 23:31:58[39m] Step: 326, Training Logs: loss_final: 1.425327, loss_mean: 1.320510, proj_loss: -0.036817, loss_mean_cls: 0.111663, deep_loss: 0.029972, grad_norm: 11.126214
Steps:   0%| | 328/1000000 [06:11<324:18:48,  1.17s/it, deep_loss=0.0305, grad_norm=13.3, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:32:00[39m] Step: 328, Training Logs: loss_final: 1.385096, loss_mean: 1.278063, proj_loss: -0.035835, loss_mean_cls: 0.112826, deep_loss: 0.030041, grad_norm: 12.879433
Steps:   0%| | 329/1000000 [06:12<324:26:18,  1.17s/it, deep_loss=0.0298, grad_norm=14.4, loss_final=1.42, loss_mean=1.32, l[[34m2025-10-03 23:32:00[39m] Step: 328, Training Logs: loss_final: 1.385096, loss_mean: 1.278063, proj_loss: -0.035835, loss_mean_cls: 0.112826, deep_loss: 0.030041, grad_norm: 12.879433
Steps:   0%| | 331/1000000 [06:15<324:50:23,  1.17s/it, deep_loss=0.0309, grad_norm=9.36, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:32:02[39m] Step: 330, Training Logs: loss_final: 1.436307, loss_mean: 1.328489, proj_loss: -0.034564, loss_mean_cls: 0.112398, deep_loss: 0.029984, grad_norm: 19.867439
Steps:   0%| | 333/1000000 [06:17<325:05:52,  1.17s/it, deep_loss=0.031, grad_norm=20.1, loss_final=1.46, loss_mean=1.35, lo[[34m2025-10-03 23:32:05[39m] Step: 332, Training Logs: loss_final: 1.419464, loss_mean: 1.313388, proj_loss: -0.036622, loss_mean_cls: 0.112315, deep_loss: 0.030384, grad_norm: 12.023056
Steps:   0%| | 334/1000000 [06:18<324:51:52,  1.17s/it, deep_loss=0.031, grad_norm=20.1, loss_final=1.46, loss_mean=1.35, lo[[34m2025-10-03 23:32:07[39m] Step: 334, Training Logs: loss_final: 1.433707, loss_mean: 1.324463, proj_loss: -0.033552, loss_mean_cls: 0.112254, deep_loss: 0.030542, grad_norm: 14.866748
Steps:   0%| | 336/1000000 [06:20<326:04:55,  1.17s/it, deep_loss=0.0295, grad_norm=9.29, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:09[39m] Step: 336, Training Logs: loss_final: 1.431127, loss_mean: 1.324771, proj_loss: -0.036311, loss_mean_cls: 0.112296, deep_loss: 0.030371, grad_norm: 11.157574
Steps:   0%| | 338/1000000 [06:23<324:46:03,  1.17s/it, deep_loss=0.0291, grad_norm=10.7, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:32:12[39m] Step: 338, Training Logs: loss_final: 1.390473, loss_mean: 1.283811, proj_loss: -0.034329, loss_mean_cls: 0.111840, deep_loss: 0.029152, grad_norm: 11.058802
Steps:   0%| | 340/1000000 [06:25<324:14:24,  1.17s/it, deep_loss=0.0305, grad_norm=10.1, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:32:14[39m] Step: 340, Training Logs: loss_final: 1.411872, loss_mean: 1.303631, proj_loss: -0.033619, loss_mean_cls: 0.112113, deep_loss: 0.029748, grad_norm: 5.0428182
Steps:   0%| | 341/1000000 [06:26<325:05:48,  1.17s/it, deep_loss=0.0298, grad_norm=10.1, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:32:14[39m] Step: 340, Training Logs: loss_final: 1.411872, loss_mean: 1.303631, proj_loss: -0.033619, loss_mean_cls: 0.112113, deep_loss: 0.029748, grad_norm: 5.0428182
Steps:   0%| | 343/1000000 [06:29<325:12:21,  1.17s/it, deep_loss=0.0303, grad_norm=8.16, loss_final=1.39, loss_mean=1.28, l[[34m2025-10-03 23:32:16[39m] Step: 342, Training Logs: loss_final: 1.426876, loss_mean: 1.321966, proj_loss: -0.037173, loss_mean_cls: 0.111423, deep_loss: 0.030659, grad_norm: 11.268364
Steps:   0%| | 346/1000000 [06:31<258:34:15,  1.07it/s, deep_loss=0.0307, grad_norm=10.7, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:20[39m] Step: 346, Training Logs: loss_final: 1.398727, loss_mean: 1.288569, proj_loss: -0.033111, loss_mean_cls: 0.112975, deep_loss: 0.030293, grad_norm: 11.742113
Steps:   0%| | 348/1000000 [06:33<283:50:47,  1.02s/it, deep_loss=0.0309, grad_norm=10.5, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:20[39m] Step: 346, Training Logs: loss_final: 1.398727, loss_mean: 1.288569, proj_loss: -0.033111, loss_mean_cls: 0.112975, deep_loss: 0.030293, grad_norm: 11.742113
Steps:   0%| | 349/1000000 [06:34<296:31:12,  1.07s/it, deep_loss=0.0305, grad_norm=9.06, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:32:22[39m] Step: 348, Training Logs: loss_final: 1.380955, loss_mean: 1.270142, proj_loss: -0.032217, loss_mean_cls: 0.112943, deep_loss: 0.030088, grad_norm: 11.580276
Steps:   0%| | 351/1000000 [06:37<310:40:15,  1.12s/it, deep_loss=0.0307, grad_norm=16.1, loss_final=1.42, loss_mean=1.3, lo[[34m2025-10-03 23:32:25[39m] Step: 350, Training Logs: loss_final: 1.439336, loss_mean: 1.328685, proj_loss: -0.033170, loss_mean_cls: 0.112625, deep_loss: 0.031196, grad_norm: 17.011898
Steps:   0%| | 353/1000000 [06:39<317:51:40,  1.14s/it, deep_loss=0.0308, grad_norm=13.6, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:32:27[39m] Step: 352, Training Logs: loss_final: 1.429782, loss_mean: 1.317793, proj_loss: -0.031971, loss_mean_cls: 0.112798, deep_loss: 0.031162, grad_norm: 14.828243
Steps:   0%| | 354/1000000 [06:40<319:35:40,  1.15s/it, deep_loss=0.0308, grad_norm=13.6, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:32:29[39m] Step: 354, Training Logs: loss_final: 1.419137, loss_mean: 1.308436, proj_loss: -0.031984, loss_mean_cls: 0.112146, deep_loss: 0.030539, grad_norm: 11.564560
Steps:   0%| | 356/1000000 [06:43<321:47:54,  1.16s/it, deep_loss=0.0307, grad_norm=11.8, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:32:32[39m] Step: 356, Training Logs: loss_final: 1.387069, loss_mean: 1.276989, proj_loss: -0.032883, loss_mean_cls: 0.112602, deep_loss: 0.030362, grad_norm: 11.994526
Steps:   0%| | 358/1000000 [06:45<323:33:13,  1.17s/it, deep_loss=0.0312, grad_norm=12.1, loss_final=1.42, loss_mean=1.32, l[[34m2025-10-03 23:32:34[39m] Step: 358, Training Logs: loss_final: 1.397452, loss_mean: 1.288786, proj_loss: -0.033199, loss_mean_cls: 0.111956, deep_loss: 0.029909, grad_norm: 11.757353
Steps:   0%| | 360/1000000 [06:47<324:30:15,  1.17s/it, deep_loss=0.0312, grad_norm=12.9, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:32:34[39m] Step: 358, Training Logs: loss_final: 1.397452, loss_mean: 1.288786, proj_loss: -0.033199, loss_mean_cls: 0.111956, deep_loss: 0.029909, grad_norm: 11.757353
Steps:   0%| | 361/1000000 [06:48<324:50:04,  1.17s/it, deep_loss=0.0308, grad_norm=10.7, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:36[39m] Step: 360, Training Logs: loss_final: 1.361540, loss_mean: 1.248919, proj_loss: -0.030864, loss_mean_cls: 0.112975, deep_loss: 0.030510, grad_norm: 15.451303
Steps:   0%| | 363/1000000 [06:51<325:09:25,  1.17s/it, deep_loss=0.0301, grad_norm=13.3, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:39[39m] Step: 362, Training Logs: loss_final: 1.386198, loss_mean: 1.276388, proj_loss: -0.032118, loss_mean_cls: 0.112683, deep_loss: 0.029245, grad_norm: 12.262922
Steps:   0%| | 365/1000000 [06:53<325:19:40,  1.17s/it, deep_loss=0.0294, grad_norm=10.7, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:41[39m] Step: 364, Training Logs: loss_final: 1.403567, loss_mean: 1.294234, proj_loss: -0.032827, loss_mean_cls: 0.111913, deep_loss: 0.030247, grad_norm: 11.402728
Steps:   0%| | 366/1000000 [06:54<324:59:12,  1.17s/it, deep_loss=0.0294, grad_norm=10.7, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:43[39m] Step: 366, Training Logs: loss_final: 1.390866, loss_mean: 1.281952, proj_loss: -0.032365, loss_mean_cls: 0.111345, deep_loss: 0.029934, grad_norm: 12.573063
Steps:   0%| | 368/1000000 [06:57<324:23:00,  1.17s/it, deep_loss=0.0303, grad_norm=12.1, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:32:46[39m] Step: 368, Training Logs: loss_final: 1.410411, loss_mean: 1.297876, proj_loss: -0.030039, loss_mean_cls: 0.112347, deep_loss: 0.030228, grad_norm: 8.5413453
Steps:   0%| | 370/1000000 [06:59<324:53:19,  1.17s/it, deep_loss=0.0302, grad_norm=8.43, loss_final=1.42, loss_mean=1.32, l[[34m2025-10-03 23:32:48[39m] Step: 370, Training Logs: loss_final: 1.390057, loss_mean: 1.278399, proj_loss: -0.029900, loss_mean_cls: 0.112024, deep_loss: 0.029534, grad_norm: 9.1066723
Steps:   0%| | 372/1000000 [07:01<324:21:51,  1.17s/it, deep_loss=0.0298, grad_norm=11.9, loss_final=1.39, loss_mean=1.28, l[[34m2025-10-03 23:32:48[39m] Step: 370, Training Logs: loss_final: 1.390057, loss_mean: 1.278399, proj_loss: -0.029900, loss_mean_cls: 0.112024, deep_loss: 0.029534, grad_norm: 9.1066723
Steps:   0%| | 373/1000000 [07:02<324:14:07,  1.17s/it, deep_loss=0.0298, grad_norm=14.1, loss_final=1.38, loss_mean=1.27, l[[34m2025-10-03 23:32:50[39m] Step: 372, Training Logs: loss_final: 1.411539, loss_mean: 1.301102, proj_loss: -0.031568, loss_mean_cls: 0.111981, deep_loss: 0.030023, grad_norm: 17.948277
Steps:   0%| | 376/1000000 [07:05<270:43:37,  1.03it/s, deep_loss=0.0305, grad_norm=11.4, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:32:54[39m] Step: 376, Training Logs: loss_final: 1.436217, loss_mean: 1.326130, proj_loss: -0.031467, loss_mean_cls: 0.110865, deep_loss: 0.030689, grad_norm: 12.444155
Steps:   0%| | 378/1000000 [07:07<244:35:49,  1.14it/s, deep_loss=0.03, grad_norm=11.2, loss_final=1.39, loss_mean=1.28, los[[34m2025-10-03 23:32:56[39m] Step: 378, Training Logs: loss_final: 1.393926, loss_mean: 1.283283, proj_loss: -0.031374, loss_mean_cls: 0.112381, deep_loss: 0.029636, grad_norm: 8.2146065
Steps:   0%| | 380/1000000 [07:08<242:42:17,  1.14it/s, deep_loss=0.0299, grad_norm=8.86, loss_final=1.39, loss_mean=1.28, l[[34m2025-10-03 23:32:58[39m] Step: 380, Training Logs: loss_final: 1.412358, loss_mean: 1.302312, proj_loss: -0.030641, loss_mean_cls: 0.110331, deep_loss: 0.030356, grad_norm: 10.440287
Steps:   0%| | 382/1000000 [07:11<285:27:21,  1.03s/it, deep_loss=0.0294, grad_norm=10.2, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:33:00[39m] Step: 382, Training Logs: loss_final: 1.404730, loss_mean: 1.293817, proj_loss: -0.031240, loss_mean_cls: 0.111726, deep_loss: 0.030427, grad_norm: 9.9743257
Steps:   0%| | 384/1000000 [07:13<305:31:07,  1.10s/it, deep_loss=0.0308, grad_norm=10.4, loss_final=1.43, loss_mean=1.33, l[[34m2025-10-03 23:33:02[39m] Step: 384, Training Logs: loss_final: 1.397866, loss_mean: 1.286127, proj_loss: -0.030473, loss_mean_cls: 0.112277, deep_loss: 0.029935, grad_norm: 12.826870
Steps:   0%| | 385/1000000 [07:14<311:09:09,  1.12s/it, deep_loss=0.0306, grad_norm=10.4, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:33:02[39m] Step: 384, Training Logs: loss_final: 1.397866, loss_mean: 1.286127, proj_loss: -0.030473, loss_mean_cls: 0.112277, deep_loss: 0.029935, grad_norm: 12.826870
Steps:   0%| | 387/1000000 [07:17<318:27:13,  1.15s/it, deep_loss=0.0315, grad_norm=16.5, loss_final=1.42, loss_mean=1.3, lo[[34m2025-10-03 23:33:05[39m] Step: 386, Training Logs: loss_final: 1.403738, loss_mean: 1.290143, proj_loss: -0.028820, loss_mean_cls: 0.112448, deep_loss: 0.029967, grad_norm: 16.156729
Steps:   0%| | 389/1000000 [07:19<320:40:32,  1.15s/it, deep_loss=0.0295, grad_norm=11.2, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:33:07[39m] Step: 388, Training Logs: loss_final: 1.433093, loss_mean: 1.319243, proj_loss: -0.028970, loss_mean_cls: 0.111509, deep_loss: 0.031310, grad_norm: 15.667892
Steps:   0%| | 390/1000000 [07:20<322:29:19,  1.16s/it, deep_loss=0.0295, grad_norm=11.2, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:33:09[39m] Step: 390, Training Logs: loss_final: 1.404526, loss_mean: 1.294945, proj_loss: -0.031382, loss_mean_cls: 0.110719, deep_loss: 0.030243, grad_norm: 11.990581
Steps:   0%| | 392/1000000 [07:23<323:35:58,  1.17s/it, deep_loss=0.0315, grad_norm=14.6, loss_final=1.45, loss_mean=1.33, l[[34m2025-10-03 23:33:12[39m] Step: 392, Training Logs: loss_final: 1.395856, loss_mean: 1.283473, proj_loss: -0.030425, loss_mean_cls: 0.112315, deep_loss: 0.030492, grad_norm: 18.071701
Steps:   0%| | 394/1000000 [07:25<324:25:19,  1.17s/it, deep_loss=0.0303, grad_norm=17.2, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:33:14[39m] Step: 394, Training Logs: loss_final: 1.400084, loss_mean: 1.285355, proj_loss: -0.027354, loss_mean_cls: 0.111368, deep_loss: 0.030716, grad_norm: 11.824428
Steps:   0%| | 396/1000000 [07:27<324:38:12,  1.17s/it, deep_loss=0.0299, grad_norm=14.1, loss_final=1.4, loss_mean=1.28, lo[[34m2025-10-03 23:33:16[39m] Step: 396, Training Logs: loss_final: 1.410688, loss_mean: 1.299877, proj_loss: -0.030490, loss_mean_cls: 0.111246, deep_loss: 0.030056, grad_norm: 16.918434
Steps:   0%| | 397/1000000 [07:28<324:28:46,  1.17s/it, deep_loss=0.0302, grad_norm=15.9, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:33:16[39m] Step: 396, Training Logs: loss_final: 1.410688, loss_mean: 1.299877, proj_loss: -0.030490, loss_mean_cls: 0.111246, deep_loss: 0.030056, grad_norm: 16.918434
Steps:   0%| | 399/1000000 [07:31<323:37:02,  1.17s/it, deep_loss=0.0304, grad_norm=17.1, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:33:19[39m] Step: 398, Training Logs: loss_final: 1.394040, loss_mean: 1.282642, proj_loss: -0.029743, loss_mean_cls: 0.111230, deep_loss: 0.029911, grad_norm: 11.316050
Steps:   0%| | 401/1000000 [07:33<323:43:24,  1.17s/it, deep_loss=0.0295, grad_norm=19.3, loss_final=1.4, loss_mean=1.28, lo[[34m2025-10-03 23:33:21[39m] Step: 400, Training Logs: loss_final: 1.369401, loss_mean: 1.257933, proj_loss: -0.029760, loss_mean_cls: 0.112141, deep_loss: 0.029088, grad_norm: 18.118586
Steps:   0%| | 402/1000000 [07:34<324:15:40,  1.17s/it, deep_loss=0.0295, grad_norm=19.3, loss_final=1.4, loss_mean=1.28, lo[[34m2025-10-03 23:33:23[39m] Step: 402, Training Logs: loss_final: 1.394385, loss_mean: 1.283472, proj_loss: -0.031551, loss_mean_cls: 0.111914, deep_loss: 0.030550, grad_norm: 14.142442
Steps:   0%| | 404/1000000 [07:37<324:36:21,  1.17s/it, deep_loss=0.0296, grad_norm=11.8, loss_final=1.38, loss_mean=1.27, l[[34m2025-10-03 23:33:26[39m] Step: 404, Training Logs: loss_final: 1.409387, loss_mean: 1.297977, proj_loss: -0.029557, loss_mean_cls: 0.110842, deep_loss: 0.030125, grad_norm: 19.572960
Steps:   0%| | 406/1000000 [07:39<324:54:10,  1.17s/it, deep_loss=0.0317, grad_norm=17.6, loss_final=1.44, loss_mean=1.33, l[[34m2025-10-03 23:33:28[39m] Step: 406, Training Logs: loss_final: 1.444489, loss_mean: 1.332275, proj_loss: -0.030763, loss_mean_cls: 0.110711, deep_loss: 0.032266, grad_norm: 18.285152
Steps:   0%| | 408/1000000 [07:41<300:43:02,  1.08s/it, deep_loss=0.0307, grad_norm=13.2, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:33:30[39m] Step: 408, Training Logs: loss_final: 1.423359, loss_mean: 1.311648, proj_loss: -0.029971, loss_mean_cls: 0.110587, deep_loss: 0.031095, grad_norm: 12.095799
Steps:   0%| | 411/1000000 [07:43<246:43:46,  1.13it/s, deep_loss=0.0314, grad_norm=12.3, loss_final=1.45, loss_mean=1.33, l[[34m2025-10-03 23:33:32[39m] Step: 410, Training Logs: loss_final: 1.449722, loss_mean: 1.336829, proj_loss: -0.031086, loss_mean_cls: 0.111818, deep_loss: 0.032160, grad_norm: 18.902094
Steps:   0%| | 412/1000000 [07:44<253:10:50,  1.10it/s, deep_loss=0.0314, grad_norm=12.3, loss_final=1.45, loss_mean=1.33, l[[34m2025-10-03 23:33:33[39m] Step: 412, Training Logs: loss_final: 1.421134, loss_mean: 1.309894, proj_loss: -0.030779, loss_mean_cls: 0.111076, deep_loss: 0.030943, grad_norm: 10.226928
Steps:   0%| | 414/1000000 [07:47<289:47:05,  1.04s/it, deep_loss=0.0312, grad_norm=10.3, loss_final=1.45, loss_mean=1.33, l[[34m2025-10-03 23:33:36[39m] Step: 414, Training Logs: loss_final: 1.423391, loss_mean: 1.312610, proj_loss: -0.030324, loss_mean_cls: 0.110636, deep_loss: 0.030469, grad_norm: 13.261240
Steps:   0%| | 416/1000000 [07:49<307:19:59,  1.11s/it, deep_loss=0.0316, grad_norm=15.4, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:33:38[39m] Step: 416, Training Logs: loss_final: 1.424672, loss_mean: 1.311665, proj_loss: -0.029234, loss_mean_cls: 0.111898, deep_loss: 0.030342, grad_norm: 12.780993
Steps:   0%| | 418/1000000 [07:51<315:50:23,  1.14s/it, deep_loss=0.0311, grad_norm=12.8, loss_final=1.44, loss_mean=1.33, l[[34m2025-10-03 23:33:40[39m] Step: 418, Training Logs: loss_final: 1.417948, loss_mean: 1.304353, proj_loss: -0.029343, loss_mean_cls: 0.112003, deep_loss: 0.030935, grad_norm: 12.467518
Steps:   0%| | 419/1000000 [07:52<318:20:49,  1.15s/it, deep_loss=0.032, grad_norm=26.9, loss_final=1.45, loss_mean=1.33, lo[[34m2025-10-03 23:33:40[39m] Step: 418, Training Logs: loss_final: 1.417948, loss_mean: 1.304353, proj_loss: -0.029343, loss_mean_cls: 0.112003, deep_loss: 0.030935, grad_norm: 12.467518
Steps:   0%| | 421/1000000 [07:55<321:11:17,  1.16s/it, deep_loss=0.0324, grad_norm=21.9, loss_final=1.45, loss_mean=1.34, l[[34m2025-10-03 23:33:43[39m] Step: 420, Training Logs: loss_final: 1.436502, loss_mean: 1.323054, proj_loss: -0.029874, loss_mean_cls: 0.111699, deep_loss: 0.031623, grad_norm: 25.043060
Steps:   0%| | 423/1000000 [07:57<322:43:44,  1.16s/it, deep_loss=0.0307, grad_norm=20.3, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:33:45[39m] Step: 422, Training Logs: loss_final: 1.399598, loss_mean: 1.288906, proj_loss: -0.031355, loss_mean_cls: 0.111061, deep_loss: 0.030986, grad_norm: 14.176481
Steps:   0%| | 424/1000000 [07:58<323:09:39,  1.16s/it, deep_loss=0.0307, grad_norm=20.3, loss_final=1.43, loss_mean=1.32, l[[34m2025-10-03 23:33:47[39m] Step: 424, Training Logs: loss_final: 1.438071, loss_mean: 1.325759, proj_loss: -0.030363, loss_mean_cls: 0.111038, deep_loss: 0.031638, grad_norm: 20.998993
Steps:   0%| | 426/1000000 [08:01<323:56:42,  1.17s/it, deep_loss=0.0319, grad_norm=20.5, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:33:50[39m] Step: 426, Training Logs: loss_final: 1.414903, loss_mean: 1.302230, proj_loss: -0.029449, loss_mean_cls: 0.110982, deep_loss: 0.031140, grad_norm: 16.652018
Steps:   0%| | 428/1000000 [08:03<323:36:14,  1.17s/it, deep_loss=0.0303, grad_norm=15.4, loss_final=1.41, loss_mean=1.29, l[[34m2025-10-03 23:33:52[39m] Step: 428, Training Logs: loss_final: 1.449010, loss_mean: 1.338036, proj_loss: -0.030256, loss_mean_cls: 0.109165, deep_loss: 0.032066, grad_norm: 19.146862
Steps:   0%| | 430/1000000 [08:05<323:32:41,  1.17s/it, deep_loss=0.0328, grad_norm=18.7, loss_final=1.45, loss_mean=1.34, l[[34m2025-10-03 23:33:54[39m] Step: 430, Training Logs: loss_final: 1.435187, loss_mean: 1.324919, proj_loss: -0.032161, loss_mean_cls: 0.110240, deep_loss: 0.032189, grad_norm: 16.990019
Steps:   0%| | 431/1000000 [08:07<323:38:48,  1.17s/it, deep_loss=0.0304, grad_norm=11.9, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:33:54[39m] Step: 430, Training Logs: loss_final: 1.435187, loss_mean: 1.324919, proj_loss: -0.032161, loss_mean_cls: 0.110240, deep_loss: 0.032189, grad_norm: 16.990019
Steps:   0%| | 433/1000000 [08:09<324:14:16,  1.17s/it, deep_loss=0.0329, grad_norm=15.3, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:33:57[39m] Step: 432, Training Logs: loss_final: 1.430509, loss_mean: 1.320052, proj_loss: -0.030756, loss_mean_cls: 0.109787, deep_loss: 0.031427, grad_norm: 18.749956
Steps:   0%| | 435/1000000 [08:11<324:04:18,  1.17s/it, deep_loss=0.0297, grad_norm=13.6, loss_final=1.39, loss_mean=1.28, l[[34m2025-10-03 23:33:59[39m] Step: 434, Training Logs: loss_final: 1.400197, loss_mean: 1.289752, proj_loss: -0.030879, loss_mean_cls: 0.109874, deep_loss: 0.031450, grad_norm: 16.854042
Steps:   0%| | 437/1000000 [08:14<323:37:43,  1.17s/it, deep_loss=0.0326, grad_norm=17.3, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:34:01[39m] Step: 436, Training Logs: loss_final: 1.432090, loss_mean: 1.320641, proj_loss: -0.029835, loss_mean_cls: 0.110583, deep_loss: 0.030700, grad_norm: 18.352812
Steps:   0%| | 438/1000000 [08:15<322:59:17,  1.16s/it, deep_loss=0.0326, grad_norm=17.3, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:34:04[39m] Step: 438, Training Logs: loss_final: 1.410468, loss_mean: 1.299792, proj_loss: -0.031601, loss_mean_cls: 0.110687, deep_loss: 0.031590, grad_norm: 17.220505
Steps:   0%| | 441/1000000 [08:17<275:13:11,  1.01it/s, deep_loss=0.0308, grad_norm=20, loss_final=1.41, loss_mean=1.3, loss[[34m2025-10-03 23:34:06[39m] Step: 440, Training Logs: loss_final: 1.411222, loss_mean: 1.299311, proj_loss: -0.029333, loss_mean_cls: 0.110618, deep_loss: 0.030625, grad_norm: 17.050112
Steps:   0%| | 443/1000000 [08:19<273:37:23,  1.01it/s, deep_loss=0.0307, grad_norm=11.7, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:34:07[39m] Step: 442, Training Logs: loss_final: 1.430589, loss_mean: 1.317151, proj_loss: -0.028053, loss_mean_cls: 0.109963, deep_loss: 0.031529, grad_norm: 16.972754
Steps:   0%| | 444/1000000 [08:21<289:09:36,  1.04s/it, deep_loss=0.0307, grad_norm=11.7, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:34:10[39m] Step: 444, Training Logs: loss_final: 1.443809, loss_mean: 1.334971, proj_loss: -0.032396, loss_mean_cls: 0.109518, deep_loss: 0.031716, grad_norm: 16.497980
Steps:   0%| | 446/1000000 [08:23<307:14:32,  1.11s/it, deep_loss=0.0322, grad_norm=20, loss_final=1.43, loss_mean=1.32, los[[34m2025-10-03 23:34:12[39m] Step: 446, Training Logs: loss_final: 1.423952, loss_mean: 1.311984, proj_loss: -0.030160, loss_mean_cls: 0.110123, deep_loss: 0.032005, grad_norm: 14.445829
Steps:   0%| | 448/1000000 [08:25<316:35:56,  1.14s/it, deep_loss=0.0316, grad_norm=14.2, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:34:14[39m] Step: 448, Training Logs: loss_final: 1.454649, loss_mean: 1.343485, proj_loss: -0.030597, loss_mean_cls: 0.110146, deep_loss: 0.031616, grad_norm: 30.717869
Steps:   0%| | 450/1000000 [08:28<320:22:28,  1.15s/it, deep_loss=0.0311, grad_norm=33.9, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:34:14[39m] Step: 448, Training Logs: loss_final: 1.454649, loss_mean: 1.343485, proj_loss: -0.030597, loss_mean_cls: 0.110146, deep_loss: 0.031616, grad_norm: 30.717869
Steps:   0%| | 451/1000000 [08:29<321:11:48,  1.16s/it, deep_loss=0.0307, grad_norm=16.6, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:34:17[39m] Step: 450, Training Logs: loss_final: 1.434554, loss_mean: 1.323906, proj_loss: -0.031832, loss_mean_cls: 0.110921, deep_loss: 0.031559, grad_norm: 23.698519
Steps:   0%| | 453/1000000 [08:31<322:33:36,  1.16s/it, deep_loss=0.0314, grad_norm=22.1, loss_final=1.45, loss_mean=1.34, l[[34m2025-10-03 23:34:19[39m] Step: 452, Training Logs: loss_final: 1.405319, loss_mean: 1.295191, proj_loss: -0.030288, loss_mean_cls: 0.110490, deep_loss: 0.029926, grad_norm: 21.559870
Steps:   0%| | 455/1000000 [08:33<322:36:06,  1.16s/it, deep_loss=0.0304, grad_norm=21.1, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:34:21[39m] Step: 454, Training Logs: loss_final: 1.431282, loss_mean: 1.319452, proj_loss: -0.030841, loss_mean_cls: 0.111460, deep_loss: 0.031210, grad_norm: 25.808746
Steps:   0%| | 456/1000000 [08:35<322:57:25,  1.16s/it, deep_loss=0.0304, grad_norm=21.1, loss_final=1.4, loss_mean=1.29, lo[[34m2025-10-03 23:34:24[39m] Step: 456, Training Logs: loss_final: 1.361908, loss_mean: 1.250293, proj_loss: -0.028950, loss_mean_cls: 0.112112, deep_loss: 0.028453, grad_norm: 12.063342
Steps:   0%| | 458/1000000 [08:37<323:37:58,  1.17s/it, deep_loss=0.031, grad_norm=20, loss_final=1.4, loss_mean=1.29, loss_[[34m2025-10-03 23:34:26[39m] Step: 458, Training Logs: loss_final: 1.412641, loss_mean: 1.299569, proj_loss: -0.029137, loss_mean_cls: 0.110406, deep_loss: 0.031803, grad_norm: 27.040745
Steps:   0%| | 460/1000000 [08:39<323:51:49,  1.17s/it, deep_loss=0.0321, grad_norm=19.3, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:34:28[39m] Step: 460, Training Logs: loss_final: 1.428383, loss_mean: 1.317976, proj_loss: -0.030437, loss_mean_cls: 0.110410, deep_loss: 0.030435, grad_norm: 15.375274
Steps:   0%| | 462/1000000 [08:42<323:57:11,  1.17s/it, deep_loss=0.03, grad_norm=23.5, loss_final=1.39, loss_mean=1.27, los[[34m2025-10-03 23:34:31[39m] Step: 462, Training Logs: loss_final: 1.428214, loss_mean: 1.316871, proj_loss: -0.030358, loss_mean_cls: 0.109252, deep_loss: 0.032450, grad_norm: 25.103886
Steps:   0%| | 463/1000000 [08:43<324:05:54,  1.17s/it, deep_loss=0.0339, grad_norm=21.7, loss_final=1.41, loss_mean=1.29, l[[34m2025-10-03 23:34:31[39m] Step: 462, Training Logs: loss_final: 1.428214, loss_mean: 1.316871, proj_loss: -0.030358, loss_mean_cls: 0.109252, deep_loss: 0.032450, grad_norm: 25.103886
Steps:   0%| | 465/1000000 [08:45<325:22:49,  1.17s/it, deep_loss=0.0311, grad_norm=26.7, loss_final=1.42, loss_mean=1.31, l[[34m2025-10-03 23:34:33[39m] Step: 464, Training Logs: loss_final: 1.442494, loss_mean: 1.328893, proj_loss: -0.030204, loss_mean_cls: 0.111301, deep_loss: 0.032503, grad_norm: 22.083128
Steps:   0%| | 467/1000000 [08:47<322:52:44,  1.16s/it, deep_loss=0.0309, grad_norm=42.2, loss_final=1.49, loss_mean=1.37, l[[34m2025-10-03 23:34:35[39m] Step: 466, Training Logs: loss_final: 1.465364, loss_mean: 1.352957, proj_loss: -0.029044, loss_mean_cls: 0.109493, deep_loss: 0.031958, grad_norm: 23.848726
Steps:   0%| | 468/1000000 [08:49<323:08:19,  1.16s/it, deep_loss=0.0309, grad_norm=42.2, loss_final=1.49, loss_mean=1.37, l[[34m2025-10-03 23:34:38[39m] Step: 468, Training Logs: loss_final: 1.499248, loss_mean: 1.387709, proj_loss: -0.031968, loss_mean_cls: 0.111064, deep_loss: 0.032442, grad_norm: 46.259819
Steps:   0%| | 471/1000000 [08:52<287:14:18,  1.03s/it, deep_loss=0.0332, grad_norm=33.5, loss_final=1.45, loss_mean=1.34, l[[34m2025-10-03 23:34:40[39m] Step: 470, Training Logs: loss_final: 1.451499, loss_mean: 1.339094, proj_loss: -0.030844, loss_mean_cls: 0.109373, deep_loss: 0.033875, grad_norm: 24.063795
Steps:   0%| | 473/1000000 [08:53<262:22:43,  1.06it/s, deep_loss=0.0319, grad_norm=32.1, loss_final=1.45, loss_mean=1.34, l[[34m2025-10-03 23:34:41[39m] Step: 472, Training Logs: loss_final: 1.489727, loss_mean: 1.378068, proj_loss: -0.031125, loss_mean_cls: 0.110054, deep_loss: 0.032731, grad_norm: 35.000378
Steps:   0%| | 475/1000000 [08:56<293:59:10,  1.06s/it, deep_loss=0.0322, grad_norm=23.6, loss_final=1.44, loss_mean=1.33, l[[34m2025-10-03 23:34:44[39m] Step: 474, Training Logs: loss_final: 1.419763, loss_mean: 1.304694, proj_loss: -0.027816, loss_mean_cls: 0.110235, deep_loss: 0.032649, grad_norm: 23.799318
Steps:   0%| | 476/1000000 [08:57<303:22:56,  1.09s/it, deep_loss=0.0322, grad_norm=23.6, loss_final=1.44, loss_mean=1.33, l[[34m2025-10-03 23:34:46[39m] Step: 476, Training Logs: loss_final: 1.412385, loss_mean: 1.299590, proj_loss: -0.028866, loss_mean_cls: 0.110473, deep_loss: 0.031189, grad_norm: 26.815128
Steps:   0%| | 478/1000000 [08:59<314:16:15,  1.13s/it, deep_loss=0.0308, grad_norm=20.8, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:34:48[39m] Step: 478, Training Logs: loss_final: 1.411816, loss_mean: 1.300820, proj_loss: -0.030535, loss_mean_cls: 0.109800, deep_loss: 0.031731, grad_norm: 13.352361
Steps:   0%| | 480/1000000 [09:01<320:06:37,  1.15s/it, deep_loss=0.0316, grad_norm=12.8, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:34:51[39m] Step: 480, Training Logs: loss_final: 1.401610, loss_mean: 1.293073, proj_loss: -0.031976, loss_mean_cls: 0.109819, deep_loss: 0.030693, grad_norm: 14.114694
Steps:   0%| | 481/1000000 [09:03<321:46:23,  1.16s/it, deep_loss=0.0303, grad_norm=16.7, loss_final=1.41, loss_mean=1.3, lo[[34m2025-10-03 23:34:51[39m] Step: 480, Training Logs: loss_final: 1.401610, loss_mean: 1.293073, proj_loss: -0.031976, loss_mean_cls: 0.109819, deep_loss: 0.030693, grad_norm: 14.114694
Steps:   0%| | 483/1000000 [09:05<322:47:26,  1.16s/it, deep_loss=0.032, grad_norm=29.2, loss_final=1.43, loss_mean=1.32, lo[[34m2025-10-03 23:34:53[39m] Step: 482, Training Logs: loss_final: 1.367616, loss_mean: 1.257475, proj_loss: -0.030258, loss_mean_cls: 0.110502, deep_loss: 0.029897, grad_norm: 12.064272
Steps:   0%| | 485/1000000 [09:07<323:27:23,  1.17s/it, deep_loss=0.0336, grad_norm=25.5, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:34:55[39m] Step: 484, Training Logs: loss_final: 1.489491, loss_mean: 1.376081, proj_loss: -0.029940, loss_mean_cls: 0.110046, deep_loss: 0.033303, grad_norm: 36.079082
Steps:   0%| | 487/1000000 [09:10<323:50:39,  1.17s/it, deep_loss=0.0341, grad_norm=35.9, loss_final=1.58, loss_mean=1.46, l[[34m2025-10-03 23:34:58[39m] Step: 486, Training Logs: loss_final: 1.526494, loss_mean: 1.413338, proj_loss: -0.032234, loss_mean_cls: 0.112209, deep_loss: 0.033181, grad_norm: 24.500961
Steps:   0%| | 488/1000000 [09:11<324:19:15,  1.17s/it, deep_loss=0.0341, grad_norm=35.9, loss_final=1.58, loss_mean=1.46, l[[34m2025-10-03 23:35:00[39m] Step: 488, Training Logs: loss_final: 1.604614, loss_mean: 1.487722, proj_loss: -0.031267, loss_mean_cls: 0.112646, deep_loss: 0.035514, grad_norm: 40.241081
Steps:   0%| | 490/1000000 [09:13<324:16:33,  1.17s/it, deep_loss=0.0361, grad_norm=35.1, loss_final=1.6, loss_mean=1.49, lo[[34m2025-10-03 23:35:02[39m] Step: 490, Training Logs: loss_final: 1.572030, loss_mean: 1.457434, proj_loss: -0.031355, loss_mean_cls: 0.111485, deep_loss: 0.034466, grad_norm: 27.342079
Steps:   0%| | 492/1000000 [09:15<324:12:40,  1.17s/it, deep_loss=0.0366, grad_norm=24, loss_final=1.59, loss_mean=1.47, los[[34m2025-10-03 23:35:05[39m] Step: 492, Training Logs: loss_final: 1.578335, loss_mean: 1.462321, proj_loss: -0.032021, loss_mean_cls: 0.110342, deep_loss: 0.037693, grad_norm: 23.869633
Steps:   0%| | 493/1000000 [09:17<323:44:01,  1.17s/it, deep_loss=0.0363, grad_norm=28, loss_final=1.58, loss_mean=1.47, los[[34m2025-10-03 23:35:05[39m] Step: 492, Training Logs: loss_final: 1.578335, loss_mean: 1.462321, proj_loss: -0.032021, loss_mean_cls: 0.110342, deep_loss: 0.037693, grad_norm: 23.869633
Steps:   0%| | 495/1000000 [09:19<323:53:55,  1.17s/it, deep_loss=0.0353, grad_norm=22.8, loss_final=1.58, loss_mean=1.46, l[[34m2025-10-03 23:35:07[39m] Step: 494, Training Logs: loss_final: 1.606344, loss_mean: 1.489409, proj_loss: -0.030365, loss_mean_cls: 0.110065, deep_loss: 0.037235, grad_norm: 24.528269
Steps:   0%| | 497/1000000 [09:21<324:25:54,  1.17s/it, deep_loss=0.0356, grad_norm=21.5, loss_final=1.59, loss_mean=1.48, l[[34m2025-10-03 23:35:09[39m] Step: 496, Training Logs: loss_final: 1.579144, loss_mean: 1.463422, proj_loss: -0.032363, loss_mean_cls: 0.112102, deep_loss: 0.035983, grad_norm: 22.870823
Steps:   0%| | 498/1000000 [09:22<324:10:24,  1.17s/it, deep_loss=0.0356, grad_norm=21.5, loss_final=1.59, loss_mean=1.48, l[[34m2025-10-03 23:35:12[39m] Step: 498, Training Logs: loss_final: 1.566465, loss_mean: 1.452608, proj_loss: -0.031064, loss_mean_cls: 0.110183, deep_loss: 0.034738, grad_norm: 19.724344
Steps:   0%| | 500/1000000 [09:25<324:28:10,  1.17s/it, deep_loss=0.0357, grad_norm=16.4, loss_final=1.57, loss_mean=1.45, l[[34m2025-10-03 23:35:14[39m] Step: 500, Training Logs: loss_final: 1.562333, loss_mean: 1.443784, proj_loss: -0.032576, loss_mean_cls: 0.110179, deep_loss: 0.040947, grad_norm: 15.761608
Steps:   0%| | 503/1000000 [09:27<259:12:41,  1.07it/s, deep_loss=0.0418, grad_norm=12.5, loss_final=1.56, loss_mean=1.44, l[[34m2025-10-03 23:35:16[39m] Step: 502, Training Logs: loss_final: 1.558058, loss_mean: 1.437038, proj_loss: -0.031634, loss_mean_cls: 0.109872, deep_loss: 0.042782, grad_norm: 14.754024
Steps:   0%| | 504/1000000 [09:28<269:35:52,  1.03it/s, deep_loss=0.0418, grad_norm=12.5, loss_final=1.56, loss_mean=1.44, l[[34m2025-10-03 23:35:17[39m] Step: 504, Training Logs: loss_final: 1.553722, loss_mean: 1.434425, proj_loss: -0.032073, loss_mean_cls: 0.109905, deep_loss: 0.041466, grad_norm: 13.130731
Steps:   0%| | 506/1000000 [09:31<297:27:49,  1.07s/it, deep_loss=0.0411, grad_norm=13.3, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:35:20[39m] Step: 506, Training Logs: loss_final: 1.547926, loss_mean: 1.431218, proj_loss: -0.031723, loss_mean_cls: 0.109113, deep_loss: 0.039318, grad_norm: 12.313971
Steps:   0%| | 508/1000000 [09:33<310:05:07,  1.12s/it, deep_loss=0.039, grad_norm=14.3, loss_final=1.55, loss_mean=1.43, lo[[34m2025-10-03 23:35:22[39m] Step: 508, Training Logs: loss_final: 1.531539, loss_mean: 1.412448, proj_loss: -0.030307, loss_mean_cls: 0.109085, deep_loss: 0.040313, grad_norm: 14.274155
Steps:   0%| | 510/1000000 [09:35<317:35:55,  1.14s/it, deep_loss=0.0403, grad_norm=14, loss_final=1.52, loss_mean=1.4, loss[[34m2025-10-03 23:35:24[39m] Step: 510, Training Logs: loss_final: 1.525232, loss_mean: 1.408251, proj_loss: -0.031703, loss_mean_cls: 0.109831, deep_loss: 0.038854, grad_norm: 14.678030
Steps:   0%| | 512/1000000 [09:38<321:35:56,  1.16s/it, deep_loss=0.0381, grad_norm=10.9, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:35:27[39m] Step: 512, Training Logs: loss_final: 1.510481, loss_mean: 1.391788, proj_loss: -0.031904, loss_mean_cls: 0.110899, deep_loss: 0.039698, grad_norm: 14.155401
Steps:   0%| | 513/1000000 [09:39<322:26:29,  1.16s/it, deep_loss=0.0403, grad_norm=18.2, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:35:27[39m] Step: 512, Training Logs: loss_final: 1.510481, loss_mean: 1.391788, proj_loss: -0.031904, loss_mean_cls: 0.110899, deep_loss: 0.039698, grad_norm: 14.155401
Steps:   0%| | 515/1000000 [09:41<322:47:10,  1.16s/it, deep_loss=0.0407, grad_norm=12.2, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:29[39m] Step: 514, Training Logs: loss_final: 1.529677, loss_mean: 1.409078, proj_loss: -0.031665, loss_mean_cls: 0.111045, deep_loss: 0.041219, grad_norm: 18.840090
Steps:   0%| | 517/1000000 [09:44<323:12:51,  1.16s/it, deep_loss=0.0431, grad_norm=19.1, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:31[39m] Step: 516, Training Logs: loss_final: 1.537359, loss_mean: 1.414555, proj_loss: -0.029802, loss_mean_cls: 0.110572, deep_loss: 0.042034, grad_norm: 14.477155
Steps:   0%| | 518/1000000 [09:45<323:01:00,  1.16s/it, deep_loss=0.0431, grad_norm=19.1, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:34[39m] Step: 518, Training Logs: loss_final: 1.546335, loss_mean: 1.423612, proj_loss: -0.030751, loss_mean_cls: 0.110087, deep_loss: 0.043386, grad_norm: 15.456931
Steps:   0%| | 520/1000000 [09:47<322:58:22,  1.16s/it, deep_loss=0.0433, grad_norm=14.4, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:36[39m] Step: 520, Training Logs: loss_final: 1.548358, loss_mean: 1.425364, proj_loss: -0.030237, loss_mean_cls: 0.109893, deep_loss: 0.043337, grad_norm: 13.469094
Steps:   0%| | 522/1000000 [09:49<323:53:03,  1.17s/it, deep_loss=0.0429, grad_norm=11, loss_final=1.53, loss_mean=1.41, los[[34m2025-10-03 23:35:38[39m] Step: 522, Training Logs: loss_final: 1.523766, loss_mean: 1.401969, proj_loss: -0.031832, loss_mean_cls: 0.110212, deep_loss: 0.043418, grad_norm: 17.223522
Steps:   0%| | 524/1000000 [09:52<324:12:09,  1.17s/it, deep_loss=0.0428, grad_norm=18.1, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:35:41[39m] Step: 524, Training Logs: loss_final: 1.531443, loss_mean: 1.410234, proj_loss: -0.031597, loss_mean_cls: 0.109995, deep_loss: 0.042811, grad_norm: 12.275040
Steps:   0%| | 525/1000000 [09:53<323:42:41,  1.17s/it, deep_loss=0.0423, grad_norm=16.7, loss_final=1.55, loss_mean=1.43, l[[34m2025-10-03 23:35:41[39m] Step: 524, Training Logs: loss_final: 1.531443, loss_mean: 1.410234, proj_loss: -0.031597, loss_mean_cls: 0.109995, deep_loss: 0.042811, grad_norm: 12.275040
Steps:   0%| | 527/1000000 [09:55<324:47:16,  1.17s/it, deep_loss=0.0426, grad_norm=18.9, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:35:43[39m] Step: 526, Training Logs: loss_final: 1.523865, loss_mean: 1.403132, proj_loss: -0.031578, loss_mean_cls: 0.109729, deep_loss: 0.042580, grad_norm: 21.785337
Steps:   0%| | 529/1000000 [09:58<325:23:42,  1.17s/it, deep_loss=0.0421, grad_norm=19.9, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:45[39m] Step: 528, Training Logs: loss_final: 1.539369, loss_mean: 1.419647, proj_loss: -0.031858, loss_mean_cls: 0.109813, deep_loss: 0.041767, grad_norm: 20.048458
Steps:   0%| | 530/1000000 [09:59<325:26:03,  1.17s/it, deep_loss=0.0421, grad_norm=19.9, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:48[39m] Step: 530, Training Logs: loss_final: 1.533398, loss_mean: 1.411717, proj_loss: -0.030493, loss_mean_cls: 0.110843, deep_loss: 0.041331, grad_norm: 26.446838
Steps:   0%| | 533/1000000 [10:01<268:48:48,  1.03it/s, deep_loss=0.0414, grad_norm=21.5, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-03 23:35:50[39m] Step: 532, Training Logs: loss_final: 1.542949, loss_mean: 1.422007, proj_loss: -0.030306, loss_mean_cls: 0.109085, deep_loss: 0.042163, grad_norm: 16.918571
Steps:   0%| | 535/1000000 [10:04<279:56:37,  1.01s/it, deep_loss=0.0421, grad_norm=23.3, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:35:51[39m] Step: 534, Training Logs: loss_final: 1.525402, loss_mean: 1.403094, proj_loss: -0.030076, loss_mean_cls: 0.111029, deep_loss: 0.041355, grad_norm: 24.499977
Steps:   0%| | 537/1000000 [10:06<302:22:41,  1.09s/it, deep_loss=0.0415, grad_norm=23.9, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:54[39m] Step: 536, Training Logs: loss_final: 1.548569, loss_mean: 1.428198, proj_loss: -0.030869, loss_mean_cls: 0.109369, deep_loss: 0.041871, grad_norm: 21.117626
Steps:   0%| | 538/1000000 [10:07<310:05:58,  1.12s/it, deep_loss=0.0415, grad_norm=23.9, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:56[39m] Step: 538, Training Logs: loss_final: 1.539218, loss_mean: 1.418309, proj_loss: -0.030336, loss_mean_cls: 0.110638, deep_loss: 0.040607, grad_norm: 28.956427
Steps:   0%| | 540/1000000 [10:09<317:14:38,  1.14s/it, deep_loss=0.0398, grad_norm=25.4, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:35:58[39m] Step: 540, Training Logs: loss_final: 1.542685, loss_mean: 1.423828, proj_loss: -0.031327, loss_mean_cls: 0.109833, deep_loss: 0.040350, grad_norm: 24.844955
Steps:   0%| | 542/1000000 [10:12<320:44:30,  1.16s/it, deep_loss=0.0402, grad_norm=25.1, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:36:01[39m] Step: 542, Training Logs: loss_final: 1.551368, loss_mean: 1.429724, proj_loss: -0.028558, loss_mean_cls: 0.110178, deep_loss: 0.040023, grad_norm: 31.140396
Steps:   0%| | 543/1000000 [10:13<321:41:20,  1.16s/it, deep_loss=0.041, grad_norm=29.9, loss_final=1.55, loss_mean=1.43, lo[[34m2025-10-03 23:36:01[39m] Step: 542, Training Logs: loss_final: 1.551368, loss_mean: 1.429724, proj_loss: -0.028558, loss_mean_cls: 0.110178, deep_loss: 0.040023, grad_norm: 31.140396
Steps:   0%| | 545/1000000 [10:15<324:06:14,  1.17s/it, deep_loss=0.04, grad_norm=26.1, loss_final=1.54, loss_mean=1.42, los[[34m2025-10-03 23:36:03[39m] Step: 544, Training Logs: loss_final: 1.529203, loss_mean: 1.408366, proj_loss: -0.031469, loss_mean_cls: 0.111151, deep_loss: 0.041155, grad_norm: 26.565626
Steps:   0%| | 547/1000000 [10:18<324:37:22,  1.17s/it, deep_loss=0.0399, grad_norm=29.7, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:36:05[39m] Step: 546, Training Logs: loss_final: 1.522194, loss_mean: 1.403566, proj_loss: -0.031755, loss_mean_cls: 0.109779, deep_loss: 0.040604, grad_norm: 29.173189
Steps:   0%| | 548/1000000 [10:19<325:08:38,  1.17s/it, deep_loss=0.0399, grad_norm=29.7, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:36:08[39m] Step: 548, Training Logs: loss_final: 1.549992, loss_mean: 1.432146, proj_loss: -0.031678, loss_mean_cls: 0.109708, deep_loss: 0.039816, grad_norm: 27.366146
Steps:   0%| | 550/1000000 [10:21<325:06:16,  1.17s/it, deep_loss=0.0402, grad_norm=25, loss_final=1.53, loss_mean=1.42, los[[34m2025-10-03 23:36:10[39m] Step: 550, Training Logs: loss_final: 1.530144, loss_mean: 1.410526, proj_loss: -0.029809, loss_mean_cls: 0.110112, deep_loss: 0.039315, grad_norm: 27.034975
Steps:   0%| | 552/1000000 [10:23<324:07:50,  1.17s/it, deep_loss=0.0401, grad_norm=26.6, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:36:12[39m] Step: 552, Training Logs: loss_final: 1.539572, loss_mean: 1.421512, proj_loss: -0.031563, loss_mean_cls: 0.109743, deep_loss: 0.039881, grad_norm: 30.048241
Steps:   0%| | 554/1000000 [10:26<325:03:13,  1.17s/it, deep_loss=0.0402, grad_norm=24, loss_final=1.54, loss_mean=1.43, los[[34m2025-10-03 23:36:15[39m] Step: 554, Training Logs: loss_final: 1.512684, loss_mean: 1.395189, proj_loss: -0.032003, loss_mean_cls: 0.109948, deep_loss: 0.039550, grad_norm: 22.495483
Steps:   0%| | 555/1000000 [10:27<325:25:22,  1.17s/it, deep_loss=0.0391, grad_norm=27.4, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:36:15[39m] Step: 554, Training Logs: loss_final: 1.512684, loss_mean: 1.395189, proj_loss: -0.032003, loss_mean_cls: 0.109948, deep_loss: 0.039550, grad_norm: 22.495483
Steps:   0%| | 557/1000000 [10:29<324:43:16,  1.17s/it, deep_loss=0.0382, grad_norm=19.8, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:36:17[39m] Step: 556, Training Logs: loss_final: 1.525804, loss_mean: 1.405933, proj_loss: -0.029849, loss_mean_cls: 0.110075, deep_loss: 0.039645, grad_norm: 21.559290
Steps:   0%| | 559/1000000 [10:32<324:41:30,  1.17s/it, deep_loss=0.0393, grad_norm=23.2, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:36:19[39m] Step: 558, Training Logs: loss_final: 1.524853, loss_mean: 1.406385, proj_loss: -0.030680, loss_mean_cls: 0.109971, deep_loss: 0.039176, grad_norm: 23.595114
Steps:   0%| | 560/1000000 [10:33<325:47:57,  1.17s/it, deep_loss=0.0393, grad_norm=23.2, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:36:22[39m] Step: 560, Training Logs: loss_final: 1.504212, loss_mean: 1.386288, proj_loss: -0.031751, loss_mean_cls: 0.110657, deep_loss: 0.039018, grad_norm: 24.259106
Steps:   0%| | 563/1000000 [10:36<279:03:47,  1.01s/it, deep_loss=0.0384, grad_norm=23.7, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:36:24[39m] Step: 562, Training Logs: loss_final: 1.509188, loss_mean: 1.393400, proj_loss: -0.032902, loss_mean_cls: 0.109511, deep_loss: 0.039179, grad_norm: 23.875490
Steps:   0%| | 565/1000000 [10:37<249:00:51,  1.11it/s, deep_loss=0.0391, grad_norm=20.9, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:36:25[39m] Step: 564, Training Logs: loss_final: 1.522577, loss_mean: 1.404962, proj_loss: -0.031149, loss_mean_cls: 0.109544, deep_loss: 0.039220, grad_norm: 22.588345
Steps:   0%| | 567/1000000 [10:39<270:21:53,  1.03it/s, deep_loss=0.0392, grad_norm=23.9, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-03 23:36:27[39m] Step: 566, Training Logs: loss_final: 1.511473, loss_mean: 1.394419, proj_loss: -0.031083, loss_mean_cls: 0.109140, deep_loss: 0.038997, grad_norm: 26.269846
Steps:   0%| | 569/1000000 [10:42<297:30:52,  1.07s/it, deep_loss=0.0391, grad_norm=24.5, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:36:29[39m] Step: 568, Training Logs: loss_final: 1.507361, loss_mean: 1.390789, proj_loss: -0.031788, loss_mean_cls: 0.108804, deep_loss: 0.039557, grad_norm: 18.489534
Steps:   0%| | 571/1000000 [10:44<312:14:27,  1.12s/it, deep_loss=0.0385, grad_norm=26.7, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:36:32[39m] Step: 570, Training Logs: loss_final: 1.505543, loss_mean: 1.386428, proj_loss: -0.030974, loss_mean_cls: 0.110641, deep_loss: 0.039447, grad_norm: 22.674603
Steps:   0%| | 572/1000000 [10:45<315:51:08,  1.14s/it, deep_loss=0.0385, grad_norm=26.7, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:36:34[39m] Step: 572, Training Logs: loss_final: 1.514055, loss_mean: 1.398397, proj_loss: -0.032704, loss_mean_cls: 0.109301, deep_loss: 0.039060, grad_norm: 27.232084
Steps:   0%| | 574/1000000 [10:47<320:52:48,  1.16s/it, deep_loss=0.0389, grad_norm=27, loss_final=1.52, loss_mean=1.4, loss[[34m2025-10-03 23:36:37[39m] Step: 574, Training Logs: loss_final: 1.527734, loss_mean: 1.411675, proj_loss: -0.031989, loss_mean_cls: 0.109478, deep_loss: 0.038570, grad_norm: 32.017212
Steps:   0%| | 576/1000000 [10:50<321:18:10,  1.16s/it, deep_loss=0.0376, grad_norm=31.2, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:36:39[39m] Step: 576, Training Logs: loss_final: 1.536031, loss_mean: 1.421028, proj_loss: -0.031512, loss_mean_cls: 0.107763, deep_loss: 0.038751, grad_norm: 33.084854
Steps:   0%| | 577/1000000 [10:51<322:09:26,  1.16s/it, deep_loss=0.0378, grad_norm=34.6, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:36:39[39m] Step: 576, Training Logs: loss_final: 1.536031, loss_mean: 1.421028, proj_loss: -0.031512, loss_mean_cls: 0.107763, deep_loss: 0.038751, grad_norm: 33.084854
Steps:   0%| | 579/1000000 [10:53<323:51:01,  1.17s/it, deep_loss=0.037, grad_norm=26.4, loss_final=1.52, loss_mean=1.4, los[[34m2025-10-03 23:36:41[39m] Step: 578, Training Logs: loss_final: 1.497222, loss_mean: 1.378858, proj_loss: -0.029939, loss_mean_cls: 0.111510, deep_loss: 0.036793, grad_norm: 27.451960
Steps:   0%| | 581/1000000 [10:56<322:23:53,  1.16s/it, deep_loss=0.0368, grad_norm=32.2, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:36:44[39m] Step: 580, Training Logs: loss_final: 1.558198, loss_mean: 1.445147, proj_loss: -0.030458, loss_mean_cls: 0.106888, deep_loss: 0.036621, grad_norm: 36.688271
Steps:   0%| | 583/1000000 [10:58<321:46:43,  1.16s/it, deep_loss=0.0374, grad_norm=30.6, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:36:46[39m] Step: 582, Training Logs: loss_final: 1.502099, loss_mean: 1.388129, proj_loss: -0.032532, loss_mean_cls: 0.109187, deep_loss: 0.037315, grad_norm: 24.325897
Steps:   0%| | 584/1000000 [10:59<322:24:50,  1.16s/it, deep_loss=0.0374, grad_norm=30.6, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:36:48[39m] Step: 584, Training Logs: loss_final: 1.542633, loss_mean: 1.425200, proj_loss: -0.029868, loss_mean_cls: 0.109452, deep_loss: 0.037848, grad_norm: 32.501835
Steps:   0%| | 586/1000000 [11:01<322:45:00,  1.16s/it, deep_loss=0.0364, grad_norm=26.1, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:36:50[39m] Step: 586, Training Logs: loss_final: 1.521811, loss_mean: 1.408475, proj_loss: -0.031345, loss_mean_cls: 0.108571, deep_loss: 0.036111, grad_norm: 29.632685
Steps:   0%| | 588/1000000 [11:04<324:40:07,  1.17s/it, deep_loss=0.0358, grad_norm=27.1, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:36:53[39m] Step: 588, Training Logs: loss_final: 1.511256, loss_mean: 1.394484, proj_loss: -0.029828, loss_mean_cls: 0.109167, deep_loss: 0.037432, grad_norm: 29.470667
Steps:   0%| | 589/1000000 [11:05<325:18:40,  1.17s/it, deep_loss=0.0363, grad_norm=33.3, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:36:53[39m] Step: 588, Training Logs: loss_final: 1.511256, loss_mean: 1.394484, proj_loss: -0.029828, loss_mean_cls: 0.109167, deep_loss: 0.037432, grad_norm: 29.470667
Steps:   0%| | 591/1000000 [11:07<323:06:03,  1.16s/it, deep_loss=0.0358, grad_norm=31.3, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:36:55[39m] Step: 590, Training Logs: loss_final: 1.498302, loss_mean: 1.382179, proj_loss: -0.030207, loss_mean_cls: 0.109774, deep_loss: 0.036555, grad_norm: 27.855305
Steps:   0%| | 593/1000000 [11:10<324:05:48,  1.17s/it, deep_loss=0.0362, grad_norm=26, loss_final=1.51, loss_mean=1.39, los[[34m2025-10-03 23:36:57[39m] Step: 592, Training Logs: loss_final: 1.505297, loss_mean: 1.389860, proj_loss: -0.030406, loss_mean_cls: 0.110274, deep_loss: 0.035568, grad_norm: 34.946663
Steps:   0%| | 595/1000000 [11:11<279:48:54,  1.01s/it, deep_loss=0.0359, grad_norm=40.9, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:37:00[39m] Step: 594, Training Logs: loss_final: 1.517461, loss_mean: 1.404839, proj_loss: -0.029817, loss_mean_cls: 0.108837, deep_loss: 0.033602, grad_norm: 28.448891
Steps:   0%| | 598/1000000 [11:14<254:53:39,  1.09it/s, deep_loss=0.0364, grad_norm=28, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:37:03[39m] Step: 598, Training Logs: loss_final: 1.502446, loss_mean: 1.390261, proj_loss: -0.031263, loss_mean_cls: 0.109327, deep_loss: 0.034121, grad_norm: 35.112476
Steps:   0%| | 599/1000000 [11:15<275:38:27,  1.01it/s, deep_loss=0.0354, grad_norm=30.9, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:37:03[39m] Step: 598, Training Logs: loss_final: 1.502446, loss_mean: 1.390261, proj_loss: -0.031263, loss_mean_cls: 0.109327, deep_loss: 0.034121, grad_norm: 35.112476
Steps:   0%| | 601/1000000 [11:17<300:41:23,  1.08s/it, deep_loss=0.0363, grad_norm=33, loss_final=1.5, loss_mean=1.38, loss[[34m2025-10-03 23:37:05[39m] Step: 600, Training Logs: loss_final: 1.504845, loss_mean: 1.391951, proj_loss: -0.030770, loss_mean_cls: 0.108916, deep_loss: 0.034748, grad_norm: 25.158918
Steps:   0%| | 603/1000000 [11:20<310:14:41,  1.12s/it, deep_loss=0.0349, grad_norm=29.3, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-03 23:37:08[39m] Step: 602, Training Logs: loss_final: 1.518332, loss_mean: 1.402500, proj_loss: -0.029356, loss_mean_cls: 0.109500, deep_loss: 0.035688, grad_norm: 34.027706
Steps:   0%| | 605/1000000 [11:22<317:09:43,  1.14s/it, deep_loss=0.0356, grad_norm=35, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:37:10[39m] Step: 604, Training Logs: loss_final: 1.506286, loss_mean: 1.393178, proj_loss: -0.030873, loss_mean_cls: 0.109294, deep_loss: 0.034686, grad_norm: 28.918423
Steps:   0%| | 606/1000000 [11:23<319:40:07,  1.15s/it, deep_loss=0.0356, grad_norm=35, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:37:12[39m] Step: 606, Training Logs: loss_final: 1.481960, loss_mean: 1.368360, proj_loss: -0.031160, loss_mean_cls: 0.110083, deep_loss: 0.034677, grad_norm: 30.612713
Steps:   0%| | 608/1000000 [11:26<322:05:53,  1.16s/it, deep_loss=0.0354, grad_norm=32.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:37:15[39m] Step: 608, Training Logs: loss_final: 1.510495, loss_mean: 1.396452, proj_loss: -0.031643, loss_mean_cls: 0.109741, deep_loss: 0.035946, grad_norm: 35.254372
Steps:   0%| | 610/1000000 [11:28<322:38:38,  1.16s/it, deep_loss=0.0355, grad_norm=32.4, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:37:17[39m] Step: 610, Training Logs: loss_final: 1.523110, loss_mean: 1.408127, proj_loss: -0.029642, loss_mean_cls: 0.109355, deep_loss: 0.035270, grad_norm: 43.554050
Steps:   0%| | 611/1000000 [11:29<323:03:03,  1.16s/it, deep_loss=0.0356, grad_norm=41.3, loss_final=1.53, loss_mean=1.41, l[[34m2025-10-03 23:37:17[39m] Step: 610, Training Logs: loss_final: 1.523110, loss_mean: 1.408127, proj_loss: -0.029642, loss_mean_cls: 0.109355, deep_loss: 0.035270, grad_norm: 43.554050
Steps:   0%| | 613/1000000 [11:31<324:43:04,  1.17s/it, deep_loss=0.034, grad_norm=41.1, loss_final=1.52, loss_mean=1.41, lo[[34m2025-10-03 23:37:19[39m] Step: 612, Training Logs: loss_final: 1.526544, loss_mean: 1.412453, proj_loss: -0.029876, loss_mean_cls: 0.108470, deep_loss: 0.035497, grad_norm: 33.219955
Steps:   0%| | 615/1000000 [11:34<326:00:52,  1.17s/it, deep_loss=0.0348, grad_norm=33.7, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-03 23:37:22[39m] Step: 614, Training Logs: loss_final: 1.533149, loss_mean: 1.421262, proj_loss: -0.031173, loss_mean_cls: 0.107914, deep_loss: 0.035146, grad_norm: 42.399509
Steps:   0%| | 617/1000000 [11:36<327:04:40,  1.18s/it, deep_loss=0.0353, grad_norm=49.2, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:37:24[39m] Step: 616, Training Logs: loss_final: 1.514940, loss_mean: 1.405184, proj_loss: -0.031904, loss_mean_cls: 0.107956, deep_loss: 0.033703, grad_norm: 41.479412
Steps:   0%| | 618/1000000 [11:37<326:56:10,  1.18s/it, deep_loss=0.0353, grad_norm=49.2, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:37:26[39m] Step: 618, Training Logs: loss_final: 1.456471, loss_mean: 1.341286, proj_loss: -0.030296, loss_mean_cls: 0.111067, deep_loss: 0.034415, grad_norm: 41.944553
Steps:   0%| | 620/1000000 [11:40<326:14:31,  1.18s/it, deep_loss=0.0344, grad_norm=29.7, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:37:29[39m] Step: 620, Training Logs: loss_final: 1.493883, loss_mean: 1.383222, proj_loss: -0.031392, loss_mean_cls: 0.107868, deep_loss: 0.034185, grad_norm: 41.580177
Steps:   0%| | 622/1000000 [11:42<327:02:07,  1.18s/it, deep_loss=0.0346, grad_norm=48.2, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:37:31[39m] Step: 622, Training Logs: loss_final: 1.485308, loss_mean: 1.372821, proj_loss: -0.031025, loss_mean_cls: 0.110328, deep_loss: 0.033183, grad_norm: 37.177265
Steps:   0%| | 623/1000000 [11:43<326:12:00,  1.18s/it, deep_loss=0.0339, grad_norm=34.7, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-03 23:37:31[39m] Step: 622, Training Logs: loss_final: 1.485308, loss_mean: 1.372821, proj_loss: -0.031025, loss_mean_cls: 0.110328, deep_loss: 0.033183, grad_norm: 37.177265
Steps:   0%| | 625/1000000 [11:46<326:05:38,  1.17s/it, deep_loss=0.0342, grad_norm=42.2, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:37:33[39m] Step: 624, Training Logs: loss_final: 1.497696, loss_mean: 1.385860, proj_loss: -0.031537, loss_mean_cls: 0.108966, deep_loss: 0.034407, grad_norm: 40.011276
Steps:   0%| | 628/1000000 [11:48<256:30:36,  1.08it/s, deep_loss=0.034, grad_norm=35.4, loss_final=1.5, loss_mean=1.39, los[[34m2025-10-03 23:37:37[39m] Step: 628, Training Logs: loss_final: 1.502583, loss_mean: 1.389869, proj_loss: -0.031313, loss_mean_cls: 0.110202, deep_loss: 0.033825, grad_norm: 42.277130
Steps:   0%| | 630/1000000 [11:50<277:02:04,  1.00it/s, deep_loss=0.0344, grad_norm=40.8, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-03 23:37:39[39m] Step: 630, Training Logs: loss_final: 1.506282, loss_mean: 1.393837, proj_loss: -0.030474, loss_mean_cls: 0.108337, deep_loss: 0.034582, grad_norm: 36.684586
Steps:   0%| | 631/1000000 [11:51<291:08:08,  1.05s/it, deep_loss=0.0351, grad_norm=43, loss_final=1.49, loss_mean=1.37, los[[34m2025-10-03 23:37:39[39m] Step: 630, Training Logs: loss_final: 1.506282, loss_mean: 1.393837, proj_loss: -0.030474, loss_mean_cls: 0.108337, deep_loss: 0.034582, grad_norm: 36.684586
Steps:   0%| | 633/1000000 [11:54<308:05:29,  1.11s/it, deep_loss=0.0348, grad_norm=40.8, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:37:41[39m] Step: 632, Training Logs: loss_final: 1.488670, loss_mean: 1.377026, proj_loss: -0.032082, loss_mean_cls: 0.109206, deep_loss: 0.034520, grad_norm: 45.239880
Steps:   0%| | 635/1000000 [11:56<317:25:44,  1.14s/it, deep_loss=0.0339, grad_norm=41.2, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:37:44[39m] Step: 634, Training Logs: loss_final: 1.517631, loss_mean: 1.403788, proj_loss: -0.029033, loss_mean_cls: 0.109166, deep_loss: 0.033710, grad_norm: 44.917370
Steps:   0%| | 637/1000000 [11:58<320:30:03,  1.15s/it, deep_loss=0.0337, grad_norm=39.8, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:37:46[39m] Step: 636, Training Logs: loss_final: 1.530552, loss_mean: 1.414807, proj_loss: -0.029184, loss_mean_cls: 0.108996, deep_loss: 0.035933, grad_norm: 40.910889
Steps:   0%| | 638/1000000 [11:59<321:34:31,  1.16s/it, deep_loss=0.0337, grad_norm=39.8, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:37:48[39m] Step: 638, Training Logs: loss_final: 1.550308, loss_mean: 1.438831, proj_loss: -0.031021, loss_mean_cls: 0.107458, deep_loss: 0.035041, grad_norm: 40.990711
Steps:   0%| | 640/1000000 [12:02<323:25:06,  1.17s/it, deep_loss=0.0344, grad_norm=42.4, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:37:51[39m] Step: 640, Training Logs: loss_final: 1.527600, loss_mean: 1.416613, proj_loss: -0.030974, loss_mean_cls: 0.108031, deep_loss: 0.033930, grad_norm: 32.810467
Steps:   0%| | 642/1000000 [12:04<323:20:22,  1.16s/it, deep_loss=0.0341, grad_norm=34.5, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:37:53[39m] Step: 642, Training Logs: loss_final: 1.514294, loss_mean: 1.401768, proj_loss: -0.028971, loss_mean_cls: 0.108189, deep_loss: 0.033307, grad_norm: 37.536243
Steps:   0%| | 643/1000000 [12:05<323:48:17,  1.17s/it, deep_loss=0.0337, grad_norm=35, loss_final=1.48, loss_mean=1.37, los[[34m2025-10-03 23:37:53[39m] Step: 642, Training Logs: loss_final: 1.514294, loss_mean: 1.401768, proj_loss: -0.028971, loss_mean_cls: 0.108189, deep_loss: 0.033307, grad_norm: 37.536243
Steps:   0%| | 645/1000000 [12:08<322:57:24,  1.16s/it, deep_loss=0.0339, grad_norm=30.4, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:37:55[39m] Step: 644, Training Logs: loss_final: 1.504623, loss_mean: 1.393931, proj_loss: -0.030647, loss_mean_cls: 0.108878, deep_loss: 0.032462, grad_norm: 35.135792
Steps:   0%| | 647/1000000 [12:10<324:31:27,  1.17s/it, deep_loss=0.0324, grad_norm=34.9, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:37:58[39m] Step: 646, Training Logs: loss_final: 1.490566, loss_mean: 1.378960, proj_loss: -0.030297, loss_mean_cls: 0.109170, deep_loss: 0.032734, grad_norm: 39.249874
Steps:   0%| | 649/1000000 [12:12<324:30:37,  1.17s/it, deep_loss=0.0325, grad_norm=37, loss_final=1.47, loss_mean=1.36, los[[34m2025-10-03 23:38:00[39m] Step: 648, Training Logs: loss_final: 1.505421, loss_mean: 1.391897, proj_loss: -0.030308, loss_mean_cls: 0.110475, deep_loss: 0.033357, grad_norm: 37.444141
Steps:   0%| | 650/1000000 [12:13<323:56:26,  1.17s/it, deep_loss=0.0325, grad_norm=37, loss_final=1.47, loss_mean=1.36, los[[34m2025-10-03 23:38:02[39m] Step: 650, Training Logs: loss_final: 1.493220, loss_mean: 1.381010, proj_loss: -0.031197, loss_mean_cls: 0.109437, deep_loss: 0.033969, grad_norm: 28.042894
Steps:   0%| | 652/1000000 [12:16<324:10:16,  1.17s/it, deep_loss=0.0332, grad_norm=30.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:38:05[39m] Step: 652, Training Logs: loss_final: 1.492037, loss_mean: 1.379598, proj_loss: -0.030347, loss_mean_cls: 0.109272, deep_loss: 0.033515, grad_norm: 34.597771
Steps:   0%| | 654/1000000 [12:18<324:49:50,  1.17s/it, deep_loss=0.033, grad_norm=30.1, loss_final=1.48, loss_mean=1.38, lo[[34m2025-10-03 23:38:07[39m] Step: 654, Training Logs: loss_final: 1.508114, loss_mean: 1.396618, proj_loss: -0.031258, loss_mean_cls: 0.108487, deep_loss: 0.034267, grad_norm: 37.113655
Steps:   0%| | 655/1000000 [12:19<323:53:34,  1.17s/it, deep_loss=0.0338, grad_norm=34.1, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-03 23:38:07[39m] Step: 654, Training Logs: loss_final: 1.508114, loss_mean: 1.396618, proj_loss: -0.031258, loss_mean_cls: 0.108487, deep_loss: 0.034267, grad_norm: 37.113655
Steps:   0%| | 658/1000000 [12:22<276:17:39,  1.00it/s, deep_loss=0.0341, grad_norm=30, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:38:11[39m] Step: 658, Training Logs: loss_final: 1.488770, loss_mean: 1.376495, proj_loss: -0.030861, loss_mean_cls: 0.109072, deep_loss: 0.034064, grad_norm: 34.110043
Steps:   0%| | 660/1000000 [12:24<246:33:48,  1.13it/s, deep_loss=0.0338, grad_norm=38, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:38:13[39m] Step: 660, Training Logs: loss_final: 1.513671, loss_mean: 1.398292, proj_loss: -0.028995, loss_mean_cls: 0.109448, deep_loss: 0.034926, grad_norm: 31.348043
Steps:   0%| | 662/1000000 [12:26<284:37:03,  1.03s/it, deep_loss=0.0332, grad_norm=34.8, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-03 23:38:15[39m] Step: 662, Training Logs: loss_final: 1.498703, loss_mean: 1.385264, proj_loss: -0.031099, loss_mean_cls: 0.109943, deep_loss: 0.034595, grad_norm: 33.658318
Steps:   0%| | 664/1000000 [12:28<304:42:31,  1.10s/it, deep_loss=0.0342, grad_norm=36, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:38:17[39m] Step: 664, Training Logs: loss_final: 1.475413, loss_mean: 1.363898, proj_loss: -0.030100, loss_mean_cls: 0.108998, deep_loss: 0.032616, grad_norm: 35.828217
Steps:   0%| | 665/1000000 [12:29<309:37:59,  1.12s/it, deep_loss=0.0344, grad_norm=41.7, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:38:17[39m] Step: 664, Training Logs: loss_final: 1.475413, loss_mean: 1.363898, proj_loss: -0.030100, loss_mean_cls: 0.108998, deep_loss: 0.032616, grad_norm: 35.828217
Steps:   0%| | 667/1000000 [12:32<316:30:43,  1.14s/it, deep_loss=0.0343, grad_norm=46.1, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:38:20[39m] Step: 666, Training Logs: loss_final: 1.509102, loss_mean: 1.396271, proj_loss: -0.030425, loss_mean_cls: 0.108467, deep_loss: 0.034789, grad_norm: 43.664619
Steps:   0%| | 669/1000000 [12:34<320:02:35,  1.15s/it, deep_loss=0.0349, grad_norm=44.9, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:38:22[39m] Step: 668, Training Logs: loss_final: 1.501793, loss_mean: 1.390352, proj_loss: -0.031798, loss_mean_cls: 0.109032, deep_loss: 0.034207, grad_norm: 44.092144
Steps:   0%| | 670/1000000 [12:35<321:30:53,  1.16s/it, deep_loss=0.0349, grad_norm=44.9, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:38:24[39m] Step: 670, Training Logs: loss_final: 1.537943, loss_mean: 1.425801, proj_loss: -0.030858, loss_mean_cls: 0.108441, deep_loss: 0.034560, grad_norm: 46.509907
Steps:   0%| | 672/1000000 [12:38<323:36:33,  1.17s/it, deep_loss=0.0342, grad_norm=48.4, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:38:27[39m] Step: 672, Training Logs: loss_final: 1.528130, loss_mean: 1.415314, proj_loss: -0.031079, loss_mean_cls: 0.108454, deep_loss: 0.035441, grad_norm: 50.577354
Steps:   0%| | 674/1000000 [12:40<322:32:33,  1.16s/it, deep_loss=0.0342, grad_norm=44.1, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:38:29[39m] Step: 674, Training Logs: loss_final: 1.498171, loss_mean: 1.386118, proj_loss: -0.030869, loss_mean_cls: 0.108941, deep_loss: 0.033981, grad_norm: 53.879696
Steps:   0%| | 676/1000000 [12:42<324:13:22,  1.17s/it, deep_loss=0.0345, grad_norm=56.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:38:31[39m] Step: 676, Training Logs: loss_final: 1.515652, loss_mean: 1.402320, proj_loss: -0.030056, loss_mean_cls: 0.108616, deep_loss: 0.034773, grad_norm: 43.675152
Steps:   0%| | 677/1000000 [12:43<324:22:43,  1.17s/it, deep_loss=0.0334, grad_norm=50.2, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:38:31[39m] Step: 676, Training Logs: loss_final: 1.515652, loss_mean: 1.402320, proj_loss: -0.030056, loss_mean_cls: 0.108616, deep_loss: 0.034773, grad_norm: 43.675152
Steps:   0%| | 679/1000000 [12:46<324:49:07,  1.17s/it, deep_loss=0.0353, grad_norm=47.1, loss_final=1.55, loss_mean=1.44, l[[34m2025-10-03 23:38:34[39m] Step: 678, Training Logs: loss_final: 1.550026, loss_mean: 1.438534, proj_loss: -0.030446, loss_mean_cls: 0.106505, deep_loss: 0.035434, grad_norm: 56.037670
Steps:   0%| | 681/1000000 [12:48<325:24:00,  1.17s/it, deep_loss=0.0348, grad_norm=46.5, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:38:36[39m] Step: 680, Training Logs: loss_final: 1.502469, loss_mean: 1.389649, proj_loss: -0.030652, loss_mean_cls: 0.109846, deep_loss: 0.033626, grad_norm: 39.931953
Steps:   0%| | 682/1000000 [12:49<324:58:21,  1.17s/it, deep_loss=0.0348, grad_norm=46.5, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:38:38[39m] Step: 682, Training Logs: loss_final: 1.521926, loss_mean: 1.409421, proj_loss: -0.031049, loss_mean_cls: 0.108443, deep_loss: 0.035111, grad_norm: 50.019348
Steps:   0%| | 684/1000000 [12:52<324:51:11,  1.17s/it, deep_loss=0.0341, grad_norm=36.7, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:38:41[39m] Step: 684, Training Logs: loss_final: 1.506832, loss_mean: 1.393419, proj_loss: -0.029080, loss_mean_cls: 0.108829, deep_loss: 0.033663, grad_norm: 35.721222
Steps:   0%| | 686/1000000 [12:54<325:07:16,  1.17s/it, deep_loss=0.0332, grad_norm=48, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:38:43[39m] Step: 686, Training Logs: loss_final: 1.513310, loss_mean: 1.403475, proj_loss: -0.031432, loss_mean_cls: 0.107153, deep_loss: 0.034114, grad_norm: 32.551411
Steps:   0%| | 688/1000000 [12:56<314:42:10,  1.13s/it, deep_loss=0.0337, grad_norm=32.2, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:38:45[39m] Step: 688, Training Logs: loss_final: 1.489570, loss_mean: 1.377347, proj_loss: -0.030289, loss_mean_cls: 0.108712, deep_loss: 0.033800, grad_norm: 36.282932
Steps:   0%| | 690/1000000 [12:58<265:19:44,  1.05it/s, deep_loss=0.0329, grad_norm=37.6, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:38:47[39m] Step: 690, Training Logs: loss_final: 1.473544, loss_mean: 1.362849, proj_loss: -0.030993, loss_mean_cls: 0.109401, deep_loss: 0.032287, grad_norm: 28.845873
Steps:   0%| | 692/1000000 [13:00<266:01:29,  1.04it/s, deep_loss=0.0333, grad_norm=39.5, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:38:49[39m] Step: 692, Training Logs: loss_final: 1.475436, loss_mean: 1.365854, proj_loss: -0.032464, loss_mean_cls: 0.108569, deep_loss: 0.033477, grad_norm: 40.686115
Steps:   0%| | 694/1000000 [13:02<296:18:25,  1.07s/it, deep_loss=0.0334, grad_norm=34.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:38:51[39m] Step: 694, Training Logs: loss_final: 1.516469, loss_mean: 1.405120, proj_loss: -0.030641, loss_mean_cls: 0.108140, deep_loss: 0.033850, grad_norm: 44.702374
Steps:   0%| | 696/1000000 [13:04<311:02:51,  1.12s/it, deep_loss=0.0335, grad_norm=45.7, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-03 23:38:53[39m] Step: 696, Training Logs: loss_final: 1.522852, loss_mean: 1.411434, proj_loss: -0.029486, loss_mean_cls: 0.107855, deep_loss: 0.033049, grad_norm: 42.480919
Steps:   0%| | 697/1000000 [13:06<315:43:40,  1.14s/it, deep_loss=0.033, grad_norm=43.1, loss_final=1.52, loss_mean=1.41, lo[[34m2025-10-03 23:38:53[39m] Step: 696, Training Logs: loss_final: 1.522852, loss_mean: 1.411434, proj_loss: -0.029486, loss_mean_cls: 0.107855, deep_loss: 0.033049, grad_norm: 42.480919
Steps:   0%| | 699/1000000 [13:08<319:59:15,  1.15s/it, deep_loss=0.0357, grad_norm=62.2, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:38:56[39m] Step: 698, Training Logs: loss_final: 1.540145, loss_mean: 1.426232, proj_loss: -0.029044, loss_mean_cls: 0.108588, deep_loss: 0.034369, grad_norm: 43.355209
Steps:   0%| | 701/1000000 [13:10<323:38:45,  1.17s/it, deep_loss=0.0344, grad_norm=38.7, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:38:58[39m] Step: 700, Training Logs: loss_final: 1.518261, loss_mean: 1.403469, proj_loss: -0.029676, loss_mean_cls: 0.108775, deep_loss: 0.035692, grad_norm: 58.842308
Steps:   0%| | 702/1000000 [13:11<323:45:50,  1.17s/it, deep_loss=0.0344, grad_norm=38.7, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:39:00[39m] Step: 702, Training Logs: loss_final: 1.480301, loss_mean: 1.367211, proj_loss: -0.030033, loss_mean_cls: 0.109257, deep_loss: 0.033866, grad_norm: 43.175911
Steps:   0%| | 704/1000000 [13:14<324:00:33,  1.17s/it, deep_loss=0.0339, grad_norm=61.1, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:39:03[39m] Step: 704, Training Logs: loss_final: 1.516695, loss_mean: 1.403368, proj_loss: -0.030274, loss_mean_cls: 0.109051, deep_loss: 0.034551, grad_norm: 61.710258
Steps:   0%| | 706/1000000 [13:16<323:59:21,  1.17s/it, deep_loss=0.0366, grad_norm=47.8, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:39:05[39m] Step: 706, Training Logs: loss_final: 1.523500, loss_mean: 1.408900, proj_loss: -0.031122, loss_mean_cls: 0.110303, deep_loss: 0.035419, grad_norm: 34.055958
Steps:   0%| | 708/1000000 [13:18<324:21:56,  1.17s/it, deep_loss=0.0365, grad_norm=45.9, loss_final=1.55, loss_mean=1.44, l[[34m2025-10-03 23:39:07[39m] Step: 708, Training Logs: loss_final: 1.537570, loss_mean: 1.423682, proj_loss: -0.032396, loss_mean_cls: 0.109674, deep_loss: 0.036610, grad_norm: 54.522308
Steps:   0%| | 709/1000000 [13:20<324:14:08,  1.17s/it, deep_loss=0.0363, grad_norm=41.4, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:39:07[39m] Step: 708, Training Logs: loss_final: 1.537570, loss_mean: 1.423682, proj_loss: -0.032396, loss_mean_cls: 0.109674, deep_loss: 0.036610, grad_norm: 54.522308
Steps:   0%| | 711/1000000 [13:22<323:46:49,  1.17s/it, deep_loss=0.0358, grad_norm=38.3, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:39:10[39m] Step: 710, Training Logs: loss_final: 1.529105, loss_mean: 1.415248, proj_loss: -0.031533, loss_mean_cls: 0.109561, deep_loss: 0.035829, grad_norm: 36.001236
Steps:   0%| | 713/1000000 [13:24<323:32:36,  1.17s/it, deep_loss=0.0361, grad_norm=33.6, loss_final=1.56, loss_mean=1.44, l[[34m2025-10-03 23:39:12[39m] Step: 712, Training Logs: loss_final: 1.543868, loss_mean: 1.430695, proj_loss: -0.031306, loss_mean_cls: 0.107920, deep_loss: 0.036559, grad_norm: 43.104561
Steps:   0%| | 714/1000000 [13:25<324:01:09,  1.17s/it, deep_loss=0.0361, grad_norm=33.6, loss_final=1.56, loss_mean=1.44, l[[34m2025-10-03 23:39:14[39m] Step: 714, Training Logs: loss_final: 1.535502, loss_mean: 1.421944, proj_loss: -0.030490, loss_mean_cls: 0.108583, deep_loss: 0.035465, grad_norm: 34.794479
Steps:   0%| | 716/1000000 [13:28<324:24:16,  1.17s/it, deep_loss=0.0365, grad_norm=47.6, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:39:17[39m] Step: 716, Training Logs: loss_final: 1.559628, loss_mean: 1.444299, proj_loss: -0.031415, loss_mean_cls: 0.110346, deep_loss: 0.036398, grad_norm: 36.569481
Steps:   0%| | 718/1000000 [13:30<323:16:43,  1.16s/it, deep_loss=0.0353, grad_norm=35.6, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:39:19[39m] Step: 718, Training Logs: loss_final: 1.549510, loss_mean: 1.437813, proj_loss: -0.031718, loss_mean_cls: 0.107895, deep_loss: 0.035520, grad_norm: 49.137375
Steps:   0%| | 720/1000000 [13:32<287:08:38,  1.03s/it, deep_loss=0.0361, grad_norm=52.7, loss_final=1.54, loss_mean=1.42, l[[34m2025-10-03 23:39:21[39m] Step: 720, Training Logs: loss_final: 1.498700, loss_mean: 1.383362, proj_loss: -0.031328, loss_mean_cls: 0.111078, deep_loss: 0.035589, grad_norm: 32.215466
Steps:   0%| | 723/1000000 [13:34<242:11:48,  1.15it/s, deep_loss=0.0362, grad_norm=39.5, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:39:22[39m] Step: 722, Training Logs: loss_final: 1.525931, loss_mean: 1.409081, proj_loss: -0.029527, loss_mean_cls: 0.109888, deep_loss: 0.036490, grad_norm: 52.445160
Steps:   0%| | 725/1000000 [13:36<257:10:41,  1.08it/s, deep_loss=0.0354, grad_norm=39.9, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:39:24[39m] Step: 724, Training Logs: loss_final: 1.496686, loss_mean: 1.383739, proj_loss: -0.031457, loss_mean_cls: 0.108509, deep_loss: 0.035894, grad_norm: 39.508289
Steps:   0%| | 726/1000000 [13:37<277:39:51,  1.00s/it, deep_loss=0.0354, grad_norm=39.9, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:39:26[39m] Step: 726, Training Logs: loss_final: 1.516986, loss_mean: 1.405128, proj_loss: -0.031370, loss_mean_cls: 0.108183, deep_loss: 0.035046, grad_norm: 37.975441
Steps:   0%| | 728/1000000 [13:40<301:00:59,  1.08s/it, deep_loss=0.0359, grad_norm=41.3, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:39:29[39m] Step: 728, Training Logs: loss_final: 1.482038, loss_mean: 1.370760, proj_loss: -0.032111, loss_mean_cls: 0.108562, deep_loss: 0.034827, grad_norm: 41.014011
Steps:   0%| | 730/1000000 [13:42<313:10:01,  1.13s/it, deep_loss=0.0354, grad_norm=38, loss_final=1.51, loss_mean=1.39, los[[34m2025-10-03 23:39:31[39m] Step: 730, Training Logs: loss_final: 1.510333, loss_mean: 1.397223, proj_loss: -0.030562, loss_mean_cls: 0.109030, deep_loss: 0.034642, grad_norm: 43.875229
Steps:   0%| | 732/1000000 [13:44<319:24:47,  1.15s/it, deep_loss=0.0348, grad_norm=40.7, loss_final=1.52, loss_mean=1.4, lo[[34m2025-10-03 23:39:33[39m] Step: 732, Training Logs: loss_final: 1.490256, loss_mean: 1.380024, proj_loss: -0.032713, loss_mean_cls: 0.108294, deep_loss: 0.034650, grad_norm: 31.311611
Steps:   0%| | 733/1000000 [13:46<322:23:16,  1.16s/it, deep_loss=0.034, grad_norm=44.9, loss_final=1.5, loss_mean=1.39, los[[34m2025-10-03 23:39:33[39m] Step: 732, Training Logs: loss_final: 1.490256, loss_mean: 1.380024, proj_loss: -0.032713, loss_mean_cls: 0.108294, deep_loss: 0.034650, grad_norm: 31.311611
Steps:   0%| | 735/1000000 [13:48<322:50:16,  1.16s/it, deep_loss=0.0331, grad_norm=41, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:39:36[39m] Step: 734, Training Logs: loss_final: 1.505378, loss_mean: 1.394791, proj_loss: -0.030479, loss_mean_cls: 0.107723, deep_loss: 0.033343, grad_norm: 48.009033
Steps:   0%| | 737/1000000 [13:50<324:21:07,  1.17s/it, deep_loss=0.0326, grad_norm=43.5, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:39:38[39m] Step: 736, Training Logs: loss_final: 1.505569, loss_mean: 1.394737, proj_loss: -0.031152, loss_mean_cls: 0.108769, deep_loss: 0.033215, grad_norm: 36.540367
Steps:   0%| | 738/1000000 [13:51<324:58:40,  1.17s/it, deep_loss=0.0326, grad_norm=43.5, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:39:40[39m] Step: 738, Training Logs: loss_final: 1.544283, loss_mean: 1.433404, proj_loss: -0.030390, loss_mean_cls: 0.107063, deep_loss: 0.034207, grad_norm: 40.441605
Steps:   0%| | 740/1000000 [13:54<324:02:50,  1.17s/it, deep_loss=0.0342, grad_norm=34.2, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:39:43[39m] Step: 740, Training Logs: loss_final: 1.511527, loss_mean: 1.401663, proj_loss: -0.031548, loss_mean_cls: 0.107562, deep_loss: 0.033850, grad_norm: 38.322372
Steps:   0%| | 742/1000000 [13:56<324:39:28,  1.17s/it, deep_loss=0.0341, grad_norm=42.4, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:39:45[39m] Step: 742, Training Logs: loss_final: 1.501058, loss_mean: 1.390061, proj_loss: -0.029895, loss_mean_cls: 0.108126, deep_loss: 0.032766, grad_norm: 33.644348
Steps:   0%| | 744/1000000 [13:58<324:52:51,  1.17s/it, deep_loss=0.0338, grad_norm=41.8, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:39:47[39m] Step: 744, Training Logs: loss_final: 1.513092, loss_mean: 1.402007, proj_loss: -0.030242, loss_mean_cls: 0.108289, deep_loss: 0.033039, grad_norm: 48.698830
Steps:   0%| | 745/1000000 [14:00<324:44:55,  1.17s/it, deep_loss=0.0342, grad_norm=42.9, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:39:47[39m] Step: 744, Training Logs: loss_final: 1.513092, loss_mean: 1.402007, proj_loss: -0.030242, loss_mean_cls: 0.108289, deep_loss: 0.033039, grad_norm: 48.698830
Steps:   0%| | 747/1000000 [14:02<325:12:44,  1.17s/it, deep_loss=0.0333, grad_norm=48.1, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:39:50[39m] Step: 746, Training Logs: loss_final: 1.522626, loss_mean: 1.411531, proj_loss: -0.031072, loss_mean_cls: 0.107784, deep_loss: 0.034383, grad_norm: 41.504425
Steps:   0%| | 749/1000000 [14:04<324:39:30,  1.17s/it, deep_loss=0.0338, grad_norm=44.4, loss_final=1.51, loss_mean=1.41, l[[34m2025-10-03 23:39:52[39m] Step: 748, Training Logs: loss_final: 1.515054, loss_mean: 1.404268, proj_loss: -0.031170, loss_mean_cls: 0.108296, deep_loss: 0.033660, grad_norm: 43.484077
Steps:   0%| | 750/1000000 [14:05<324:19:31,  1.17s/it, deep_loss=0.0338, grad_norm=44.4, loss_final=1.51, loss_mean=1.41, l[[34m2025-10-03 23:39:54[39m] Step: 750, Training Logs: loss_final: 1.539447, loss_mean: 1.429473, proj_loss: -0.031521, loss_mean_cls: 0.107997, deep_loss: 0.033498, grad_norm: 51.465286
Steps:   0%| | 753/1000000 [14:08<285:20:32,  1.03s/it, deep_loss=0.0331, grad_norm=53.3, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:39:57[39m] Step: 752, Training Logs: loss_final: 1.503957, loss_mean: 1.393791, proj_loss: -0.032092, loss_mean_cls: 0.108758, deep_loss: 0.033500, grad_norm: 39.516411
Steps:   0%| | 755/1000000 [14:10<251:36:13,  1.10it/s, deep_loss=0.0329, grad_norm=40, loss_final=1.52, loss_mean=1.41, los[[34m2025-10-03 23:39:58[39m] Step: 754, Training Logs: loss_final: 1.532123, loss_mean: 1.420875, proj_loss: -0.031257, loss_mean_cls: 0.108299, deep_loss: 0.034206, grad_norm: 50.690590
Steps:   0%| | 757/1000000 [14:12<269:32:08,  1.03it/s, deep_loss=0.0349, grad_norm=51.6, loss_final=1.55, loss_mean=1.44, l[[34m2025-10-03 23:40:00[39m] Step: 756, Training Logs: loss_final: 1.527426, loss_mean: 1.414331, proj_loss: -0.030314, loss_mean_cls: 0.108475, deep_loss: 0.034934, grad_norm: 48.797241
Steps:   0%| | 759/1000000 [14:14<297:18:49,  1.07s/it, deep_loss=0.0334, grad_norm=46.9, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:40:02[39m] Step: 758, Training Logs: loss_final: 1.511519, loss_mean: 1.402038, proj_loss: -0.032353, loss_mean_cls: 0.108094, deep_loss: 0.033740, grad_norm: 44.313271
Steps:   0%| | 760/1000000 [14:15<304:56:22,  1.10s/it, deep_loss=0.0334, grad_norm=46.9, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:40:05[39m] Step: 760, Training Logs: loss_final: 1.510534, loss_mean: 1.400391, proj_loss: -0.031806, loss_mean_cls: 0.108248, deep_loss: 0.033701, grad_norm: 51.196972
Steps:   0%| | 762/1000000 [14:18<314:42:40,  1.13s/it, deep_loss=0.0335, grad_norm=50.1, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:40:07[39m] Step: 762, Training Logs: loss_final: 1.515630, loss_mean: 1.405233, proj_loss: -0.031057, loss_mean_cls: 0.108111, deep_loss: 0.033343, grad_norm: 52.006523
Steps:   0%| | 764/1000000 [14:20<319:41:43,  1.15s/it, deep_loss=0.0332, grad_norm=50, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:40:09[39m] Step: 764, Training Logs: loss_final: 1.500252, loss_mean: 1.388367, proj_loss: -0.030190, loss_mean_cls: 0.109084, deep_loss: 0.032990, grad_norm: 46.710110
Steps:   0%| | 766/1000000 [14:22<322:16:23,  1.16s/it, deep_loss=0.0338, grad_norm=52.3, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:40:12[39m] Step: 766, Training Logs: loss_final: 1.489701, loss_mean: 1.379417, proj_loss: -0.031066, loss_mean_cls: 0.108967, deep_loss: 0.032382, grad_norm: 49.306805
Steps:   0%| | 767/1000000 [14:24<322:13:39,  1.16s/it, deep_loss=0.0332, grad_norm=45.9, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:40:12[39m] Step: 766, Training Logs: loss_final: 1.489701, loss_mean: 1.379417, proj_loss: -0.031066, loss_mean_cls: 0.108967, deep_loss: 0.032382, grad_norm: 49.306805
Steps:   0%| | 769/1000000 [14:26<324:22:59,  1.17s/it, deep_loss=0.0323, grad_norm=39.8, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:40:14[39m] Step: 768, Training Logs: loss_final: 1.491456, loss_mean: 1.381194, proj_loss: -0.031772, loss_mean_cls: 0.109239, deep_loss: 0.032795, grad_norm: 52.263847
Steps:   0%| | 771/1000000 [14:28<324:32:09,  1.17s/it, deep_loss=0.0321, grad_norm=53.4, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:40:16[39m] Step: 770, Training Logs: loss_final: 1.491153, loss_mean: 1.381399, proj_loss: -0.030888, loss_mean_cls: 0.106994, deep_loss: 0.033647, grad_norm: 39.350731
Steps:   0%| | 772/1000000 [14:30<324:45:57,  1.17s/it, deep_loss=0.0321, grad_norm=53.4, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:40:19[39m] Step: 772, Training Logs: loss_final: 1.495046, loss_mean: 1.386863, proj_loss: -0.032892, loss_mean_cls: 0.108202, deep_loss: 0.032873, grad_norm: 37.630077
Steps:   0%| | 774/1000000 [14:32<324:00:36,  1.17s/it, deep_loss=0.032, grad_norm=43.4, loss_final=1.49, loss_mean=1.38, lo[[34m2025-10-03 23:40:21[39m] Step: 774, Training Logs: loss_final: 1.506782, loss_mean: 1.394958, proj_loss: -0.029874, loss_mean_cls: 0.108352, deep_loss: 0.033347, grad_norm: 59.624355
Steps:   0%| | 776/1000000 [14:34<324:04:23,  1.17s/it, deep_loss=0.0335, grad_norm=53.3, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:40:23[39m] Step: 776, Training Logs: loss_final: 1.503273, loss_mean: 1.393889, proj_loss: -0.030065, loss_mean_cls: 0.106976, deep_loss: 0.032473, grad_norm: 39.459526
Steps:   0%| | 778/1000000 [14:37<324:46:57,  1.17s/it, deep_loss=0.0327, grad_norm=50.9, loss_final=1.49, loss_mean=1.39, l[[34m2025-10-03 23:40:26[39m] Step: 778, Training Logs: loss_final: 1.519533, loss_mean: 1.412671, proj_loss: -0.033186, loss_mean_cls: 0.106876, deep_loss: 0.033172, grad_norm: 55.376602
Steps:   0%| | 779/1000000 [14:38<325:46:47,  1.17s/it, deep_loss=0.032, grad_norm=48.9, loss_final=1.47, loss_mean=1.36, lo[[34m2025-10-03 23:40:26[39m] Step: 778, Training Logs: loss_final: 1.519533, loss_mean: 1.412671, proj_loss: -0.033186, loss_mean_cls: 0.106876, deep_loss: 0.033172, grad_norm: 55.376602
Steps:   0%| | 781/1000000 [14:40<325:18:43,  1.17s/it, deep_loss=0.0329, grad_norm=54.8, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:40:28[39m] Step: 780, Training Logs: loss_final: 1.497645, loss_mean: 1.387553, proj_loss: -0.030505, loss_mean_cls: 0.108061, deep_loss: 0.032537, grad_norm: 49.386333
Steps:   0%| | 783/1000000 [14:42<324:35:31,  1.17s/it, deep_loss=0.0325, grad_norm=51.6, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:40:30[39m] Step: 782, Training Logs: loss_final: 1.470441, loss_mean: 1.361370, proj_loss: -0.031242, loss_mean_cls: 0.108718, deep_loss: 0.031595, grad_norm: 47.819851
Steps:   0%| | 785/1000000 [14:44<280:21:45,  1.01s/it, deep_loss=0.0327, grad_norm=51.1, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:40:32[39m] Step: 784, Training Logs: loss_final: 1.504123, loss_mean: 1.394662, proj_loss: -0.030517, loss_mean_cls: 0.107805, deep_loss: 0.032173, grad_norm: 59.328899
Steps:   0%| | 788/1000000 [14:47<257:52:58,  1.08it/s, deep_loss=0.0328, grad_norm=56.5, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:40:34[39m] Step: 786, Training Logs: loss_final: 1.480327, loss_mean: 1.369736, proj_loss: -0.030545, loss_mean_cls: 0.108987, deep_loss: 0.032150, grad_norm: 47.385380
Steps:   0%| | 789/1000000 [14:48<277:42:48,  1.00s/it, deep_loss=0.0331, grad_norm=51.8, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:40:36[39m] Step: 788, Training Logs: loss_final: 1.496064, loss_mean: 1.386455, proj_loss: -0.031023, loss_mean_cls: 0.107907, deep_loss: 0.032725, grad_norm: 55.112808
Steps:   0%| | 791/1000000 [14:50<302:41:01,  1.09s/it, deep_loss=0.033, grad_norm=51.1, loss_final=1.5, loss_mean=1.39, los[[34m2025-10-03 23:40:38[39m] Step: 790, Training Logs: loss_final: 1.508934, loss_mean: 1.399253, proj_loss: -0.030079, loss_mean_cls: 0.106504, deep_loss: 0.033256, grad_norm: 54.518051
Steps:   0%| | 793/1000000 [14:53<313:08:48,  1.13s/it, deep_loss=0.0333, grad_norm=58, loss_final=1.52, loss_mean=1.41, los[[34m2025-10-03 23:40:40[39m] Step: 792, Training Logs: loss_final: 1.496124, loss_mean: 1.389035, proj_loss: -0.033559, loss_mean_cls: 0.108162, deep_loss: 0.032486, grad_norm: 58.826664
Steps:   0%| | 794/1000000 [14:54<316:27:11,  1.14s/it, deep_loss=0.0333, grad_norm=58, loss_final=1.52, loss_mean=1.41, los[[34m2025-10-03 23:40:43[39m] Step: 794, Training Logs: loss_final: 1.509866, loss_mean: 1.398950, proj_loss: -0.030205, loss_mean_cls: 0.108053, deep_loss: 0.033069, grad_norm: 49.331146
Steps:   0%| | 796/1000000 [14:56<320:56:05,  1.16s/it, deep_loss=0.0318, grad_norm=59.6, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:40:45[39m] Step: 796, Training Logs: loss_final: 1.534136, loss_mean: 1.425760, proj_loss: -0.032172, loss_mean_cls: 0.107679, deep_loss: 0.032869, grad_norm: 62.718609
Steps:   0%| | 798/1000000 [14:58<323:12:32,  1.16s/it, deep_loss=0.0326, grad_norm=57.1, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:40:47[39m] Step: 798, Training Logs: loss_final: 1.519967, loss_mean: 1.411953, proj_loss: -0.032360, loss_mean_cls: 0.107527, deep_loss: 0.032847, grad_norm: 50.168076
Steps:   0%| | 800/1000000 [15:01<324:51:15,  1.17s/it, deep_loss=0.0328, grad_norm=55.1, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:40:47[39m] Step: 798, Training Logs: loss_final: 1.519967, loss_mean: 1.411953, proj_loss: -0.032360, loss_mean_cls: 0.107527, deep_loss: 0.032847, grad_norm: 50.168076
Steps:   0%| | 801/1000000 [15:02<324:58:59,  1.17s/it, deep_loss=0.033, grad_norm=45.3, loss_final=1.52, loss_mean=1.41, lo[[34m2025-10-03 23:40:50[39m] Step: 800, Training Logs: loss_final: 1.516014, loss_mean: 1.406003, proj_loss: -0.030984, loss_mean_cls: 0.108815, deep_loss: 0.032180, grad_norm: 60.940617
Steps:   0%| | 803/1000000 [15:04<325:11:10,  1.17s/it, deep_loss=0.0329, grad_norm=58.5, loss_final=1.51, loss_mean=1.41, l[[34m2025-10-03 23:40:52[39m] Step: 802, Training Logs: loss_final: 1.512557, loss_mean: 1.404919, proj_loss: -0.031288, loss_mean_cls: 0.106587, deep_loss: 0.032338, grad_norm: 45.287769
Steps:   0%| | 805/1000000 [15:07<324:51:25,  1.17s/it, deep_loss=0.032, grad_norm=34.5, loss_final=1.47, loss_mean=1.36, lo[[34m2025-10-03 23:40:55[39m] Step: 804, Training Logs: loss_final: 1.495239, loss_mean: 1.387083, proj_loss: -0.030819, loss_mean_cls: 0.106836, deep_loss: 0.032138, grad_norm: 48.004116
Steps:   0%| | 806/1000000 [15:08<323:47:35,  1.17s/it, deep_loss=0.032, grad_norm=34.5, loss_final=1.47, loss_mean=1.36, lo[[34m2025-10-03 23:40:57[39m] Step: 806, Training Logs: loss_final: 1.500451, loss_mean: 1.392741, proj_loss: -0.032106, loss_mean_cls: 0.106982, deep_loss: 0.032835, grad_norm: 47.203484
Steps:   0%| | 808/1000000 [15:10<323:16:59,  1.16s/it, deep_loss=0.0331, grad_norm=39.5, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:40:59[39m] Step: 808, Training Logs: loss_final: 1.477091, loss_mean: 1.369121, proj_loss: -0.031564, loss_mean_cls: 0.106490, deep_loss: 0.033044, grad_norm: 33.978180
Steps:   0%| | 810/1000000 [15:12<324:34:46,  1.17s/it, deep_loss=0.0321, grad_norm=37.5, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:41:02[39m] Step: 810, Training Logs: loss_final: 1.480862, loss_mean: 1.373158, proj_loss: -0.032401, loss_mean_cls: 0.106698, deep_loss: 0.033407, grad_norm: 37.994892
Steps:   0%| | 812/1000000 [15:15<324:01:30,  1.17s/it, deep_loss=0.0324, grad_norm=33.1, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:41:02[39m] Step: 810, Training Logs: loss_final: 1.480862, loss_mean: 1.373158, proj_loss: -0.032401, loss_mean_cls: 0.106698, deep_loss: 0.033407, grad_norm: 37.994892
Steps:   0%| | 813/1000000 [15:16<324:03:39,  1.17s/it, deep_loss=0.0325, grad_norm=34.3, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:41:04[39m] Step: 812, Training Logs: loss_final: 1.483683, loss_mean: 1.372524, proj_loss: -0.030098, loss_mean_cls: 0.107419, deep_loss: 0.033837, grad_norm: 30.276711
Steps:   0%| | 815/1000000 [15:18<323:51:17,  1.17s/it, deep_loss=0.0337, grad_norm=23, loss_final=1.49, loss_mean=1.38, los[[34m2025-10-03 23:41:06[39m] Step: 814, Training Logs: loss_final: 1.470643, loss_mean: 1.361322, proj_loss: -0.030695, loss_mean_cls: 0.108116, deep_loss: 0.031900, grad_norm: 33.787403
Steps:   0%| | 818/1000000 [15:21<254:20:48,  1.09it/s, deep_loss=0.0352, grad_norm=45.3, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-03 23:41:10[39m] Step: 818, Training Logs: loss_final: 1.501584, loss_mean: 1.389303, proj_loss: -0.032163, loss_mean_cls: 0.108312, deep_loss: 0.036133, grad_norm: 35.680042
Steps:   0%| | 820/1000000 [15:23<261:34:34,  1.06it/s, deep_loss=0.035, grad_norm=45.3, loss_final=1.51, loss_mean=1.39, lo[[34m2025-10-03 23:41:12[39m] Step: 820, Training Logs: loss_final: 1.508937, loss_mean: 1.397150, proj_loss: -0.031240, loss_mean_cls: 0.108456, deep_loss: 0.034572, grad_norm: 43.913376
Steps:   0%| | 821/1000000 [15:24<279:48:25,  1.01s/it, deep_loss=0.0359, grad_norm=49.3, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:41:12[39m] Step: 820, Training Logs: loss_final: 1.508937, loss_mean: 1.397150, proj_loss: -0.031240, loss_mean_cls: 0.108456, deep_loss: 0.034572, grad_norm: 43.913376
Steps:   0%| | 823/1000000 [15:26<302:48:53,  1.09s/it, deep_loss=0.0347, grad_norm=44.6, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:41:14[39m] Step: 822, Training Logs: loss_final: 1.511733, loss_mean: 1.395778, proj_loss: -0.031014, loss_mean_cls: 0.110264, deep_loss: 0.036704, grad_norm: 44.582829
Steps:   0%| | 825/1000000 [15:28<313:28:43,  1.13s/it, deep_loss=0.0382, grad_norm=38.9, loss_final=1.5, loss_mean=1.38, lo[[34m2025-10-03 23:41:16[39m] Step: 824, Training Logs: loss_final: 1.525566, loss_mean: 1.413638, proj_loss: -0.032707, loss_mean_cls: 0.108939, deep_loss: 0.035696, grad_norm: 53.938046
Steps:   0%| | 827/1000000 [15:31<319:17:26,  1.15s/it, deep_loss=0.036, grad_norm=54, loss_final=1.5, loss_mean=1.39, loss_[[34m2025-10-03 23:41:19[39m] Step: 826, Training Logs: loss_final: 1.511801, loss_mean: 1.398458, proj_loss: -0.032363, loss_mean_cls: 0.108836, deep_loss: 0.036870, grad_norm: 40.280964
Steps:   0%| | 828/1000000 [15:32<320:35:44,  1.16s/it, deep_loss=0.036, grad_norm=54, loss_final=1.5, loss_mean=1.39, loss_[[34m2025-10-03 23:41:21[39m] Step: 828, Training Logs: loss_final: 1.502646, loss_mean: 1.384996, proj_loss: -0.029952, loss_mean_cls: 0.109949, deep_loss: 0.037654, grad_norm: 40.204777
Steps:   0%| | 830/1000000 [15:34<322:19:13,  1.16s/it, deep_loss=0.0362, grad_norm=38.8, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:41:23[39m] Step: 830, Training Logs: loss_final: 1.508566, loss_mean: 1.396010, proj_loss: -0.030213, loss_mean_cls: 0.107339, deep_loss: 0.035429, grad_norm: 48.550995
Steps:   0%| | 832/1000000 [15:37<324:29:08,  1.17s/it, deep_loss=0.037, grad_norm=38.9, loss_final=1.5, loss_mean=1.38, los[[34m2025-10-03 23:41:26[39m] Step: 832, Training Logs: loss_final: 1.465077, loss_mean: 1.353137, proj_loss: -0.032250, loss_mean_cls: 0.108849, deep_loss: 0.035340, grad_norm: 36.674137
Steps:   0%| | 833/1000000 [15:38<325:05:58,  1.17s/it, deep_loss=0.0347, grad_norm=43, loss_final=1.48, loss_mean=1.37, los[[34m2025-10-03 23:41:26[39m] Step: 832, Training Logs: loss_final: 1.465077, loss_mean: 1.353137, proj_loss: -0.032250, loss_mean_cls: 0.108849, deep_loss: 0.035340, grad_norm: 36.674137
Steps:   0%| | 835/1000000 [15:40<326:00:13,  1.17s/it, deep_loss=0.0325, grad_norm=44, loss_final=1.46, loss_mean=1.34, los[[34m2025-10-03 23:41:28[39m] Step: 834, Training Logs: loss_final: 1.492580, loss_mean: 1.377826, proj_loss: -0.030018, loss_mean_cls: 0.109559, deep_loss: 0.035212, grad_norm: 37.495914
Steps:   0%| | 837/1000000 [15:42<325:35:51,  1.17s/it, deep_loss=0.0352, grad_norm=41.7, loss_final=1.49, loss_mean=1.37, l[[34m2025-10-03 23:41:30[39m] Step: 836, Training Logs: loss_final: 1.504104, loss_mean: 1.391354, proj_loss: -0.030997, loss_mean_cls: 0.108408, deep_loss: 0.035339, grad_norm: 39.299934
Steps:   0%| | 839/1000000 [15:45<325:30:16,  1.17s/it, deep_loss=0.0341, grad_norm=41.4, loss_final=1.49, loss_mean=1.37, l[[34m2025-10-03 23:41:33[39m] Step: 838, Training Logs: loss_final: 1.487578, loss_mean: 1.376486, proj_loss: -0.030102, loss_mean_cls: 0.107574, deep_loss: 0.033620, grad_norm: 40.204845
Steps:   0%| | 840/1000000 [15:46<324:38:42,  1.17s/it, deep_loss=0.0341, grad_norm=41.4, loss_final=1.49, loss_mean=1.37, l[[34m2025-10-03 23:41:35[39m] Step: 840, Training Logs: loss_final: 1.457431, loss_mean: 1.343585, proj_loss: -0.028985, loss_mean_cls: 0.108970, deep_loss: 0.033862, grad_norm: 39.582039
Steps:   0%| | 842/1000000 [15:48<324:23:43,  1.17s/it, deep_loss=0.0336, grad_norm=44.8, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:41:37[39m] Step: 842, Training Logs: loss_final: 1.507919, loss_mean: 1.395788, proj_loss: -0.029486, loss_mean_cls: 0.107507, deep_loss: 0.034110, grad_norm: 33.499603
Steps:   0%| | 844/1000000 [15:51<324:42:35,  1.17s/it, deep_loss=0.034, grad_norm=42.3, loss_final=1.5, loss_mean=1.39, los[[34m2025-10-03 23:41:40[39m] Step: 844, Training Logs: loss_final: 1.470940, loss_mean: 1.358683, proj_loss: -0.029531, loss_mean_cls: 0.108562, deep_loss: 0.033226, grad_norm: 40.751442
Steps:   0%| | 845/1000000 [15:52<325:13:46,  1.17s/it, deep_loss=0.0333, grad_norm=41.1, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:41:40[39m] Step: 844, Training Logs: loss_final: 1.470940, loss_mean: 1.358683, proj_loss: -0.029531, loss_mean_cls: 0.108562, deep_loss: 0.033226, grad_norm: 40.751442
Steps:   0%| | 848/1000000 [15:55<286:49:12,  1.03s/it, deep_loss=0.034, grad_norm=48.6, loss_final=1.48, loss_mean=1.37, lo[[34m2025-10-03 23:41:44[39m] Step: 848, Training Logs: loss_final: 1.473153, loss_mean: 1.360379, proj_loss: -0.029670, loss_mean_cls: 0.109688, deep_loss: 0.032756, grad_norm: 41.934544
Steps:   0%| | 850/1000000 [15:56<252:42:46,  1.10it/s, deep_loss=0.0329, grad_norm=40.5, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:41:45[39m] Step: 850, Training Logs: loss_final: 1.478874, loss_mean: 1.367800, proj_loss: -0.030564, loss_mean_cls: 0.107651, deep_loss: 0.033986, grad_norm: 41.102932
Steps:   0%| | 852/1000000 [15:58<263:28:02,  1.05it/s, deep_loss=0.0328, grad_norm=42.5, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:41:47[39m] Step: 852, Training Logs: loss_final: 1.498704, loss_mean: 1.387135, proj_loss: -0.030418, loss_mean_cls: 0.108924, deep_loss: 0.033063, grad_norm: 51.347225
Steps:   0%| | 854/1000000 [16:01<295:09:41,  1.06s/it, deep_loss=0.0337, grad_norm=37, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:41:50[39m] Step: 854, Training Logs: loss_final: 1.514097, loss_mean: 1.403890, proj_loss: -0.031559, loss_mean_cls: 0.107708, deep_loss: 0.034059, grad_norm: 38.285629
Steps:   0%| | 855/1000000 [16:02<305:08:16,  1.10s/it, deep_loss=0.0333, grad_norm=45.1, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:41:50[39m] Step: 854, Training Logs: loss_final: 1.514097, loss_mean: 1.403890, proj_loss: -0.031559, loss_mean_cls: 0.107708, deep_loss: 0.034059, grad_norm: 38.285629
Steps:   0%| | 857/1000000 [16:04<316:15:21,  1.14s/it, deep_loss=0.0332, grad_norm=44.6, loss_final=1.5, loss_mean=1.4, los[[34m2025-10-03 23:41:52[39m] Step: 856, Training Logs: loss_final: 1.508334, loss_mean: 1.395308, proj_loss: -0.030602, loss_mean_cls: 0.109530, deep_loss: 0.034099, grad_norm: 29.816502
Steps:   0%| | 859/1000000 [16:07<320:34:13,  1.16s/it, deep_loss=0.0341, grad_norm=31.1, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:41:54[39m] Step: 858, Training Logs: loss_final: 1.502321, loss_mean: 1.389352, proj_loss: -0.030824, loss_mean_cls: 0.108861, deep_loss: 0.034933, grad_norm: 48.827904
Steps:   0%| | 861/1000000 [16:09<321:52:26,  1.16s/it, deep_loss=0.0361, grad_norm=56, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:41:57[39m] Step: 860, Training Logs: loss_final: 1.519318, loss_mean: 1.407391, proj_loss: -0.030660, loss_mean_cls: 0.108329, deep_loss: 0.034258, grad_norm: 46.441147
Steps:   0%| | 862/1000000 [16:10<322:06:27,  1.16s/it, deep_loss=0.0361, grad_norm=56, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:41:59[39m] Step: 862, Training Logs: loss_final: 1.507562, loss_mean: 1.391707, proj_loss: -0.030534, loss_mean_cls: 0.109253, deep_loss: 0.037136, grad_norm: 41.353497
Steps:   0%| | 864/1000000 [16:12<323:02:52,  1.16s/it, deep_loss=0.0362, grad_norm=45.7, loss_final=1.51, loss_mean=1.39, l[[34m2025-10-03 23:42:01[39m] Step: 864, Training Logs: loss_final: 1.521585, loss_mean: 1.409209, proj_loss: -0.030868, loss_mean_cls: 0.108559, deep_loss: 0.034685, grad_norm: 51.301922
Steps:   0%| | 866/1000000 [16:15<323:36:41,  1.17s/it, deep_loss=0.0355, grad_norm=41.7, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:42:04[39m] Step: 866, Training Logs: loss_final: 1.508116, loss_mean: 1.396243, proj_loss: -0.031934, loss_mean_cls: 0.109249, deep_loss: 0.034557, grad_norm: 49.035885
Steps:   0%| | 867/1000000 [16:16<323:58:36,  1.17s/it, deep_loss=0.0338, grad_norm=62.4, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:42:04[39m] Step: 866, Training Logs: loss_final: 1.508116, loss_mean: 1.396243, proj_loss: -0.031934, loss_mean_cls: 0.109249, deep_loss: 0.034557, grad_norm: 49.035885
Steps:   0%| | 869/1000000 [16:18<323:12:40,  1.16s/it, deep_loss=0.0344, grad_norm=41.7, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:42:06[39m] Step: 868, Training Logs: loss_final: 1.516033, loss_mean: 1.404185, proj_loss: -0.032396, loss_mean_cls: 0.108924, deep_loss: 0.035320, grad_norm: 52.419266
Steps:   0%| | 871/1000000 [16:21<323:49:54,  1.17s/it, deep_loss=0.0339, grad_norm=54.3, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:42:08[39m] Step: 870, Training Logs: loss_final: 1.544642, loss_mean: 1.433030, proj_loss: -0.029898, loss_mean_cls: 0.107632, deep_loss: 0.033878, grad_norm: 50.373913
Steps:   0%| | 873/1000000 [16:23<323:19:38,  1.16s/it, deep_loss=0.0328, grad_norm=38.9, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:42:11[39m] Step: 872, Training Logs: loss_final: 1.516083, loss_mean: 1.405292, proj_loss: -0.032329, loss_mean_cls: 0.109117, deep_loss: 0.034003, grad_norm: 48.741707
Steps:   0%| | 874/1000000 [16:24<323:28:06,  1.17s/it, deep_loss=0.0328, grad_norm=38.9, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:42:13[39m] Step: 874, Training Logs: loss_final: 1.510537, loss_mean: 1.398037, proj_loss: -0.030000, loss_mean_cls: 0.108570, deep_loss: 0.033929, grad_norm: 45.806671
Steps:   0%| | 876/1000000 [16:26<324:32:17,  1.17s/it, deep_loss=0.033, grad_norm=57.5, loss_final=1.51, loss_mean=1.4, los[[34m2025-10-03 23:42:15[39m] Step: 876, Training Logs: loss_final: 1.495700, loss_mean: 1.387545, proj_loss: -0.033196, loss_mean_cls: 0.108132, deep_loss: 0.033218, grad_norm: 41.938713
Steps:   0%| | 878/1000000 [16:29<324:03:05,  1.17s/it, deep_loss=0.0329, grad_norm=33.9, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:42:18[39m] Step: 878, Training Logs: loss_final: 1.501455, loss_mean: 1.391330, proj_loss: -0.030905, loss_mean_cls: 0.108289, deep_loss: 0.032740, grad_norm: 57.223549
Steps:   0%| | 880/1000000 [16:31<286:32:51,  1.03s/it, deep_loss=0.0345, grad_norm=49.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:20[39m] Step: 880, Training Logs: loss_final: 1.510189, loss_mean: 1.400174, proj_loss: -0.030688, loss_mean_cls: 0.107095, deep_loss: 0.033608, grad_norm: 29.580177
Steps:   0%| | 883/1000000 [16:33<246:28:59,  1.13it/s, deep_loss=0.0323, grad_norm=33.9, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:42:21[39m] Step: 882, Training Logs: loss_final: 1.470454, loss_mean: 1.356980, proj_loss: -0.030842, loss_mean_cls: 0.109831, deep_loss: 0.034485, grad_norm: 38.883038
Steps:   0%| | 884/1000000 [16:34<269:44:15,  1.03it/s, deep_loss=0.0323, grad_norm=33.9, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:42:23[39m] Step: 884, Training Logs: loss_final: 1.477400, loss_mean: 1.367337, proj_loss: -0.031971, loss_mean_cls: 0.108293, deep_loss: 0.033742, grad_norm: 45.238743
Steps:   0%| | 886/1000000 [16:36<297:38:00,  1.07s/it, deep_loss=0.0348, grad_norm=37.1, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:42:26[39m] Step: 886, Training Logs: loss_final: 1.465007, loss_mean: 1.355003, proj_loss: -0.030550, loss_mean_cls: 0.108444, deep_loss: 0.032109, grad_norm: 34.562035
Steps:   0%| | 888/1000000 [16:39<311:19:32,  1.12s/it, deep_loss=0.0334, grad_norm=45.1, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:42:28[39m] Step: 888, Training Logs: loss_final: 1.492478, loss_mean: 1.383482, proj_loss: -0.032777, loss_mean_cls: 0.107700, deep_loss: 0.034073, grad_norm: 47.552742
Steps:   0%| | 889/1000000 [16:40<315:23:38,  1.14s/it, deep_loss=0.034, grad_norm=28.8, loss_final=1.46, loss_mean=1.35, lo[[34m2025-10-03 23:42:28[39m] Step: 888, Training Logs: loss_final: 1.492478, loss_mean: 1.383482, proj_loss: -0.032777, loss_mean_cls: 0.107700, deep_loss: 0.034073, grad_norm: 47.552742
Steps:   0%| | 891/1000000 [16:42<320:43:33,  1.16s/it, deep_loss=0.0341, grad_norm=58.3, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:30[39m] Step: 890, Training Logs: loss_final: 1.467808, loss_mean: 1.357258, proj_loss: -0.030345, loss_mean_cls: 0.108348, deep_loss: 0.032547, grad_norm: 46.545330
Steps:   0%| | 893/1000000 [16:45<322:47:19,  1.16s/it, deep_loss=0.0328, grad_norm=38.5, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:42:33[39m] Step: 892, Training Logs: loss_final: 1.501223, loss_mean: 1.389077, proj_loss: -0.030195, loss_mean_cls: 0.107930, deep_loss: 0.034410, grad_norm: 38.202248
Steps:   0%| | 895/1000000 [16:47<324:03:44,  1.17s/it, deep_loss=0.0348, grad_norm=46.4, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:35[39m] Step: 894, Training Logs: loss_final: 1.489945, loss_mean: 1.377774, proj_loss: -0.029212, loss_mean_cls: 0.108311, deep_loss: 0.033071, grad_norm: 62.353966
Steps:   0%| | 896/1000000 [16:48<325:36:59,  1.17s/it, deep_loss=0.0348, grad_norm=46.4, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:37[39m] Step: 896, Training Logs: loss_final: 1.457726, loss_mean: 1.348026, proj_loss: -0.032062, loss_mean_cls: 0.108665, deep_loss: 0.033097, grad_norm: 25.727423
Steps:   0%| | 898/1000000 [16:51<325:39:29,  1.17s/it, deep_loss=0.0342, grad_norm=47.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:40[39m] Step: 898, Training Logs: loss_final: 1.481436, loss_mean: 1.368685, proj_loss: -0.032104, loss_mean_cls: 0.109678, deep_loss: 0.035177, grad_norm: 47.944939
Steps:   0%| | 900/1000000 [16:53<326:04:19,  1.17s/it, deep_loss=0.0344, grad_norm=36.8, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:42:42[39m] Step: 900, Training Logs: loss_final: 1.492863, loss_mean: 1.384234, proj_loss: -0.031883, loss_mean_cls: 0.107724, deep_loss: 0.032788, grad_norm: 45.308075
Steps:   0%| | 901/1000000 [16:54<325:55:23,  1.17s/it, deep_loss=0.0341, grad_norm=45.4, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:42:42[39m] Step: 900, Training Logs: loss_final: 1.492863, loss_mean: 1.384234, proj_loss: -0.031883, loss_mean_cls: 0.107724, deep_loss: 0.032788, grad_norm: 45.308075
Steps:   0%| | 903/1000000 [16:56<325:33:04,  1.17s/it, deep_loss=0.034, grad_norm=45.5, loss_final=1.51, loss_mean=1.4, los[[34m2025-10-03 23:42:44[39m] Step: 902, Training Logs: loss_final: 1.499237, loss_mean: 1.390018, proj_loss: -0.033376, loss_mean_cls: 0.107916, deep_loss: 0.034680, grad_norm: 44.227192
Steps:   0%| | 905/1000000 [16:59<324:00:54,  1.17s/it, deep_loss=0.0338, grad_norm=43.7, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:42:47[39m] Step: 904, Training Logs: loss_final: 1.483757, loss_mean: 1.372486, proj_loss: -0.030853, loss_mean_cls: 0.108966, deep_loss: 0.033158, grad_norm: 34.993969
Steps:   0%| | 907/1000000 [17:01<324:15:35,  1.17s/it, deep_loss=0.0337, grad_norm=33, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:42:49[39m] Step: 906, Training Logs: loss_final: 1.487604, loss_mean: 1.378646, proj_loss: -0.032399, loss_mean_cls: 0.108176, deep_loss: 0.033180, grad_norm: 46.052044
Steps:   0%| | 908/1000000 [17:02<324:33:27,  1.17s/it, deep_loss=0.0337, grad_norm=33, loss_final=1.51, loss_mean=1.4, loss[[34m2025-10-03 23:42:51[39m] Step: 908, Training Logs: loss_final: 1.491257, loss_mean: 1.382095, proj_loss: -0.032023, loss_mean_cls: 0.108153, deep_loss: 0.033031, grad_norm: 38.523239
Steps:   0%| | 910/1000000 [17:05<325:39:49,  1.17s/it, deep_loss=0.0341, grad_norm=41.3, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:42:54[39m] Step: 910, Training Logs: loss_final: 1.479503, loss_mean: 1.369781, proj_loss: -0.032458, loss_mean_cls: 0.108271, deep_loss: 0.033910, grad_norm: 36.765278
Steps:   0%| | 913/1000000 [17:07<260:24:55,  1.07it/s, deep_loss=0.0336, grad_norm=31.4, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:55[39m] Step: 912, Training Logs: loss_final: 1.484004, loss_mean: 1.373911, proj_loss: -0.031855, loss_mean_cls: 0.108350, deep_loss: 0.033598, grad_norm: 38.991180
Steps:   0%| | 914/1000000 [17:08<265:03:22,  1.05it/s, deep_loss=0.0336, grad_norm=31.4, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:42:57[39m] Step: 914, Training Logs: loss_final: 1.483960, loss_mean: 1.373947, proj_loss: -0.030179, loss_mean_cls: 0.107028, deep_loss: 0.033164, grad_norm: 38.289795
Steps:   0%| | 916/1000000 [17:10<294:26:53,  1.06s/it, deep_loss=0.0334, grad_norm=32.1, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:42:59[39m] Step: 916, Training Logs: loss_final: 1.486689, loss_mean: 1.376993, proj_loss: -0.030980, loss_mean_cls: 0.108037, deep_loss: 0.032639, grad_norm: 38.418991
Steps:   0%| | 918/1000000 [17:13<310:03:53,  1.12s/it, deep_loss=0.0339, grad_norm=35.9, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:43:02[39m] Step: 918, Training Logs: loss_final: 1.479652, loss_mean: 1.369789, proj_loss: -0.031670, loss_mean_cls: 0.108870, deep_loss: 0.032664, grad_norm: 35.156109
Steps:   0%| | 920/1000000 [17:15<319:06:59,  1.15s/it, deep_loss=0.0332, grad_norm=39.9, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:43:04[39m] Step: 920, Training Logs: loss_final: 1.500310, loss_mean: 1.391086, proj_loss: -0.031741, loss_mean_cls: 0.107388, deep_loss: 0.033578, grad_norm: 30.089466
Steps:   0%| | 921/1000000 [17:16<320:29:56,  1.15s/it, deep_loss=0.0336, grad_norm=38.6, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:43:04[39m] Step: 920, Training Logs: loss_final: 1.500310, loss_mean: 1.391086, proj_loss: -0.031741, loss_mean_cls: 0.107388, deep_loss: 0.033578, grad_norm: 30.089466
Steps:   0%| | 923/1000000 [17:19<323:00:02,  1.16s/it, deep_loss=0.0343, grad_norm=35, loss_final=1.49, loss_mean=1.38, los[[34m2025-10-03 23:43:07[39m] Step: 922, Training Logs: loss_final: 1.492095, loss_mean: 1.382174, proj_loss: -0.032622, loss_mean_cls: 0.109231, deep_loss: 0.033312, grad_norm: 45.062397
Steps:   0%| | 925/1000000 [17:21<322:52:24,  1.16s/it, deep_loss=0.0338, grad_norm=60.8, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:43:09[39m] Step: 924, Training Logs: loss_final: 1.517197, loss_mean: 1.405146, proj_loss: -0.029555, loss_mean_cls: 0.109074, deep_loss: 0.032531, grad_norm: 57.736526
Steps:   0%| | 926/1000000 [17:22<323:57:56,  1.17s/it, deep_loss=0.0338, grad_norm=60.8, loss_final=1.53, loss_mean=1.42, l[[34m2025-10-03 23:43:11[39m] Step: 926, Training Logs: loss_final: 1.522584, loss_mean: 1.412762, proj_loss: -0.032222, loss_mean_cls: 0.107640, deep_loss: 0.034404, grad_norm: 36.561550
Steps:   0%| | 928/1000000 [17:24<325:01:24,  1.17s/it, deep_loss=0.0336, grad_norm=50, loss_final=1.49, loss_mean=1.38, los[[34m2025-10-03 23:43:14[39m] Step: 928, Training Logs: loss_final: 1.529204, loss_mean: 1.418216, proj_loss: -0.031863, loss_mean_cls: 0.108298, deep_loss: 0.034554, grad_norm: 56.647629
Steps:   0%| | 930/1000000 [17:27<325:21:59,  1.17s/it, deep_loss=0.0346, grad_norm=38.9, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:43:16[39m] Step: 930, Training Logs: loss_final: 1.505430, loss_mean: 1.395800, proj_loss: -0.031962, loss_mean_cls: 0.109144, deep_loss: 0.032449, grad_norm: 58.892483
Steps:   0%| | 932/1000000 [17:29<323:56:35,  1.17s/it, deep_loss=0.0348, grad_norm=62.3, loss_final=1.54, loss_mean=1.43, l[[34m2025-10-03 23:43:18[39m] Step: 932, Training Logs: loss_final: 1.516258, loss_mean: 1.406592, proj_loss: -0.031782, loss_mean_cls: 0.107358, deep_loss: 0.034090, grad_norm: 41.618668
Steps:   0%| | 933/1000000 [17:30<323:34:04,  1.17s/it, deep_loss=0.0342, grad_norm=39.9, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:43:18[39m] Step: 932, Training Logs: loss_final: 1.516258, loss_mean: 1.406592, proj_loss: -0.031782, loss_mean_cls: 0.107358, deep_loss: 0.034090, grad_norm: 41.618668
Steps:   0%| | 935/1000000 [17:33<323:39:55,  1.17s/it, deep_loss=0.0338, grad_norm=63.2, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:43:22[39m] Step: 935, Training Logs: loss_final: 1.512112, loss_mean: 1.399810, proj_loss: -0.032091, loss_mean_cls: 0.109591, deep_loss: 0.034803, grad_norm: 53.109009
Steps:   0%| | 937/1000000 [17:35<324:15:37,  1.17s/it, deep_loss=0.0335, grad_norm=36.6, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:43:24[39m] Step: 937, Training Logs: loss_final: 1.512615, loss_mean: 1.401642, proj_loss: -0.030867, loss_mean_cls: 0.108698, deep_loss: 0.033143, grad_norm: 51.558979
Steps:   0%| | 938/1000000 [17:36<324:08:38,  1.17s/it, deep_loss=0.0332, grad_norm=45.3, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:43:24[39m] Step: 937, Training Logs: loss_final: 1.512615, loss_mean: 1.401642, proj_loss: -0.030867, loss_mean_cls: 0.108698, deep_loss: 0.033143, grad_norm: 51.558979
Steps:   0%| | 940/1000000 [17:38<324:17:44,  1.17s/it, deep_loss=0.0332, grad_norm=42.7, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:43:28[39m] Step: 940, Training Logs: loss_final: 1.501189, loss_mean: 1.390935, proj_loss: -0.031339, loss_mean_cls: 0.108382, deep_loss: 0.033211, grad_norm: 44.023071
Steps:   0%| | 942/1000000 [17:40<292:26:07,  1.05s/it, deep_loss=0.034, grad_norm=44.7, loss_final=1.51, loss_mean=1.4, los[[34m2025-10-03 23:43:29[39m] Step: 942, Training Logs: loss_final: 1.512559, loss_mean: 1.402657, proj_loss: -0.031806, loss_mean_cls: 0.108733, deep_loss: 0.032975, grad_norm: 48.464352
Steps:   0%| | 945/1000000 [17:43<244:16:22,  1.14it/s, deep_loss=0.033, grad_norm=35.1, loss_final=1.48, loss_mean=1.37, lo[[34m2025-10-03 23:43:31[39m] Step: 944, Training Logs: loss_final: 1.475655, loss_mean: 1.365782, proj_loss: -0.031832, loss_mean_cls: 0.109140, deep_loss: 0.032565, grad_norm: 42.013943
Steps:   0%| | 947/1000000 [17:44<232:13:03,  1.20it/s, deep_loss=0.0332, grad_norm=43, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:43:33[39m] Step: 946, Training Logs: loss_final: 1.503750, loss_mean: 1.395398, proj_loss: -0.032155, loss_mean_cls: 0.107692, deep_loss: 0.032815, grad_norm: 45.316898
Steps:   0%| | 949/1000000 [17:47<275:55:17,  1.01it/s, deep_loss=0.034, grad_norm=49, loss_final=1.48, loss_mean=1.37, loss[[34m2025-10-03 23:43:35[39m] Step: 948, Training Logs: loss_final: 1.497206, loss_mean: 1.387236, proj_loss: -0.032613, loss_mean_cls: 0.109007, deep_loss: 0.033577, grad_norm: 25.394762
Steps:   0%| | 951/1000000 [17:49<301:32:44,  1.09s/it, deep_loss=0.0342, grad_norm=39, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:43:37[39m] Step: 950, Training Logs: loss_final: 1.470985, loss_mean: 1.358706, proj_loss: -0.032015, loss_mean_cls: 0.109342, deep_loss: 0.034951, grad_norm: 45.735340
Steps:   0%| | 952/1000000 [17:50<308:47:42,  1.11s/it, deep_loss=0.0342, grad_norm=39, loss_final=1.5, loss_mean=1.39, loss[[34m2025-10-03 23:43:39[39m] Step: 952, Training Logs: loss_final: 1.489680, loss_mean: 1.379489, proj_loss: -0.032269, loss_mean_cls: 0.109018, deep_loss: 0.033442, grad_norm: 52.610744
Steps:   0%| | 954/1000000 [17:53<318:11:09,  1.15s/it, deep_loss=0.033, grad_norm=51.3, loss_final=1.49, loss_mean=1.38, lo[[34m2025-10-03 23:43:42[39m] Step: 954, Training Logs: loss_final: 1.489611, loss_mean: 1.377511, proj_loss: -0.031331, loss_mean_cls: 0.110193, deep_loss: 0.033238, grad_norm: 44.625019
Steps:   0%| | 956/1000000 [17:55<321:40:33,  1.16s/it, deep_loss=0.0347, grad_norm=42.9, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:43:44[39m] Step: 956, Training Logs: loss_final: 1.510471, loss_mean: 1.401449, proj_loss: -0.031779, loss_mean_cls: 0.108259, deep_loss: 0.032542, grad_norm: 50.995735
Steps:   0%| | 958/1000000 [17:57<322:45:55,  1.16s/it, deep_loss=0.0333, grad_norm=50.1, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:43:46[39m] Step: 958, Training Logs: loss_final: 1.472196, loss_mean: 1.363795, proj_loss: -0.033466, loss_mean_cls: 0.108501, deep_loss: 0.033366, grad_norm: 36.670361
Steps:   0%| | 959/1000000 [17:58<323:29:54,  1.17s/it, deep_loss=0.0332, grad_norm=41.2, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:43:46[39m] Step: 958, Training Logs: loss_final: 1.472196, loss_mean: 1.363795, proj_loss: -0.033466, loss_mean_cls: 0.108501, deep_loss: 0.033366, grad_norm: 36.670361
Steps:   0%| | 961/1000000 [18:01<323:56:38,  1.17s/it, deep_loss=0.0333, grad_norm=47.9, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:43:50[39m] Step: 961, Training Logs: loss_final: 1.507735, loss_mean: 1.397670, proj_loss: -0.032255, loss_mean_cls: 0.108575, deep_loss: 0.033746, grad_norm: 38.831135
Steps:   0%| | 963/1000000 [18:03<324:44:28,  1.17s/it, deep_loss=0.0324, grad_norm=33.8, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:43:52[39m] Step: 963, Training Logs: loss_final: 1.519483, loss_mean: 1.409549, proj_loss: -0.032018, loss_mean_cls: 0.108041, deep_loss: 0.033911, grad_norm: 47.263439
Steps:   0%| | 964/1000000 [18:04<324:53:39,  1.17s/it, deep_loss=0.0336, grad_norm=48.2, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:43:52[39m] Step: 963, Training Logs: loss_final: 1.519483, loss_mean: 1.409549, proj_loss: -0.032018, loss_mean_cls: 0.108041, deep_loss: 0.033911, grad_norm: 47.263439
Steps:   0%| | 966/1000000 [18:07<326:24:39,  1.18s/it, deep_loss=0.0334, grad_norm=34.5, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:43:56[39m] Step: 966, Training Logs: loss_final: 1.481153, loss_mean: 1.372696, proj_loss: -0.033371, loss_mean_cls: 0.109648, deep_loss: 0.032179, grad_norm: 37.501064
Steps:   0%| | 968/1000000 [18:09<324:17:31,  1.17s/it, deep_loss=0.0338, grad_norm=47.7, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:43:58[39m] Step: 968, Training Logs: loss_final: 1.476363, loss_mean: 1.366970, proj_loss: -0.031855, loss_mean_cls: 0.108588, deep_loss: 0.032660, grad_norm: 33.267063
Steps:   0%| | 970/1000000 [18:11<323:34:14,  1.17s/it, deep_loss=0.033, grad_norm=32.5, loss_final=1.47, loss_mean=1.37, lo[[34m2025-10-03 23:44:00[39m] Step: 970, Training Logs: loss_final: 1.506954, loss_mean: 1.398714, proj_loss: -0.033347, loss_mean_cls: 0.107947, deep_loss: 0.033641, grad_norm: 44.177681
Steps:   0%| | 971/1000000 [18:13<324:35:50,  1.17s/it, deep_loss=0.0327, grad_norm=28.6, loss_final=1.5, loss_mean=1.4, los[[34m2025-10-03 23:44:00[39m] Step: 970, Training Logs: loss_final: 1.506954, loss_mean: 1.398714, proj_loss: -0.033347, loss_mean_cls: 0.107947, deep_loss: 0.033641, grad_norm: 44.177681
Steps:   0%| | 973/1000000 [18:15<325:04:10,  1.17s/it, deep_loss=0.0349, grad_norm=31.5, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:44:04[39m] Step: 973, Training Logs: loss_final: 1.504054, loss_mean: 1.393512, proj_loss: -0.031927, loss_mean_cls: 0.108725, deep_loss: 0.033743, grad_norm: 37.911446
Steps:   0%| | 975/1000000 [18:17<314:05:39,  1.13s/it, deep_loss=0.0332, grad_norm=19.1, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:44:06[39m] Step: 975, Training Logs: loss_final: 1.512855, loss_mean: 1.403054, proj_loss: -0.033162, loss_mean_cls: 0.108541, deep_loss: 0.034422, grad_norm: 43.719482
Steps:   0%| | 977/1000000 [18:19<264:59:38,  1.05it/s, deep_loss=0.0348, grad_norm=61.6, loss_final=1.52, loss_mean=1.41, l[[34m2025-10-03 23:44:08[39m] Step: 977, Training Logs: loss_final: 1.511339, loss_mean: 1.396510, proj_loss: -0.030820, loss_mean_cls: 0.110215, deep_loss: 0.035435, grad_norm: 37.245399
Steps:   0%| | 979/1000000 [18:21<274:39:24,  1.01it/s, deep_loss=0.0349, grad_norm=36.5, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:44:10[39m] Step: 979, Training Logs: loss_final: 1.499761, loss_mean: 1.389079, proj_loss: -0.032567, loss_mean_cls: 0.108299, deep_loss: 0.034951, grad_norm: 48.708649
Steps:   0%| | 981/1000000 [18:23<299:27:27,  1.08s/it, deep_loss=0.035, grad_norm=36.4, loss_final=1.52, loss_mean=1.41, lo[[34m2025-10-03 23:44:12[39m] Step: 981, Training Logs: loss_final: 1.477374, loss_mean: 1.365058, proj_loss: -0.031853, loss_mean_cls: 0.110163, deep_loss: 0.034006, grad_norm: 31.999308
Steps:   0%| | 983/1000000 [18:25<312:28:16,  1.13s/it, deep_loss=0.0338, grad_norm=42.1, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:44:14[39m] Step: 983, Training Logs: loss_final: 1.479325, loss_mean: 1.368871, proj_loss: -0.032192, loss_mean_cls: 0.109074, deep_loss: 0.033572, grad_norm: 33.292030
Steps:   0%| | 984/1000000 [18:26<315:56:01,  1.14s/it, deep_loss=0.0339, grad_norm=21.9, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:44:14[39m] Step: 983, Training Logs: loss_final: 1.479325, loss_mean: 1.368871, proj_loss: -0.032192, loss_mean_cls: 0.109074, deep_loss: 0.033572, grad_norm: 33.292030
Steps:   0%| | 986/1000000 [18:29<319:43:27,  1.15s/it, deep_loss=0.033, grad_norm=36.7, loss_final=1.49, loss_mean=1.38, lo[[34m2025-10-03 23:44:18[39m] Step: 986, Training Logs: loss_final: 1.486385, loss_mean: 1.374348, proj_loss: -0.031486, loss_mean_cls: 0.109603, deep_loss: 0.033920, grad_norm: 28.122673
Steps:   0%| | 988/1000000 [18:31<321:09:15,  1.16s/it, deep_loss=0.0348, grad_norm=28.2, loss_final=1.49, loss_mean=1.38, l[[34m2025-10-03 23:44:20[39m] Step: 988, Training Logs: loss_final: 1.497321, loss_mean: 1.386911, proj_loss: -0.032439, loss_mean_cls: 0.108776, deep_loss: 0.034073, grad_norm: 31.515749
Steps:   0%| | 990/1000000 [18:33<322:31:18,  1.16s/it, deep_loss=0.033, grad_norm=25.4, loss_final=1.47, loss_mean=1.36, lo[[34m2025-10-03 23:44:20[39m] Step: 988, Training Logs: loss_final: 1.497321, loss_mean: 1.386911, proj_loss: -0.032439, loss_mean_cls: 0.108776, deep_loss: 0.034073, grad_norm: 31.515749
Steps:   0%| | 991/1000000 [18:35<323:42:04,  1.17s/it, deep_loss=0.0343, grad_norm=33.5, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:44:24[39m] Step: 991, Training Logs: loss_final: 1.471339, loss_mean: 1.361726, proj_loss: -0.032872, loss_mean_cls: 0.109613, deep_loss: 0.032872, grad_norm: 23.139017
Steps:   0%| | 993/1000000 [18:37<324:58:16,  1.17s/it, deep_loss=0.0341, grad_norm=32.8, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:44:26[39m] Step: 993, Training Logs: loss_final: 1.460572, loss_mean: 1.348864, proj_loss: -0.032465, loss_mean_cls: 0.109712, deep_loss: 0.034460, grad_norm: 28.353127
Steps:   0%| | 995/1000000 [18:39<326:22:09,  1.18s/it, deep_loss=0.0327, grad_norm=30.3, loss_final=1.48, loss_mean=1.37, l[[34m2025-10-03 23:44:28[39m] Step: 995, Training Logs: loss_final: 1.460629, loss_mean: 1.349962, proj_loss: -0.032038, loss_mean_cls: 0.108225, deep_loss: 0.034480, grad_norm: 32.933399
Steps:   0%| | 996/1000000 [18:40<325:32:42,  1.17s/it, deep_loss=0.0342, grad_norm=26, loss_final=1.46, loss_mean=1.35, los[[34m2025-10-03 23:44:28[39m] Step: 995, Training Logs: loss_final: 1.460629, loss_mean: 1.349962, proj_loss: -0.032038, loss_mean_cls: 0.108225, deep_loss: 0.034480, grad_norm: 32.933399
Steps:   0%| | 998/1000000 [18:43<326:23:38,  1.18s/it, deep_loss=0.0331, grad_norm=29.3, loss_final=1.46, loss_mean=1.35, l[[34m2025-10-03 23:44:32[39m] Step: 998, Training Logs: loss_final: 1.464755, loss_mean: 1.352932, proj_loss: -0.031347, loss_mean_cls: 0.109470, deep_loss: 0.033699, grad_norm: 32.983437
Steps:   0%| | 1000/1000000 [18:45<325:53:28,  1.17s/it, deep_loss=0.0344, grad_norm=27, loss_final=1.48, loss_mean=1.37, lo[[34m2025-10-03 23:44:34[39m] Step: 1000, Training Logs: loss_final: 1.425683, loss_mean: 1.313535, proj_loss: -0.031288, loss_mean_cls: 0.110943, deep_loss: 0.032493, grad_norm: 34.363247
Steps:   0%| | 1001/1000000 [18:46<325:25:34,  1.17s/it, deep_loss=0.0333, grad_norm=37.2, loss_final=1.49, loss_mean=1.38, [[34m2025-10-03 23:44:34[39m] Step: 1000, Training Logs: loss_final: 1.425683, loss_mean: 1.313535, proj_loss: -0.031288, loss_mean_cls: 0.110943, deep_loss: 0.032493, grad_norm: 34.363247
Steps:   0%| | 1003/1000000 [18:49<324:59:48,  1.17s/it, deep_loss=0.0345, grad_norm=27.1, loss_final=1.47, loss_mean=1.35, [[34m2025-10-03 23:44:38[39m] Step: 1003, Training Logs: loss_final: 1.448270, loss_mean: 1.337864, proj_loss: -0.031079, loss_mean_cls: 0.109129, deep_loss: 0.032356, grad_norm: 38.662426
Steps:   0%| | 1005/1000000 [18:51<324:05:07,  1.17s/it, deep_loss=0.0335, grad_norm=31.1, loss_final=1.48, loss_mean=1.37, [[34m2025-10-03 23:44:40[39m] Step: 1005, Training Logs: loss_final: 1.464013, loss_mean: 1.352045, proj_loss: -0.030904, loss_mean_cls: 0.109723, deep_loss: 0.033149, grad_norm: 29.481606
Steps:   0%| | 1007/1000000 [18:53<281:31:41,  1.01s/it, deep_loss=0.0319, grad_norm=37.6, loss_final=1.45, loss_mean=1.34, [[34m2025-10-03 23:44:42[39m] Step: 1007, Training Logs: loss_final: 1.444033, loss_mean: 1.332044, proj_loss: -0.031524, loss_mean_cls: 0.110161, deep_loss: 0.033353, grad_norm: 25.628063
Steps:   0%| | 1009/1000000 [18:54<250:07:18,  1.11it/s, deep_loss=0.0326, grad_norm=35.5, loss_final=1.45, loss_mean=1.34, [[34m2025-10-03 23:44:43[39m] Step: 1009, Training Logs: loss_final: 1.482051, loss_mean: 1.371430, proj_loss: -0.031232, loss_mean_cls: 0.108701, deep_loss: 0.033152, grad_norm: 30.881996
Steps:   0%| | 1011/1000000 [18:57<285:50:57,  1.03s/it, deep_loss=0.0337, grad_norm=31.6, loss_final=1.49, loss_mean=1.37, [[34m2025-10-03 23:44:46[39m] Step: 1011, Training Logs: loss_final: 1.454359, loss_mean: 1.343283, proj_loss: -0.031556, loss_mean_cls: 0.109966, deep_loss: 0.032666, grad_norm: 27.831793
Steps:   0%| | 1013/1000000 [18:59<305:07:37,  1.10s/it, deep_loss=0.0328, grad_norm=38.3, loss_final=1.47, loss_mean=1.36, [[34m2025-10-03 23:44:48[39m] Step: 1013, Training Logs: loss_final: 1.470740, loss_mean: 1.358443, proj_loss: -0.031028, loss_mean_cls: 0.109934, deep_loss: 0.033391, grad_norm: 35.269611
Steps:   0%| | 1015/1000000 [19:01<315:10:30,  1.14s/it, deep_loss=0.0329, grad_norm=34.6, loss_final=1.46, loss_mean=1.35, [[34m2025-10-03 23:44:50[39m] Step: 1015, Training Logs: loss_final: 1.450000, loss_mean: 1.339193, proj_loss: -0.032016, loss_mean_cls: 0.110501, deep_loss: 0.032323, grad_norm: 35.786282
Steps:   0%| | 1016/1000000 [19:03<318:10:33,  1.15s/it, deep_loss=0.0322, grad_norm=36.5, loss_final=1.46, loss_mean=1.35, [[34m2025-10-03 23:44:50[39m] Step: 1015, Training Logs: loss_final: 1.450000, loss_mean: 1.339193, proj_loss: -0.032016, loss_mean_cls: 0.110501, deep_loss: 0.032323, grad_norm: 35.786282
Steps:   0%| | 1018/1000000 [19:05<321:20:16,  1.16s/it, deep_loss=0.0331, grad_norm=25, loss_final=1.5, loss_mean=1.39, los[[34m2025-10-03 23:44:54[39m] Step: 1018, Training Logs: loss_final: 1.490735, loss_mean: 1.381046, proj_loss: -0.032093, loss_mean_cls: 0.109136, deep_loss: 0.032645, grad_norm: 41.027397
Steps:   0%| | 1020/1000000 [19:07<323:58:19,  1.17s/it, deep_loss=0.0324, grad_norm=31.6, loss_final=1.48, loss_mean=1.36, [[34m2025-10-03 23:44:56[39m] Step: 1020, Training Logs: loss_final: 1.482053, loss_mean: 1.372577, proj_loss: -0.032693, loss_mean_cls: 0.109564, deep_loss: 0.032605, grad_norm: 30.170996
Steps:   0%| | 1022/1000000 [19:09<322:16:43,  1.16s/it, deep_loss=0.0327, grad_norm=38.9, loss_final=1.49, loss_mean=1.38, [[34m2025-10-03 23:44:56[39m] Step: 1020, Training Logs: loss_final: 1.482053, loss_mean: 1.372577, proj_loss: -0.032693, loss_mean_cls: 0.109564, deep_loss: 0.032605, grad_norm: 30.170996
Steps:   0%| | 1023/1000000 [19:11<323:10:51,  1.16s/it, deep_loss=0.0325, grad_norm=27.9, loss_final=1.48, loss_mean=1.37, [[34m2025-10-03 23:45:00[39m] Step: 1023, Training Logs: loss_final: 1.504103, loss_mean: 1.392141, proj_loss: -0.030447, loss_mean_cls: 0.108494, deep_loss: 0.033915, grad_norm: 32.684494
Steps:   0%| | 1025/1000000 [19:13<323:59:01,  1.17s/it, deep_loss=0.0332, grad_norm=38.2, loss_final=1.49, loss_mean=1.38, [[34m2025-10-03 23:45:02[39m] Step: 1025, Training Logs: loss_final: 1.468823, loss_mean: 1.358544, proj_loss: -0.031905, loss_mean_cls: 0.109560, deep_loss: 0.032624, grad_norm: 24.838495
Steps:   0%| | 1027/1000000 [19:15<324:02:41,  1.17s/it, deep_loss=0.0339, grad_norm=34.5, loss_final=1.48, loss_mean=1.37, [[34m2025-10-03 23:45:04[39m] Step: 1027, Training Logs: loss_final: 1.478023, loss_mean: 1.366866, proj_loss: -0.032028, loss_mean_cls: 0.109603, deep_loss: 0.033581, grad_norm: 39.662376
Steps:   0%| | 1028/1000000 [19:17<325:12:03,  1.17s/it, deep_loss=0.0326, grad_norm=23, loss_final=1.49, loss_mean=1.38, lo[[34m2025-10-03 23:45:04[39m] Step: 1027, Training Logs: loss_final: 1.478023, loss_mean: 1.366866, proj_loss: -0.032028, loss_mean_cls: 0.109603, deep_loss: 0.033581, grad_norm: 39.662376
Steps:   0%| | 1030/1000000 [19:19<325:40:05,  1.17s/it, deep_loss=0.0335, grad_norm=40.2, loss_final=1.48, loss_mean=1.37, [[34m2025-10-03 23:45:08[39m] Step: 1030, Training Logs: loss_final: 1.483052, loss_mean: 1.371029, proj_loss: -0.031778, loss_mean_cls: 0.110047, deep_loss: 0.033754, grad_norm: 33.734371
Steps:   0%| | 1032/1000000 [19:21<324:46:49,  1.17s/it, deep_loss=0.032, grad_norm=23.7, loss_final=1.47, loss_mean=1.36, l[[34m2025-10-03 23:45:10[39m] Step: 1032, Training Logs: loss_final: 1.485782, loss_mean: 1.376600, proj_loss: -0.031925, loss_mean_cls: 0.108379, deep_loss: 0.032728, grad_norm: 39.364033
Steps:   0%| | 1034/1000000 [19:24<324:21:37,  1.17s/it, deep_loss=0.034, grad_norm=36.3, loss_final=1.5, loss_mean=1.39, lo[[34m2025-10-03 23:45:10[39m] Step: 1032, Training Logs: loss_final: 1.485782, loss_mean: 1.376600, proj_loss: -0.031925, loss_mean_cls: 0.108379, deep_loss: 0.032728, grad_norm: 39.364033
Steps:   0%| | 1035/1000000 [19:25<323:52:29,  1.17s/it, deep_loss=0.0329, grad_norm=25.8, loss_final=1.47, loss_mean=1.36, [[34m2025-10-03 23:45:14[39m] Step: 1035, Training Logs: loss_final: 1.492284, loss_mean: 1.383633, proj_loss: -0.032707, loss_mean_cls: 0.107491, deep_loss: 0.033867, grad_norm: 38.903675
Steps:   0%| | 1037/1000000 [19:27<313:09:39,  1.13s/it, deep_loss=0.0333, grad_norm=36.1, loss_final=1.48, loss_mean=1.37, [[34m2025-10-03 23:45:16[39m] Step: 1037, Training Logs: loss_final: 1.492605, loss_mean: 1.380401, proj_loss: -0.031562, loss_mean_cls: 0.109920, deep_loss: 0.033846, grad_norm: 28.859646
Steps:   0%| | 1040/1000000 [19:29<260:16:18,  1.07it/s, deep_loss=0.0335, grad_norm=31.7, loss_final=1.52, loss_mean=1.41, [[34m2025-10-03 23:45:18[39m] Step: 1039, Training Logs: loss_final: 1.511348, loss_mean: 1.402212, proj_loss: -0.032430, loss_mean_cls: 0.107369, deep_loss: 0.034197, grad_norm: 28.759850
Steps:   0%| | 1041/1000000 [19:31<279:19:46,  1.01s/it, deep_loss=0.0335, grad_norm=31.7, loss_final=1.52, loss_mean=1.41, [[34m2025-10-03 23:45:20[39m] Step: 1041, Training Logs: loss_final: 1.475869, loss_mean: 1.364064, proj_loss: -0.031519, loss_mean_cls: 0.110411, deep_loss: 0.032913, grad_norm: 37.809479
Steps:   0%| | 1043/1000000 [19:33<302:49:45,  1.09s/it, deep_loss=0.0329, grad_norm=26.7, loss_final=1.49, loss_mean=1.38, [[34m2025-10-03 23:45:22[39m] Step: 1043, Training Logs: loss_final: 1.470262, loss_mean: 1.360259, proj_loss: -0.031633, loss_mean_cls: 0.109149, deep_loss: 0.032488, grad_norm: 28.628910
Steps:   0%| | 1045/1000000 [19:35<313:23:03,  1.13s/it, deep_loss=0.0338, grad_norm=38.3, loss_final=1.49, loss_mean=1.37, [[34m2025-10-03 23:45:24[39m] Step: 1045, Training Logs: loss_final: 1.482298, loss_mean: 1.371341, proj_loss: -0.031863, loss_mean_cls: 0.109669, deep_loss: 0.033151, grad_norm: 25.388176
Steps:   0%| | 1047/1000000 [19:38<320:25:16,  1.15s/it, deep_loss=0.0349, grad_norm=45.1, loss_final=1.5, loss_mean=1.39, l[[34m2025-10-03 23:45:24[39m] Step: 1045, Training Logs: loss_final: 1.482298, loss_mean: 1.371341, proj_loss: -0.031863, loss_mean_cls: 0.109669, deep_loss: 0.033151, grad_norm: 25.388176
Steps:   0%| | 1048/1000000 [19:39<321:26:16,  1.16s/it, deep_loss=0.0351, grad_norm=51.5, loss_final=1.51, loss_mean=1.4, l[[34m2025-10-03 23:45:28[39m] Step: 1048, Training Logs: loss_final: 1.494552, loss_mean: 1.383158, proj_loss: -0.032989, loss_mean_cls: 0.109680, deep_loss: 0.034703, grad_norm: 22.779961
Steps:   0%| | 1050/1000000 [19:41<323:19:34,  1.17s/it, deep_loss=0.0345, grad_norm=48.1, loss_final=1.48, loss_mean=1.37, [[34m2025-10-03 23:45:30[39m] Step: 1050, Training Logs: loss_final: 1.516412, loss_mean: 1.402163, proj_loss: -0.032128, loss_mean_cls: 0.109739, deep_loss: 0.036639, grad_norm: 52.840328
Steps:   0%| | 1052/1000000 [19:43<323:35:56,  1.17s/it, deep_loss=0.0368, grad_norm=29.6, loss_final=1.47, loss_mean=1.35, [[34m2025-10-03 23:45:32[39m] Step: 1052, Training Logs: loss_final: 1.500380, loss_mean: 1.384383, proj_loss: -0.030068, loss_mean_cls: 0.110938, deep_loss: 0.035126, grad_norm: 51.348068
Steps:   0%| | 1053/1000000 [19:45<324:00:55,  1.17s/it, deep_loss=0.035, grad_norm=60.4, loss_final=1.51, loss_mean=1.4, lo[[34m2025-10-03 23:45:32[39m] Step: 1052, Training Logs: loss_final: 1.500380, loss_mean: 1.384383, proj_loss: -0.030068, loss_mean_cls: 0.110938, deep_loss: 0.035126, grad_norm: 51.348068
Steps:   0%| | 1055/1000000 [19:47<325:10:12,  1.17s/it, deep_loss=0.0368, grad_norm=45.8, loss_final=1.5, loss_mean=1.38, l[[34m2025-10-03 23:45:36[39m] Step: 1055, Training Logs: loss_final: 1.498001, loss_mean: 1.383361, proj_loss: -0.031447, loss_mean_cls: 0.110458, deep_loss: 0.035628, grad_norm: 45.060116
Steps:   0%| | 1057/1000000 [19:49<324:50:29,  1.17s/it, deep_loss=0.0343, grad_norm=51.4, loss_final=1.5, loss_mean=1.39, l[[34m2025-10-03 23:45:38[39m] Step: 1057, Training Logs: loss_final: 1.526387, loss_mean: 1.414302, proj_loss: -0.031966, loss_mean_cls: 0.109684, deep_loss: 0.034366, grad_norm: 48.365677
Steps:   0%| | 1059/1000000 [19:52<323:59:40,  1.17s/it, deep_loss=0.0349, grad_norm=40.3, loss_final=1.5, loss_mean=1.39, l[[34m2025-10-03 23:45:38[39m] Step: 1057, Training Logs: loss_final: 1.526387, loss_mean: 1.414302, proj_loss: -0.031966, loss_mean_cls: 0.109684, deep_loss: 0.034366, grad_norm: 48.365677
Steps:   0%| | 1060/1000000 [19:53<323:54:25,  1.17s/it, deep_loss=0.0341, grad_norm=53.4, loss_final=1.51, loss_mean=1.4, l[[34m2025-10-03 23:45:42[39m] Step: 1060, Training Logs: loss_final: 1.512082, loss_mean: 1.398547, proj_loss: -0.031137, loss_mean_cls: 0.109774, deep_loss: 0.034898, grad_norm: 60.924591
Steps:   0%| | 1062/1000000 [19:55<324:23:07,  1.17s/it, deep_loss=0.0347, grad_norm=48, loss_final=1.51, loss_mean=1.4, los[[34m2025-10-03 23:45:44[39m] Step: 1062, Training Logs: loss_final: 1.518892, loss_mean: 1.406898, proj_loss: -0.031745, loss_mean_cls: 0.108857, deep_loss: 0.034881, grad_norm: 43.592175
Steps:   0%| | 1064/1000000 [19:57<324:40:12,  1.17s/it, deep_loss=0.0337, grad_norm=51, loss_final=1.51, loss_mean=1.4, los[[34m2025-10-03 23:45:47[39m] Step: 1064, Training Logs: loss_final: 1.508341, loss_mean: 1.396066, proj_loss: -0.031694, loss_mean_cls: 0.109988, deep_loss: 0.033981, grad_norm: 61.034901
